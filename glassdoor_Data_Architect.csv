Job Title,Salary Estimate,Company Name,Location,Job Description,Rating,Size,Founded,Type of ownership,Industry,Sector,Revenue
Data Engineer,$80.00 - $85.00 Per Hour (Employer est.),"3G Federal Solutions, LLC",Remote,"Re-opening for additional resume submissions. Minimum requirements HM is looking for:
1. Hands-on data engineering skills using Python and related programming skills
2. Demonstrated data transformation skills converting variety of unstructured data to structured data for analytics including experience in parser development, multi-modality extraction capabilities
3. Must have Data Engineering/solutioning experience in designing, developing, and implementing cloud-based data analytical solutions using more than 2 of the following Azure Products:
Azure Data Factory, Azure Analysis Services, Azure DataBricks (PySpark), Azure Machine Learning, Azure Storage/Data Lakes
4. Traditional BI experience in SQL Server Stack including writing complex T-SQL stored procedures; use of SSIS to develop and deploy complex SSIS Packages across multiple-environments; data migration experience
5. Data modeling and visualization experience using Power BI /DAX programming experience is highly preferred
We are looking for Data Engineers to support operationalizing Security Governance and Risk (SG&R) Division`s Data Analytics Programs. The ideal candidate for this position with source, evaluate, and prepare data assets for easier access and use by data consumers and stakeholders. The person hired for this role will be part of a team that will help implement a modern end-toend data analytics infrastructure that enable data-centric risk decisioning.
Responsibilities
Implement and manage data transformations needed by customer (e.g., Analytics team, Data Scientists, ML Modelers)
Closely work with Data Architect(s) to build functional capabilities and analytical tools and needed to realize data architecture goals
Improve/automate internal processes for optimal data delivery and mature infrastructure for greater scalability and functionality
Confirm all data pipelines and data flows are operational and well-functioning
Implement data quality checks to maintain data integrity and monitor for high data quality
Provide support to assigned department; may work on small projects or portions of larger projects
Support business strategy and initiatives within the business unit and/or across the organization
Assist and collaborate with various levels of staff to accomplish tasks/assignments
Perform research and analysis; may include quantitative and/or qualitative analysis
Maintain professionalism in all interactions, placing member service as priority
Support comprehensive day-to-day
Qualifications
Must have a bachelor’s degree in Information Science, Data Analytics, Information Management, or Computer Science or 5+ years of experience in a directly related role with progressive growth
Proven experience as a data engineer with experiences in designing and building analytical solutions. Specifically, handson experience in setting up data pipelines for data science and machine learning projects.
Proficiency with Python in a data engineering context. E.g., Pandas, PySpark, PyTorch
Experience in cloud-based data products and solutions such as: Azure Data Factory, Azure Synapse, Azure SQL, Azure Data Lake, and Azure App Service
Exposure to data/collaboration tools such as MS SharePoint, MS Power BI, MS Power Platform, Service Now, GRC applications, and related Azure Cloud Technology/Products
Significant experience in handling unstructured datasets and converting them into Structured datasets
Effective interpersonal, verbal, and written communication skills
Effective research, analytical, and problem-solving skills
Effective skill maintaining accuracy with attention to detail and meeting deadlines
Provide exceptional Customer Service support
Preferred Qualifications
Experience in designing and hands-on development in cloud-based analytics solutions
Proficiency with Python in a data engineering context. E.g., Pandas, PySpark, PyTorch
Experience with multiple programming languages, including Python, R, MATLAB, or SAS • Hands-on experience in modern Data Platforms related technologies such as Azure Synapse, Azure SQL Azure Databricks and Power BI (including using DAX) is desirable
Strong knowledge of Microsoft BI Stack (SSRS/SSAS (Tabular with DAX & OLAP with MDX) SSIS)
Strong understanding of NoSQL implementation (Mongo, Cosmos DB or other similar tools)
Designing and building of data pipelines using API ingestion and other ingestion methods (batch and real-time)
Knowledge of Dev-Ops processes (including CI/CD) and use of source control software such as Git or GitHub is essential
Experience in metadata management and data governance tools and processes (e.g., Microsoft Purview, Collibra, Informatica, Talend) is desirable
Strong experience in common data warehouse modelling principles including Kimball, Inmon is desirable
Ability to easily converse with Data Scientists, ML Modelers, and Data Engineers on various data analytical concepts and statistical modeling technique (e.g., regression, logistic regression, log-linear regression) is desirable
Strong academic background or experiences in Security-related domain and/or banking Industry is desirable
Excellent knowledge and passion for cloud computing technologies and current computing trends
Job Type: Contract
Pay: $80.00 - $85.00 per hour
Experience level:
10 years
Schedule:
Monday to Friday
Work Location: In person
Show Less
Report",-1,1 to 50 Employees,-1,Company - Public,-1,-1,Unknown / Non-Applicable
Data Engineer/MACHINE LEARNING,$60.00 - $70.00 Per Hour (Employer est.),TellusSolutions3.7 ★,"Sunnyvale, CA","Job Description:
The role will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams.
The ideal candidate is an experienced data pipeline builder and data wrangler who enjoy optimizing data systems and building them from the ground up.
The Data Engineer will support our software developers, database architects, and data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple teams, systems and products.
The right candidate will be excited by the prospect of optimizing or even re-designing our data architecture to support our next generation of products and data initiatives.
Responsibilities:
Create and maintain optimal data pipeline architecture for data intensive applications.
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using Azure SQL, Cosmo DB, Databricks and other legacy databases.
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.
Keep our data separated and secure across national boundaries through multiple data centers and Azure regions.
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
Work with data and analytics experts to strive for greater functionality in our data systems.
Qualifications for Data Engineer
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Extensive Experience on Databricks on Azure Cloud platform, deep understanding on Delta lake, Lake House Architecture.
Programming experience on Python, Shell scripting, PySpark, and other data programming language.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with Data Visualization Dashboard, Metrics and etc.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
Skills:
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Working knowledge of message queuing, stream processing, and highly scalable 'big data' data stores.
Familiar with Deployment tool like Docker and building CI/CD pipelines.
Experience supporting and working with cross-functional teams in a dynamic environment.
8+ years' experience in software development, Data engineering, and
Bachelor's degree in computer science, Statistics, Informatics, Information Systems or another quantitative field. Postgraduate/master's degree is preferred.
Experience in Machine Learning and Data Modeling is a plus.
Job Type: Contract
Pay: $60.00 - $70.00 per hour
Benefits:
401(k)
Dental insurance
Vision insurance
Compensation package:
Hourly pay
Schedule:
8 hour shift
Ability to commute/relocate:
Sunnyvale, CA 94086: Reliably commute or planning to relocate before starting work (Required)
Experience:
Python: 1 year (Preferred)
SQL: 1 year (Preferred)
Work Location: In person
Show Less
Report",3.7,51 to 200 Employees,2006,Company - Private,Information Technology Support Services,Information Technology,$5 to $25 million (USD)
Data Architect,$160K - $230K (Employer est.),Appcues4.9 ★,Remote,"Your work as Appcues’ Data Architect will empower thousands of Appcues customers to improve their SaaS products’ adoption and engagement for millions of their end-users. Appcues’ no-code tools have helped customers deliver over 1.4 billion in-app web and mobile experiences such as onboarding guides, tips, announcements, and surveys. Our customers, such as Fullstory, Lyft, and Twilio, depend on our services to deliver these in-app experiences. Your mission will be to evolve our platform’s data architecture to support several new product initiatives and new products. You will collaborate closely with our product team and platform engineers to gather requirements, design and implement foundational changes that will power Appcues for years.
Tools we use
We store data in PostgreSQL, DynamoDB, S3, Redis, and Snowflake. We operate data pipelines and event streams using Kafka and SQS.
We manage, monitor, and deploy code using CircleCI, Terraform, and AWS CodeDeploy, CloudFormation, DataDog.
Our platform is powered using Elixir, Node running on Lambdas, ECS, and EC2.
Our engineers communicate primarily via Slack, and are committed to remote, agile development using Kanban.
About the role
Our fully remote engineering team currently has over 45 people. As Data Architect you will work closely with our Platform engineering teams to define our data platform and collaborate with the team on implementation.
Our data model is currently defined in Snowflake, DynamoDB and Postgres and is optimized for delivering experiences embedded in our customers' SaaS applications. Your goal will be to evolve that data model to support additional use cases and products.
Our platform handles over a billion requests from our customer sites per day via our JavaScript and mobile SDKs and from partners like Segment.io and Zapier. It also includes services that process customer rules for personalization, segmentation, and targeting.
You will evolve our data model using domain-driven design and other strategies to support our product and business objectives and adapt to current constraints.
On a typical day, you may work with our product managers to understand our business’ data model and future goals, collaborate with frontend and backend teams on constraints and needs, publish models, write technical proposals, architect solutions, work with tech leads to break epics, implement features, or mentor others.
You'll be involved in all research & development, including discovery and testing of new features and products. You will work with engineers, designers, and product managers to discover solutions, including identifying and mitigating any feasibility risks.
You will select and propose suitable database technologies to meet our business objectives including defining ETL processes for data transformation.
Work closely with the Security and Compliance team on data security measures and on ensuring compliance with regulations and data governance frameworks.
Become an expert on the data Appcues needs for products, integrations, and customers to be successful.
About you
You have designed, built and evolved significant data models to support the rapid growth of large distributed applications and product activity / analytics data. You have excellent judgment across multiple database implementations, including columnar, relational and streaming database technologies. You are pragmatic, not dogmatic, and are aware of the strengths & weaknesses of your tools.
You have deep experience using Snowflake and AWS database stacks. You are an expert in domain-driven design and data modeling, and proficient in data transformation, performance tuning, and data warehousing.
You are comfortable influencing cross-team practices, and tools by rolling up your sleeves and showing how things can improve. You can clearly describe the business implications of your technical decisions. You are excited to develop a vision & future technical roadmap of a data platform.
You enjoy mentoring other engineers and helping them grow technically. You often have become a key go-to person in your company, even on projects outside your project area.
You have led the delivery of data platform initiatives for B2B SaaS applications with significant analytics needs. For example, systems that have ingested and processed data at significant scale, managed elastic workloads using queue/worker or streaming architectures, and power the visualization of millions of data points.
While our company supports remote work, we require your availability for team collaboration during the core hours of 10 am to 4 pm Eastern Time.
You are energized working in a highly collaborative environment at a customer-driven startup.
Note - Appcues uses a market-data driven approach to setting compensation ranges, and pins compensation ranges to data provided by third-party organizations. This range is for all US-based candidates and is built to be competitive nationwide by utilizing ranges for the Greater Boston area, regardless of where in the US an employee lives (or later relocates). This range represents salary-based compensation and does not include our equity package (in stock options), 401k match, or other benefits including an office setup budget, tech budget, training and education budget, and co-working space reimbursements. Actual compensation offered to a successful applicant may be based on job-related experience and other factors consistent with applicable law. For non-US based candidates, Appcues adjusts salary ranges based on cost of labor in each market. If you have questions on the pay range in your country, the recruiter will be happy to discuss specifics during your introductory conversation.""

About Us

Appcues' mission is to help teams deliver experiences their users love. Our vision is for every software company to embrace product-led growth, resulting in more engaged and happier users.

Our Benefits

100% remote - We don’t have an office so all of our employees learn and collaborate in the same way using remote work practices. This won't change post-COVID as we are committed to being 100% remote for the long-term. We work in Slack, Zoom, and a collection of modern collaboration tools. We have inclusive remote events and we get together annually for a fun off-site retreat.
Well-being - You'll have solid health, dental, and vision plans; access to 401k, and a generous maternity and paternity leave.
Fair pay - Each role has a defined salary band, bands and salaries are audited on a regular basis to help maintain fairness and market value
Home office and tech budget - Besides paying for your work computer (Mac or PC), we offer a one-time $1000 home office stipend and an additional $500 annual budget for extra work-related technology.
Coworking space, on us - Home office not cutting it? We'll reimburse your monthly coworking fees.
Equity - We want everyone invested in our success. We grant every employee equity in the company.
Transparency and collaboration - We foster team alignment with meetings of all shapes and sizes—a monthly all-hands meeting called FirstThurs, weekly team lunches, and Lunch & Learns., and an annual learning stipend.
Flexible Time Off - We believe time away to reflect and explore makes us all more productive, so employees don’t accrue vacation time – they work with their managers to schedule time off when they need it, consistent with our Flexible Time Off policy. Employees based in the USA also take off all US federal holidays. Employees residing in other countries can choose to follow their local national holidays or US federal holidays.
Show Less
Report",4.9,1 to 50 Employees,2014,Company - Private,Internet & Web Services,Information Technology,Unknown / Non-Applicable
"Data Engineer, National",-1,Make-A-Wish Foundation of America4.0 ★,United States,"At Make-A-Wish® America, we are more than a great place to work — our work is life-changing. Together, we create life-changing wishes for children with critical illnesses. Nearly 40 years ago the inspiration for Make-A-Wish began with one little boy's wish to be a police officer. Today, together with our volunteers, donors, staff and supporters, Make-A-Wish has granted more than 500,000 life-changing wishes and transformed countless lives.

THE TEAM
Make-A-Wish America is the national headquarters for our organization, providing resources and support for our 58 Chapters around the country. The Information Technology team is comprised of a diverse team of technologists responsible for building and operating the technologies that enable Make-A-Wish to grant the wish of every eligible child. The Information Technology team is focused on providing innovative solutions across these key areas: Operations, Security, Applications, Infrastructure, Governance, and Analytics.

THE ROLE
The Data Engineer is to expand the company’s use of data as an enabler of corporate goals and objectives. The Data Engineer will achieve this by designing, developing, and implementing data models for enterprise-level applications and systems. This individual will act as the primary advocate of data modeling methodologies.

WHERE YOU COME IN
As the Data Engineer you will:
Collaborate with project managers and business unit leaders for all projects involving enterprise data. Act as an advocate of data management
Assess and determine governance, stewardship, and frameworks for managing data across the organization.
Develop and promote data management methodologies and standards.
Identify and address inefficiencies and gaps in systems integration, compatibility, and multi-platform integrations.
Oversee the mapping of data sources, data movement, interfaces, and analytics, with the goal of ensuring data quality.
Document the data architecture and environment in order to maintain a current and accurate view of the larger data picture.
Identify and develop opportunities for data reuse, migration, or retirement.
Develop, implement, and maintain change control and testing processes for modifications to databases.

WHAT YOU’LL NEED
College diploma or university degree in computer science, information systems, or computer engineering is highly desired.
Certifications are highly desired.
4+ years of work experience as a data architect, or database administrator, or data modeler, or similar.
College diploma or university degree in computer science, information systems, or computer engineering is highly desired.
Certifications are highly desired.
SQL experience working with data and programming (Queries, Functions, Stored Procedures) is a must.
Strong understanding of relational data structures, theories, principles, and practices.
Hands-on knowledge of enterprise repository tools, data modeling tools, data mapping tools, and data profiling tools.
Experience with data processing flowcharting techniques.

WHAT WE OFFER
BENEFITS
Competitive compensation with annual incentive potential
Comprehensive benefit package: Medical, Vision*, Dental*, Wellness
Health Savings Account and Flexible Spending Account Options
Health Reimbursement Account fully funded by Make-A-Wish
Short Term Disability*, Long Term Disability* and Life Insurance
Additional Insurance Plans: Accident, Critical Illness, Hospital Indemnity, Pet Insurance through Figo
401(k) Retirement Savings Plan with 5% match after one year of service

TIME OFF
Up to 15 PTO days
10 Sick Days
11 Paid Holidays
2 Volunteer Days after one year of service
2 Personal Days accrued annually
Maternity Leave
ALSO...
Employee Awards and Recognition Programs
Individual and Leadership Development
Discounts and special offers for theme parks, events, hotels, concerts, and movie tickets
Monthly premiums paid for the employee for vision, dental, and short/long term disability.

Diversity, Equity & Inclusion Vision
Make-A-Wish is committed to championing diversity, equity and inclusion, fostering an organization that is accessible and welcoming. In turn, we are uniting communities to help make more wishes possible.
Our mission is most effectively fulfilled through a commitment to diversity, equity and inclusion as core values and practice.
It is only through our mosaic of different cultures, perspectives and experiences that we can grant life-changing wishes to every eligible child.
As the world’s largest wish-granting organization we stand against racism and intolerance and are committed to representation and acceptance, creating a sense of belonging, and practicing fairness in creating opportunities for our wish families, volunteers and staff.

We respect and ensure equal opportunity, regardless of race, religion, ethnicity, national origin, age, gender identity, sexual orientation, disability, perceived disability and other legally protected characteristics. Make-A-Wish America utilizes E-Verify in its hiring practices to achieve a lawful workforce.
Show Less
Report",4.0,1001 to 5000 Employees,1980,Nonprofit Organization,Civic & Social Services,Nonprofit & NGO,$25 to $100 million (USD)
Global Breeding R&D Data Architect,$77K - $108K (Employer est.),Driscoll's4.2 ★,"Watsonville, CA","About the Opportunity:
Global Breeding drives significant value for Driscoll’s enterprise, operating breeding programs and research centers across the globe to produce elite, proprietary berry varieties. The role of the Global R&D Breeding Data Architect will be to design and implement data solutions for managing, storing, processing, and facilitating access to our complex plant breeding data. The ideal candidate will enhance our breeders’ abilities to make informed, data-driven decisions and will streamline the flow of data into genomic prediction models.

**Hybrid role - combination of remote work and onsite at our Watsonville, CA location**

Responsibilities:
Collaborate with Global Breeding data stakeholders to understand their data requirements, challenges, requests, and opportunities for improvement.
Serve as a liaison between Global Breeding and Information Services to connect and align mutual requests related to data management.
Enhance and create data collection tools and techniques to ensure adequacy, accuracy, and legitimacy of data; provide training with end-users as necessary.
Assist in the definition and implementation of streamlined workflows to systematically integrate breeding data into genomic predictive analyses.
Design and implement scalable, secure, and performant data solutions to improve data availability to stakeholders and to accelerate data analysis and reporting within Global Breeding.
Evaluate and recommend appropriate technology and tools for data management, including database systems, data integration and transformation tools, and data visualization tools.
Ensure breeding data solutions are integrated with other systems and processes, and provide ongoing technical support and troubleshooting as needed.
Create and maintain data management roadmaps, guidelines, and best practices to ensure data consistency and accuracy across the organization.
Act as a technical advisor for data-related projects and provide technical guidance and support to cross-functional teams.
Oversee the integration of new technologies and initiatives into data standards and structures.

Candidate Profile:
Bachelor’s in Computer Science, Information Systems, or related field.
2-4 years’ experience as a data manager, working with data architecture and solution design with a focus on complex data management solutions.
Proficiency in database systems (Microsoft SQL Server required), data integration and transformation tools, and data visualization tools (e.g., R, Tableau, XLStat).
Ability to analyze, interpret, and organize large amounts of data.
Ability to understand breeding program and business processes and requirements and to design and implement effective data solutions.
Excellent communication skills, with the ability to explain technical concepts to non-technical stakeholders.
Excellent organizational and time-management skills and thorough attention to detail; ability to work effectively across multiple projects and deadlines, simultaneously.
Strong problem-solving and analytical skills, with the ability to think outside the box to find innovative solutions.
Familiarity with plant breeding and agricultural data and processes (nursery, yield trials, flavor evaluations, disease trials, etc.) preferred.
Spanish language proficiency a plus.
Ability to maintain a hybrid work schedule with time working from the office and from home.
Ability to travel (5% travel).
California Driver’s license and the ability to be covered under company-sponsored vehicle insurance program.

Compensation & Benefits:
The following information is provided in good faith as a general description of the salary range and benefits for the position posted. The actual compensation offered to the successful candidate is dependent upon experience, skills, education, work location, internal pay equity, and other objective job-related factors.
Salary Range estimated for the Global R&D Breeding Data Architect: $77,100 to $108,000 USD.
Driscoll’s is committed to a culture of care and offers an attractive benefits package that includes comprehensive medical, dental, and vision coverage, life insurance, and disability coverage for positions working more than 30 hours per week. Other benefits include: 401(k) with employer match, profit-sharing participation, paid sick time, paid vacation, paid personal and family care leave, and a free Employee Assistance Program (EAP). More detailed information regarding the benefits package, will be shared during the application process.

About Driscoll's:
Driscoll's is the global market leader for fresh strawberries, blueberries, raspberries and blackberries. With more than 100 years of farming heritage and hundreds of independent growers around the world, Driscoll's is passionate about growing fresh, beautiful and delicious berries. Our values of humility, passion and trustworthiness have guided our mission to delight consumers around the world.
Driscoll's exclusive patented berry varieties are developed through years of research using only natural breeding methods – meaning, no GMOs. From farm-to-table, we focus on delivering a high quality, premium berry experience with our many supply chain partners.
Driscoll's is the trusted brand for Only the Finest Berries™.



About Driscoll's:

Driscoll's is the global market leader for fresh strawberries, blueberries, raspberries and blackberries. With more than 100 years of farming heritage and hundreds of independent growers around the world, Driscoll's is passionate about growing fresh, beautiful and delicious berries. Our values of humility, passion and trustworthiness have guided our mission to delight consumers around the world. Driscoll's exclusive patented berry varieties are developed through years of research using only natural breeding methods – meaning, no GMOs. From farm-to-table, we focus on delivering a high quality, premium berry experience with our many supply chain partners. Driscoll's is the trusted brand for Only the Finest Berries™.
Start your job application: click Easy Apply
Show Less
Report",4.2,1001 to 5000 Employees,1900,Company - Private,Crop Production,Agriculture,$5 to $25 million (USD)
Data Engineer,$71.42 Per Hour (Employer est.),TELLUS SOLUTIONS3.7 ★,"Sunnyvale, CA","Job Description:
The role will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams.
The ideal candidate is an experienced data pipeline builder and data wrangler who enjoy optimizing data systems and building them from the ground up.
The Data Engineer will support our software developers, database architects, and data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple teams, systems and products.
The right candidate will be excited by the prospect of optimizing or even re-designing our data architecture to support our next generation of products and data initiatives.
Responsibilities:
Create and maintain optimal data pipeline architecture for data intensive applications.
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using Azure SQL, Cosmo DB, Databricks and other legacy databases.
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.
Keep our data separated and secure across national boundaries through multiple data centers and Azure regions.
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
Work with data and analytics experts to strive for greater functionality in our data systems.
Qualifications for Data Engineer
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Extensive Experience on Databricks on Azure Cloud platform, deep understanding on Delta lake, Lake House Architecture.
Programming experience on Python, Shell scripting, PySpark, and other data programming language.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with Data Visualization Dashboard, Metrics and etc.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
Skills:
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Working knowledge of message queuing, stream processing, and highly scalable 'big data' data stores.
Familiar with Deployment tool like Docker and building CI/CD pipelines.
Experience supporting and working with cross-functional teams in a dynamic environment.
8+ years' experience in software development, Data engineering, and
Bachelor's degree in computer science, Statistics, Informatics, Information Systems or another quantitative field. Postgraduate/master's degree is preferred.
Experience in Machine Learning and Data Modeling is a plus.
Job Type: Contract
Salary: Up to $71.42 per hour
Benefits:
Health insurance
Ability to commute/relocate:
Sunnyvale, CA 94086: Reliably commute or planning to relocate before starting work (Required)
Experience:
Data modeling: 1 year (Preferred)
Machine learning: 1 year (Preferred)
Azure SQL: 1 year (Preferred)
Metadata: 1 year (Preferred)
Work Location: In person
Show Less
Report",3.7,51 to 200 Employees,2006,Company - Private,Information Technology Support Services,Information Technology,$5 to $25 million (USD)
Data Engineer,-1,NucleusTeq4.8 ★,Remote,"Data Engineer
Role Info:
Hands on BI Data Engineer role with strong
Creating KPI Dashboards - Interactive Dashboards using tableau / Quicksight
Top Skills:
BI Tableau / AWS Quicksight exp is a must
AWS (IAM, RDS, S3, Lambda) exp is a must
SQL exp is a must
Python knowledge is required
Nice to have:
AWS Certified Solutions Architect
About the Company:
NucleusTeq is a software services, solutions & products company empowering & transforming customer's business through the use of digital technologies such as Big-Data, Analytics, Cloud, Enterprise Automation, Block-chain, Mobility, etc.
We are enabling several fortune 1000 clients in the USA, Canada, UK & India to navigate their digital transformation.
Show Less
Report",4.8,201 to 500 Employees,2018,Company - Private,Information Technology Support Services,Information Technology,$5 to $25 million (USD)
Snowflake Data Architect - Remote Position,$85.00 - $120.00 Per Hour (Employer est.),YT Global Network5.0 ★,Remote,"Snowflake Architect- Remote
Long term contract
Responsibilities:
- Design and develop software architecture for complex systems
- Collaborate with cross-functional teams to define and implement software requirements
- Conduct code reviews and provide technical guidance to ensure high-quality code
- Analyze and optimize database design for efficient data storage and retrieval
- Implement analytics solutions to extract meaningful insights from big data
- Stay up-to-date with industry trends and emerging technologies to drive innovation
Qualifications
Experience in the implementation, execution, and maintenance of Data Integration technology solutions
Experience advancing and supporting information management practices within business processes, applications and technology that underpin the data discipline (e.g. establishing data quality processes, performing data analysis, participating in technology implementation planning, implementing data integration processes, etc)
Expertise in Snowflake data modeling, ELT using snowpipe, implementing stored procedures and standard DWH and ETL concepts
Expertise in Snowflake concepts like setting up resource monitors, RBAC controls, virtual warehouse, query performance tuning, Zero copy clone, time travel and understand how to use these features
Experience in Data Migration from RDBMS to Snowflake cloud data warehouse
Experience with enterprise cloud economics
Understanding of enterprise data management concepts (Data Governance, Data Engineering, Data Science, Data Lake, Data Warehouse, Data Sharing, Data Applications)
Hands-on expertise with SQL and SQL analytics
Industry benchmarking experience in major industries such as: Financial Services and Retail
Certifications for any of the cloud services like AWS, Snowflake, GCP or Azure
Experience working with code repositories and continuous integration
Understanding of development and project methodologies
Skills:
- Strong knowledge of database design principles and SQL
- Proficiency in programming languages such as Java, Python, or C++
- Experience with big data technologies and frameworks (e.g., Hadoop, Spark)
- Familiarity with analytics tools and techniques for data analysis and visualization
- Excellent problem-solving and analytical skills
- Strong communication and collaboration abilities
As a Software Architect, you will play a crucial role in designing and developing software solutions that meet the needs of our organization. Your expertise in database design, analytics, and big data will be instrumental in driving innovation and delivering high-quality software products.
Job Types: Full-time, Part-time, Contract
Pay: $85.00 - $120.00 per hour
Schedule:
Monday to Friday
Work Location: Remote
Show Less
Report",5.0,Unknown,-1,Company - Public,-1,-1,Unknown / Non-Applicable
Senior Data Engineer,$100K - $133K (Glassdoor est.),LOOP BELL TECH INC3.7 ★,"Fort Worth, TX","Contract: W2
Note: No C2C
Responsibilities:
* Collaborates with architecture and technical leadership to define the vision and solutions
* Collaborate alongside other engineers of various disciplines to take the design and create executable pieces of work
* Participates in all phases of development
* Establishes and champions First Command data and data engineering standards/best practices
* Communicate and work alongside members of their team in support of their day-to-day work items
* Works with business partners to ensure alignment between the ask and the output
* Participate and lead peer reviews and champion peer review best practices and culture
* Key player and leader in an Agile environment, participating in daily huddles, sprint planning, retrospectives, etc.
* Mentors junior team members in best practices and standards
* Serve as escalation point for other team members on technical issues
* Leads effort to create and document deployment and release plans
* Works with architects to evaluate new technologies and patterns that will inform the technology roadmap
* Leads Communities of Practices or other cross functional training opportunities
* Leads troubleshooting processes to determine root cause analysis
REQUIREMENTS:
* Bachelor's degree required; MBA or MS or equivalent a plus
* 7+ years of applied experience in data integration, ETL, and data management or comparable positions that handle large/complex data sets, developing automation, and fostering business partner relationships
* Expert in one or more of the following ETL tools such as Azure Data Factory, Informatica, Matillion, Fivetran and DBT
* Experience working with a diverse set of data sources such as Flat File, Database, API, Event Streaming
* Expert in SQL with knowledge of T-SQL
* Strong experience in data modeling, data warehousing, and MDM solutions
* Familiar with Azure Synapse or Snowflake
* Familiar with Databricks Delta Lake
* Familiar with a scripting language such as python, powershell, or bash
* Familiar with data lake design patterns
* Excellent written communication and presentation skills
* Proficient in understanding of data mapping and lineage strategies
* Proficient in understanding in conceptual, logical, and physical data design
* Proficient in understanding of data management practices, data architecture principles, and data governance process
Preferred Qualifications:
* Expert in Azure Data Factory, Data Bricks, and Python
* Strong dimensional modelling skills
* Familiarity with DevOps principles and processes
* Applied experience in Agile, SAFe, or Scrum
* Financial services industry experience or other highly regulated industry experience a plus
* Familiarity with data science and analytics tools such as Alteryx, SPSS, SAS, Tableau, PowerBIResponsibilities:
* Collaborates with architecture and technical leadership to define the vision and solutions
* Collaborate alongside other engineers of various disciplines to take the design and create executable pieces of work
* Participates in all phases of development
* Establishes and champions First Command data and data engineering standards/best practices
* Communicate and work alongside members of their team in support of their day-to-day work items
* Works with business partners to ensure alignment between the ask and the output
* Participate and lead peer reviews and champion peer review best practices and culture
* Key player and leader in an Agile environment, participating in daily huddles, sprint planning, retrospectives, etc.
* Mentors junior team members in best practices and standards
* Serve as escalation point for other team members on technical issues
* Leads effort to create and document deployment and release plans
* Works with architects to evaluate new technologies and patterns that will inform the technology roadmap
* Leads Communities of Practices or other cross functional training opportunities
* Leads troubleshooting processes to determine root cause analysis
REQUIREMENTS:
* Bachelor's degree required; MBA or MS or equivalent a plus
* 7+ years of applied experience in data integration, ETL, and data management or comparable positions that handle large/complex data sets, developing automation, and fostering business partner relationships
* Expert in one or more of the following ETL tools such as Azure Data Factory, Informatica, Matillion, Fivetran and DBT
* Experience working with a diverse set of data sources such as Flat File, Database, API, Event Streaming
* Expert in SQL with knowledge of T-SQL
* Strong experience in data modeling, data warehousing, and MDM solutions
* Familiar with Azure Synapse or Snowflake
* Familiar with Databricks Delta Lake
* Familiar with a scripting language such as python, powershell, or bash
* Familiar with data lake design patterns
* Excellent written communication and presentation skills
* Proficient in understanding of data mapping and lineage strategies
* Proficient in understanding in conceptual, logical, and physical data design
* Proficient in understanding of data management practices, data architecture principles, and data governance process
Preferred Qualifications:
* Expert in Azure Data Factory, Data Bricks, and Python
* Strong dimensional modelling skills
* Familiarity with DevOps principles and processes
* Applied experience in Agile, SAFe, or Scrum
* Financial services industry experience or other highly regulated industry experience a plus
* Familiarity with data science and analytics tools such as Alteryx, SPSS, SAS, Tableau, PowerBI
Job Type: Contract
Schedule:
8 hour shift
Ability to commute/relocate:
Fort Worth, TX 76102: Reliably commute or planning to relocate before starting work (Required)
Application Question(s):
Willing to work W2
Experience:
Informatica: 1 year (Preferred)
SQL: 1 year (Preferred)
Data warehouse: 1 year (Preferred)
Work Location: In person
Show Less
Report",3.7,1 to 50 Employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable
Data Engineering Architect,-1,Inova Health System3.8 ★,"Fairfax, VA","The Data Engineering Architect will assess client requirements, detail their current data needs, and design a data strategy for developing and implementing data intake, refresh and governance processes. This role is responsible for proper designing and creating necessary data architecture design across the Enterprise in a federated user/departmental environment, including data modeling, implementation of data marts and warehouses, populating data structures using proper ETL processes to support data flows from EPIC as well as other non-EPIC source systems.The Data Engineering Architect is responsible for designing, developing and operationalizing strategies that guarantee smooth and timely delivery of software products or update activities for Epic and other assigned applications. Provides project management for on-going loads of Epic Interim Updates (IUs) and Special Updates (SUs), Release Authorizations (RA), and major releases including monthly Epic production downtimes. Responsible for the environmental strategy for all Epic environments. Sets up and maintains Release Authorization user and team security. Coordinates any equipment upgrades that Epic utilizes. Advises on the infrastructure strategy design, evaluation, purchase, testing, installation and maintenance of the hardware and software for Epic systems infrastructure necessary to ensure optimal performance.Leads project teams and implements project plans in accordance with established goals and measures. Serves as a consultant to executive leadership, stakeholders, and others to provide decision support for enterprise architecture initiatives, policies, and procedures. Facilitates problem resolution, escalations, and system-wide troubleshooting and support with demonstrably superior level of proficiency.

Job Responsibilities


Lead the organization to build and develop the overall Data Architecture for the enterprise.
Support the team on their day-to-data needs for data contents and the proper modeling of such data
Provide ETL design and implementation for the construction of data marts/warehouses
Analyzing the use of data and interpreting data directly against requirements to support project needs
Contribute to data governance and assist in enforcing data standards
Capturing source data characteristics and abstracting them into consolidated data repository with proper data lineage and change control – including data from internal and external sources, also on premises or from the Cloud.
Determining the logical design characteristics and information management strategies necessary to store, move, and manage data from a wide variety of database and system platforms.
Responsible to create, vet and publish data sources for common use with various BI tools (currently Tableau, Crystal and EPIC reporting products).
Gathering, documenting, and designing data integration and data visualization requirements for projects for small organizations through large corporations.
Assist BI content creators to rapidly generate impactful, interactive visualizations with consistent and proper data elements


Additional Requirements

Education
Bachelors Degree required
Masters degree preferred
Experience
7+ years experience working with BI developers and end users. Experience in a healthcare environment.
Preferred: 8 or more years experience. Expertise in project management tools such as critical path analysis
Certifications
Advanced certifications in IT specialties within 6 months
Preferred: Multiple Epic certifications
Skills
Substantial experience in SQL and SQL scripting; familiar with EPIC Clarity and Caboodle models and design.
Very strong knowledge of ETL process
3+ years of experience in working with BI users & tools such as Tableau.
Experience in implementing best practices in end-to-end data governance for the organization.
Proven track record in converting various source system databases into data warehouses and/or data marts for heavy use in data visualization tools.
Strong executive presence and ability to interact with business users/leaders while retaining an ability to interact with all levels within the organization. Familiar with software development life cycle and project management tools (such as Agile and JIRA)
Ability to break problems down into discrete steps or activities.
Strong knowledge of capabilities, functionality, and behaviors of BI reporting/data discovery tools.
Practical application of data domain knowledge including data lineage, data governance, metadata, etc.
Strategies for optimizing data structures to perform well in an environment with large number of end users.
Exhibits strong task and project management skills to ensure tasks and projects are completed in a successful, timely manner.
Must be comfortable in a fast-paced environment, to be able to work with users and other team members to be a contributor to build out best practices on data life cycle, data quality, data lineage and content governance to support all enterprise platforms.
Apply Now: click Apply Now
Show Less
Report",3.8,10000+ Employees,1956,Nonprofit Organization,Health Care Services & Hospitals,Healthcare,$1 to $5 million (USD)
Data Architect,$95.41 Per Hour (Employer est.),Gointellects Inc.,Remote,-1,3.8,-1,-1,-1,-1,-1,-1
Azure Data Architect,$80.23 - $90.61 Per Hour (Employer est.),Plaxonic Technologies Inc.4.6 ★,Remote,"Azure Data Architect
Location: Remote (West Coast)
Duration: Long Term W2
Experience and Education:
Responsibilities:
Must have 2+ years of experience as an Architect.
Uses analytical, data and SQL development skills to produce reports to support the Business in making data driven business decisions. Includes producing both ad-hoc and regularly scheduled reports. Reviews data to ensure validity.
Cloud - Azure experience required, Dev-Ops and CI/CD experience required.
Must have Data Bricks and ADF experience.
Provides analytical support for initiatives, including business function support for system migrations and consolidations, business area process improvement projects, and product installations.
Leads system requirements definition, design, testing, training and implementation support. Applies use of tools to define requirements and documentation.
Develops and/or reviews departmental business system requirements and business systems design documents, customer acceptance test plans, and post-implementation plans.
Works directly with external customers in implementing new reporting capabilities, systems enhancements and technology.
Provides analysis of efficiencies related to system enhancements/automation.
Developing use cases and test cases.
Executes system testing.
Facilitates and support user acceptance testing.
Required Skills:
1 plus years of experience in hands-on with SSIS, SSRS, SSAS design.
5 plus years of experience in SQL development-developing and designing.
Applications and/or reports on SQL server 2014.
Cloud / Azure experience.
DevOps and CI/CD experience.
Native Azure SQL Development required.
DataBricks experience required.
Azure Data Factory ADF required.
Healthcare – Managed Care experience required
Job Type: Contract
Salary: $80.23 - $90.61 per hour
Schedule:
8 hour shift
Experience:
Managed care: 10 years (Required)
Health Care: 10 years (Required)
Azure: 10 years (Preferred)
Architect: 4 years (Preferred)
Databricks/ADF: 5 years (Required)
Work Location: Remote
Show Less
Report",4.6,51 to 200 Employees,2013,Company - Private,Information Technology Support Services,Information Technology,$1 to $5 million (USD)
Data Migration Architect,-1,Viviente Software,"Floresville, TX",-1,4.6,-1,-1,-1,-1,-1,-1
Data Modeler,$50.00 - $55.00 Per Hour (Employer est.),Snapana technologies,"San Francisco, CA",-1,4.6,-1,-1,-1,-1,-1,-1
Data Engineer,$100K - $160K (Employer est.),Effectual4.2 ★,Remote,"Position Summary
The Data Engineer builds pipelines that are used to transport date from a data source to a data warehouse. These pipelines are crucial: they are what enable an organization to access and analyze its data and use the insights to make business decisions. Data pipelines transport and transform data according to established business rules or a line of exploratory analysis the business wants to undertake. The Data Engineer prepares and organizes the data that organizations have built in their databases and other formats.
A Glimpse into the Daily Routine of a Data Engineer
A day in the life of a Data Engineer starts with building and delivering high quality data architectures and pipelines that support clients, business analysts, and data scientists. A Data Engineer also interfaces with other technology teams to extract, transform, and load [ETL] data from a wide variety of data sources. Effectual Data Engineers continually improve ongoing reporting and processes, as well as automate or simplify self-service for our clients. Effectual Data Engineers develop, code, and deploy scripts written in the Python programming language, as Python is the language of Data. All Data Engineers are first and foremost Software Engineers with an understanding of the SDLC process.
Essential Duties and Responsibilities
Develop, construct, test and maintain data architectures from the data architect
Analyze organic and raw data
Build data systems and pipelines
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS 'big data' technologies
Develop code and scripts for data architects, data scientists, and data quality engineers
Data acquisition
Identify ways to improve data reliability, efficiency, and quality
Develop data-set processes
Prepare data for prescriptive and predictive modeling
Automate the data collection and analysis processes, data releasing and reporting tools
Build algorithms and prototypes
Develop analytical tools and programs
Collaborate with data scientists and architects on projects/efforts
Qualifications
Bachelor's or master's degree in Computer Science, Engineering or a related field
Proven experience working as a Data Engineer, preferably in a professional services or consulting environment
Strong proficiency in programming languages such as Python, Java, or Scala, with expertise in data processing frameworks and libraries (e.g., Spark, Hadoop, SQL, etc.)
In-depth knowledge of database systems (relational and NoSQL), data modeling, and data warehousing concepts
Experience with cloud-based data platforms and services (e.g., AWS, Azure, Google Cloud) including familiarity with relevant tools and technologies (e.g., S3, Redshift, BigQuery, etc.)
Proficiency in designing and implementing ETL processes and data integration workflows using tools like Apache Airflow, Informatica, or Talend
Familiarity with data governance practices, data quality frameworks, and data security principles
Strong analytical and problem-solving skills, with the ability to translate business requirements into technical solutions
Excellent communication and collaborations skills, with the ability to effectively work with clients and cross-functional teams
Self-motivated and proactive, with a passion for learning and staying updated with the latest trends and advancements in the field of data engineering
Able to work with ambiguity and turn client wants and needs into working stories, epics which can be executed upon during a sprint. This means Data Engineers understand and know the 'agile' progress software delivery
A firm understanding of the SDLC process
An understanding of object-oriented programming
Needs minimal direction
AWS background
Solution Engineer mindset
Nice-to-Have Skills and Experience
A curious nature and inquisitive attitude when approaching problems
Have the attitude of 'good is not good enough' for our clients
Snowflake or Databricks certifications and/or hands-on-keyboard experience
Company Offered Benefits
Full-time employees are eligible to participate in our employee benefit programs:
Medical, dental, and vision health insurances,
Short term disability, long term disability and life insurances,
401k with Company match
Paid time off (PTO) (120 hours PTO that accrue over one year)
Paid time off for major holidays (14 days per year)
These and any other employee benefit offerings are subject to management's discretion and may change at any time.
Physical Demands and Work Environment
The work is generally performed in an office environment. Physical demands include sitting, keyboarding, verbal communication, written communication. Employees are occasionally required to stand; walk; reach with hands and arms; climb or balance; and stoop, kneel, crouch, or crawl. The physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this position. Reasonable accommodation may be made to enable individuals with disabilities to perform the functions.
Salary Range for this position: $100,000-$160,000
CA ID IT10000003
""Salary ranges provided are for informational purposes only and may vary depending on factors such as experience, qualifications, and geographic location. The final salary offer will be determined based on the candidate's skills and alignment with the role requirements.""
This job description may not be inclusive of all assigned duties, responsibilities, or aspects of the job described, and may be amended anytime at the sole discretion of the Employer. Duties and responsibilities are subject to possible modification to reasonably accommodate individuals with disabilities. To perform this job successfully, the incumbents will possess the skills, aptitudes, and abilities to perform each duty proficiently. This document does not create an employment contract, implied or otherwise, other than an ""at will"" relationship. Effectual Inc. is an EEO employer and does not discriminate on the basis of any protected classification in its hiring, promoting, or any other job-related opportunity.
Show Less
Report",4.2,201 to 500 Employees,2018,Company - Private,Information Technology Support Services,Information Technology,Unknown / Non-Applicable
Database Administrator,$66K - $135K (Employer est.),NextRow Digital4.2 ★,Remote,"Database Administrator
Remote Work
Duration: Long Term
Rate: DOE
Maintains data storage and access by evaluating, designing and implementing company database[s].
Identifies data sources, constructs data decomposition diagrams, provides data flow diagrams and documents the process.
Writes codes for database access, modifications and constructions.
Relies on established guidelines and instructions to perform daily job functions.
Works under immediate supervision and usually reports to a manager.
Full-time professional work experience in Software Development, Maintenance, or Implementation.
May require a bachelor's degree in a related area and at least 2 years or equivalent experience in the field or in a related area. Substitutions:
Two (2) years of work experience as a Data Administrator ; Data Warehousing Administrator ; Data Architect ; Database Analyst-Intermediate ; Data Warehousing Analyst may substitute for all of the required experience.
*
Job Type: Contract
Salary: $65,715.18 - $134,727.87 per year
Schedule:
8 hour shift
Experience:
MySQL: 5 years (Preferred)
Database administration: 5 years (Preferred)
Oracle: 5 years (Preferred)
Work Location: Remote
Speak with the employer
+91
Show Less
Report",4.2,51 to 200 Employees,2008,Company - Private,Information Technology Support Services,Information Technology,$5 to $25 million (USD)
Data Engineer,$75K - $103K (Glassdoor est.),Zions Bancorporation3.6 ★,"Midvale, UT","Zions Bancorporation’s Enterprise Technology and Operations (ETO) team is transforming what it means to work for a financial institution. With a commitment to technology and innovation, we have been providing our community, clients and colleagues the best experience possible for over 150 years. Help us transform our workforce of the future, today.

As a Data Engineer , you’ll provide your talents in contributing to the success of the Zions team by delivering all aspects of the software development lifecycle, including design, coding, integration testing, deployment, operations support, and documentation using Agile methodologies. Also, able to work independently, collaborate with cross-functional teams on technical understanding, handle multiple concurrent projects, with an ability to prioritize and manage projects effectively with changing priorities.

Responsibilities:
Partner with architects, engineers, information analysts, business, and technology stakeholders for developing and deploying enterprise grade platforms that enable data-driven solutions.
Enthusiasm and strong desire to learn and grow within the organization.
Demonstrate strong analytical, organizational, and problem-solving skills.
Strong focus on long-term strategy, application stability, refactoring, and re-usability.
Analyzes and designs technical solutions to address business needs.
Develops, tests, and modifies software to improve efficiency of data platforms and applications.
Identifies, investigates, and proposes solutions to technical problems.
Coordinate with data operations teams to deploy changes into production.
Serve in the goalie rotation to support Test, QA, and Production environments.
Other duties as assigned

Qualifications:
3+ years of experience in programming languages like Python, orchestration tools and processes.
Exposure in RDD’s with Python/Scala using Spark framework.
4+ years of experience in ETL (IBM Datastage preferred), SQL, UNIX/Linux scripting, and Big Data distributed systems.
Extensive experience in data migration, data analysis, data transformations, conversion, interface, large volume data loading (ETL techniques), database modeling, and performance SQL tuning.
Experience in building ETL pipelines using Python pandas
Experience working with cloud or on-prem Big Data/MPP analytics platform like Google BigQuery, Azure Data Warehouse, or similar
Experience in leveraging database tools to develop DDL scripts, stored procedures, and functions to create and alter database objects.
Experience working with Greenplum, Oracle, SQL Server, DB2, Teradata, Hive and delimited text files would be helpful.
Requires a Bachelor's in Computer Science, Computer Engineering, or related field. A combination of education and experience may meet qualifications.

Preferred skills:
Experience with designing and implementing real-time ETL pipelines
Experience with data pipeline automation and CI/CD tools like Jenkins
Hands on experiences with Git version control processes, data streaming technologies such as Kafka, and unstructured data handling preferred .

Location:
This position has a hybrid work from home schedule with a minimum of three days per week in the office at the new Zions Technology Center in Midvale, UT.

The Zions Technology Center is a 400,000-square-foot technology campus in Midvale, Utah. Located on the former Sharon Steel Mill superfund site, the sustainably built campus will be the company’s primary technology and operations center. This modern and environmentally friendly technology center will enable Zions to continue to compete for the best technology talent in the state while providing team members with an exceptional work environment with features such as:

Electric vehicle charging stations and close proximity to Historic Gardner Village UTA TRAX station.
At least 75% of the building is powered by on-site renewable solar energy.
Access to outdoor recreation, parks, trails, shareable bikes and locker rooms.
Large modern cafe with a healthy and diverse menu.
Healthy indoor environment with ample natural light and fresh air.
LEED-certified sustainable building that features include the use of low VOC-emitting construction materials.

Benefits:
Medical, Dental and Vision Insurance - START DAY ONE!
Life and Disability Insurance, Paid Parental Leave and Adoption Assistance
Health Savings (HSA), Flexible Spending (FSA) and dependent care accounts
Paid Training, Paid Time Off (PTO) and 11 Paid Federal Holidays
401(k) plan with company match, Profit Sharing, competitive compensation in line with work experience
Mental health benefits including coaching and therapy sessions
Tuition Reimbursement for qualifying employees
Employee Ambassador preferred banking products

Apply now if you have a passion for impactful outcomes, enjoy working collaboratively with co-workers, and want to make a difference for the clients and communities we serve.
Apply Now: click Apply Now
Show Less
Report",3.6,10000+ Employees,1955,Company - Public,Banking & Lending,Financial Services,$1 to $5 billion (USD)
Database Architect,$125K (Employer est.),iQuasar LLC4.6 ★,Remote,"Responsibilities:
Senior Level Experience in design and data modeling in MS SQL.
Must be comfortable writing complex stored procedures, functions, triggers, and CTE’s and PIVOT statements
Must be proficient with using JSON and SQL’s JSON tools.
Must be comfortable working in both relational and an entity attribute value database models
Must be proficient in query tuning and optimization.
Able to work well in a remote setting
Strong attention to detail
Understanding of Agile methodologies
Must have excellent written and verbal communication skills
Preferred:
Write clean, scalable code using .NET programming languages
Remain up to date with the terminology, concepts, and best practices for coding mobile apps
Use and adapt existing web applications for apps
Develop client displays and user interfaces
Assist software personnel in handling project related work and other requirements
Coordinate with other software professionals and developers
Familiarity with the ASP.NET framework, MS SQL (T-SQL) and design/architectural patterns (e.g. Model-View-Controller (MVC)
5 years of development experience using C# .NET
Knowledge of HTML5/CSS3/Bootstrap/jQuery.
Familiarity with architecture styles/APIs (REST, RPC)
Familiarity with GIT source control
Job Type: Full-time
Salary: Up to $125,000.00 per year
Schedule:
Day shift
Application Question(s):
Are you a US Citizen?
Experience:
C#: 5 years (Required)
MVC: 4 years (Preferred)
PIVOT: 5 years (Required)
MySQL: 7 years (Required)
ASP.NET: 5 years (Required)
Work Location: Remote
Show Less
Report",4.6,1 to 50 Employees,2004,Company - Private,Information Technology Support Services,Information Technology,$1 to $5 million (USD)
Data Architect,$70.00 Per Hour (Employer est.),DiamondPick Private Limited4.5 ★,"Dallas, TX","Hi,
Greetings from Diamondpick..!!
Here is the Job Description for the below Job Opening, Please let me know your Interest!!.
Job Title: AWS Data Architect
Location: Dallas, TX (onsite)
Contract
Qualifications:
Bachelor's degree in Computer Science, Business Administration or equivalent educational or professional experience and/or qualifications.
5+ years of strong experience in data warehouse and reporting application development with solid understanding of advanced analytics concepts is required, with experience in distributed architectures and designing for scalability preferred.
Strong understanding of data modeling and data architecture Extensive experience in designing, developing, and delivering business intelligence solutions using. AWS Glue, AWS RedShift, Qlik Sense or Qlik View or other business intelligence and analytic platforms
Experience in dealing with multiple projects and cross-functional teams, managing multiple tasks/assignments with staggered due dates and deadlines through effective time management skills.
Ability to identify and communicate issues/risks applying technical and root cause analysis skills is a must.
Must be a self-motivated and Experience in dealing with multiple projects and cross-functional teams, managing multiple tasks/assignments with staggered due dates and deadlines through effective time management skills.
Ability to identify and communicate issues/risks applying technical and root cause analysis skills is a must.
Must be a self-motivated and Experience in dealing with multiple projects and cross-functional teams, managing multiple tasks/assignments with staggered due dates and deadlines through effective time management skills.
Ability to identify and communicate issues/risks applying technical and root cause analysis skills is a must.
Must be a self-motivated and pro-active analytics technical leader and possess strong decision making, problem solving and analytical skills.
Ability to work within an agile development environment.
Ability to work within an agile development environment.
Job Type: Contract
Salary: Up to $70.00 per hour
Benefits:
401(k)
Health insurance
Schedule:
8 hour shift
Supplemental pay types:
Bonus pay
Signing bonus
Experience:
Data modeling: 1 year (Preferred)
AWS: 1 year (Required)
Work Location: On the road
Show Less
Report",4.5,1001 to 5000 Employees,2018,Company - Private,HR Consulting,Human Resources & Staffing,Unknown / Non-Applicable
Data Modeler Architect,$87K - $126K (Glassdoor est.),HYR Global Source Inc4.7 ★,"Overland Park, KS","Greetings from HYR Global Sources Inc., We at HYR are looking for a great Data Architect: III (Senior) for one of our esteemed clients. If you’re planning a career move/wish to pursue this opportunity, please forward us your updated resume and your expected salary on W2.
Job Title - Data Architect: III (Senior)
Location - Dallas TX(2 days onsite) Open for Multiple Location
Tax Term (W2, C2C) - W2
Position Type(Contract/permanent) - Contract
Project Duration - 12 Months (Possibility of Extension/C2H)
Job Description:
This role will be part of a team focused on cloud transformation, modernising analytics platforms and improving agility. The role requires hands-on experience in building and managing analytics solutions in SnowFlake, Provide direction on adoption of Cloud technologies (Snowflake) and industry best practices in the field of data warehouse architecture and modelling.
Establish data architecture strategy, best practices, standards, and roadmap
Experience with data warehousing and data modeling techniques (Kimball, Lakehouse)
Engage with business stakeholders to understand strategic, tactical, and operational needs; translate business requirements to technical requirements
Build Data Flows mapping Source systems and Process flows.
Mentor team members on best practices, efficient implementations and delivering high quality data products
Assemble large, complex data sets that meet non-functional and functional business requirements
Build Data Warehouse Architecture including Data Ingestion, Transformation, Security, and Aggregate layers
Initiate and facilitate continuous process improvements including re-designing infrastructure for greater scalability, optimising data delivery, and automating manual processes
Perform code reviews and assist developers in optimisation and troubleshooting.
Review the architectural/ technological solutions for ongoing projects and ensure right choice of solution
Expertise in Snowflake advanced concepts like setting up resource monitors, RBAC controls, virtual warehouse sizing, query performance tuning, Zero copy clone, time travel and understand how to use these features
Knowledge in AWS and management technologies such as S3.
Strong written communication skills
Is effective and persuasive in both written and oral communication
Education: Bachelor degree in Computer Science, Information Systems, or closely related field of study
Show Less
Report",4.7,51 to 200 Employees,2013,Company - Private,Information Technology Support Services,Information Technology,Unknown / Non-Applicable
Data Architect,-1,ShyftLabs3.5 ★,Remote,"Position Overview:
ShyftLabs is searching for a versatile and resourceful Data Architect with 5+ years of experience. ShyftLabs is a growing data product company that was founded in early 2020 and works primarily with Fortune 500 companies. We deliver digital solutions built to help accelerate the growth of businesses in various industries, by focusing on creating value through innovation.

The ideal candidate will have expertise in designing and developing complex, scalable client-facing solutions using serverless cloud technologies. This person wants to be part of building something new with great visibility across the enterprise companies and endless possibilities ahead as we continue to grow and scale.

You have experience with data as a product, and the systems that produce and underpin those products including data lakes, data pipelines, governance, and analytics. You can fine-tune for viability, performance, scalability, and resilience. You have direct experience and insights into the benefits and downsides of different data storage and transformation technologies and governance.

Job Responsibilities:
Design, architect, implement and support simple to complex enterprise data warehouses using on-premises and cloud technologies.
Lead and provide oversight into the design of end-to-end data solutions including data architecture, data integration, data modeling, security, privacy, regulatory, performance, data governance, business intelligence, etc. and to ensure alignment to the overall business needs.
Identify and articulate technical and operational requirements for data pipelines and the models they populate; be able to optimize these pipelines for high-performance/resiliency workloads.
Experiment with, recommend, and collaborate with other team members to develop and enhance the technology stack.

Basic Qualification:
5+ years of experience in data Engineering/ analytics or related field.
Expertise in Python and SQL.
Experience with Modern Data Stack.
Experience with Workflow management and automation like Airflow, Composer, DBT, Spark, etc.
Experience working with a Data Warehouse platform, Snowflake, and Big Query.
Experience with AWS and GCP Cloud Infrastructure.

Preferred Qualification:
DBA experience on other platforms.
Scripting or general programming experience.

We are proud to offer a competitive salary alongside a strong healthcare insurance and benefits package. The role is able to be fully remote within the United States. We pride ourselves on the growth of our employees, offering extensive learning and development resources.
ShyftLabs is an equal-opportunity employer committed to creating a safe, diverse and inclusive environment. We encourage qualified applicants of all backgrounds including ethnicity, religion, disability status, gender identity, sexual orientation, family status, age, nationality, and education levels to apply. If you are contacted for an interview and require accommodation during the interviewing process, please let us know.
Show Less
Report",3.5,1 to 50 Employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable
Data Warehouse Architect - Remote US,$60K - $100K (Employer est.),SitusAMC3.4 ★,Remote,"SitusAMC is where the best and most passionate people come to transform our client’s businesses and their own careers. Whether you’re a real estate veteran, a passionate technologist, or looking to get your start, join us as we work together to realize opportunities for everyone, we proudly serve.

At SitusAMC, we are looking to match your unique experience with one of our amazing careers, so that we can help you realize your potential and career growth within the Real Estate Industry. If you are someone who can be yourself, advocate for others, stay nimble, dream big, own every outcome, and think global but act local – come join our team!

Position Overview:
This role is responsible for the construction, implementation, and ongoing delivery of the company’s enterprise business intelligence strategy. The strategy includes the formation of a centralized data lake sourced from numerous operational SQL and MySQL systems, supplemental text files, and other sources to support real-time SSRS reporting across systems. The data lake will also be the source of a centralized data warehouse for the organization and combined with a Tableau business intelligence tool. This position will help build the data lake and data warehouse, build data marts, manage the data governance, and expand the availability of data throughout the organization. This position partners closely with the centralized reporting and analytics teams, and the centralized ETL team, to insure the availability, consistency, and efficiency of data.

Essential Job Functions:
Partner with business and technology team members to design and build an enterprise data lake and data warehouse

Work with business and technology leaders to draw out data and architectural requirements

Implement data warehousing and data governance best practices

Assist in the creating embedded analytics across internally and externally facing web-based portals

Promote the usage of data and business intelligence across the organization, including demonstrating capabilities, collaborating with other technology teams, and consulting with business leaders

Mentor staff

Such other activities as may be assigned by your manager
Qualifications/ Requirements:
Four-year college degree or equivalent combination of education and experience
2+ years data warehousing (data modeling, scripting stored procedures, security), preferably in a SQL environment
2+ years enterprise reporting and business intelligence
2+ years building business intelligence and embedded analytics, preferably with Tableau
2 to 4 years working with data engineering platforms
Knowledge of commercial and/or residential finance preferred
Experience with Agile Methodologies and SDLC
Strong time management and communication skills (written and oral)
Strong analytical ability, good judgment; strategic and multidimensional thinker
Detail oriented, organized; prompt and regular attendance is required
Continuous learner; excitement in personal growth and development
Strong commitment and dedication to the position and a Team Player
Special Requirements:
The employee may be required to report to a different local office as a normal, contemplated, and mandated incident of their employment
Working Conditions:
Office environment with frequent computer, mouse, keyboard use
Alternating between sitting or standing as needed
Hearing, talking, reaching, grasping
#LI- AS1 #LI-REMOTE

Note: This job description is not intended to be all inclusive or exclusive. At any time, employees may perform other related duties as required to meet the ongoing needs of the organization and participate in additional trainings.

SitusAMC is an Equal Opportunity Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, age, sex, national origin, disability, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state, or local laws.

EEO is the Law

SitusAMC does not accept unsolicited resumes from staffing agencies, search firms or any third parties. Any unsolicited resume submitted to SitusAMC in any manner will be considered SitusAMC property, and SitusAMC will not pay a fee for any placement resulting from the receipt of an unsolicited resume.

Remote, RE, USA

USA

The annual full time base salary range for this role is ($60,000 - $100,000). Specific compensation is determined through interviews and a review of relevant education, experience, training, skills, geographic location and alignment with market data. Additionally, certain positions may be eligible to receive a discretionary bonus as determined by bonus program guidelines, position eligibility and SitusAMC Senior Management approval. SitusAMC offers PTO and paid holidays, the terms of which are set forth in the program policies. All full time employees also are eligible to participate in various benefit plans, including medical, dental, vision, life, disability insurance and 401K; in each case in accordance with the terms of the applicable plans.
Show Less
Report",3.4,5001 to 10000 Employees,1984,Company - Private,Real Estate,Real Estate,Unknown / Non-Applicable
AWS Data Architect,$61.05 - $73.52 Per Hour (Employer est.),Synapseb systems,"Raleigh, NC","Kite PharmaAWS data Architect
Position: C2C
Location: Santa Monica, CA or Raleigh, NC. (Hybrid – 3 day of week onsite) Onsite from day one of joining
Client: Virtusa/Kite Pharma
Need 10+ years candidate
Passport number is mandatory
Candidate must have 10+ years of IT working experience with at least 5 years of experience on AWS Cloud environment is preferred
Experience and knowledge of AWS Cloud Architectures, Databases, Data models and Data integration patterns.
Conduct data profiling activities, discover data quality challenges, document the impacts to business and make recommendations for data quality improvements
Expertise in defining new architectures and ability to drive project from architecture standpoint with AWS Cloud platform.
Experience with Ingestion & Transformation framework development and enhancements
Define and design Data pipeline architecture for data ingestion processes using AWS native services.
Design and optimize data models on AWS Cloud using AWS data stores such as Redshift, RDS, S3, Glue Data Catalog, Python, Lake formation, etc
Collaborate with different teams to ensure quality and compliance to the Enterprise Data Architecture by participating in data analysis/design activities and conducting appropriate technical data design reviews at various stages during the development life cycle. This includes providing data modelling expertise with both relational and dimensional modelling techniques.
Guide, educate, and mentor the Data Architecture Strategy directives, principles, & standards to individuals who play data-related roles (e.g., data analysts, ETL developers, report developers & business analysts).
Establish and maintain data standards, policies, and architectures.
Provide direction, guidance, and oversight for data quality controls.
Identify opportunities for standardizing data descriptions, integration and archiving, and elimination of unnecessary redundancy.
Capture and maintain metadata, creating business rules for the use of data
Design and optimize data governance framework including the management of data, operating model, data policies and standards.
Participate in client design workshops and provide trade-offs and recommendations towards building solutions.
Collaborating with teams to resolve technical requirements, feasibility, and expectations.
Mentor Data engineers in coding best practices and problem solving.
Working experience with Agile Methodology
Experience working with source code management tools such as GitHub
Experience working with Jenkins or any CI/CD Pipelines using AWS Services
Job Type: Contract
Salary: $61.05 - $73.52 per hour
Schedule:
8 hour shift
Ability to commute/relocate:
Raleigh, NC 27601: Reliably commute or planning to relocate before starting work (Required)
Experience:
AWS data Architect: 10 years (Preferred)
Work Location: Hybrid remote in Raleigh, NC 27601
Show Less
Report",-1,51 to 200 Employees,-1,Company - Public,-1,-1,Unknown / Non-Applicable
Technology Architect Senior - Data Platforms,$86K - $115K (Glassdoor est.),Arkansas Blue Cross and Blue Shield4.1 ★,"Little Rock, AR","To learn more about Arkansas Blue Cross and Blue Shield Hiring Policies, please click
here
.
Arkansas Blue Cross is only seeking applicants for remote positions from the following states:
Arkansas, Florida, Georgia, Illinois, Kansas, Louisiana, Minnesota, Mississippi, Oklahoma, South Carolina, Tennessee, Texas, Virginia and Wisconsin.
Workforce Scheduling
Flex
Job Summary
The Technology Architect Senior - Database is responsible for Planning and Design of the enterprise technology solutions and processes, with a specialized focus on database architecture.
Requirements
EDUCATION
Bachelor’s degree in Business, Computer Science, Management Information Systems, Computer Engineering, or related field. In lieu of degree, five (5) years’ related experience will be considered.
LICESNING/CERTIFICATON
Professional level IT Certification in a relevant area of expertise or other similar credentials required.
EXPERIENCE
Minimum five (5) years’ IT operations experience with complex system technology.
Experience with architecting platforms / systems required.
Project management experience required.
Familiarity with automation tooling required.
Technical drawing (schematics) and documentation experience required.
Short and long-term technology planning experience required.
Capacity monitoring and planning experience required.
IT lifecycle management experience required.
Expert knowledge of at least one (1) common Information Technology management frameworks, such as HITRUST, ITIL, or TOGAF required.
In depth knowledge of enterprise systems, networking, and integrations required.
Excellent knowledge of computer hardware and networking systems required.
Knowledge of ITIL Service Design and Continual Service Improvement processes required.
Value stream mapping experience preferred.
Experience prototyping and evaluating technical solutions against KPIs and Business requirements preferred.
ESSENTIAL SKILLS & ABILITIES
Detail Oriented
Critical Thinking
Analytical
Problem Solving
Ingenuity
Project Management
Leadership
Oral & Written Communication
Ability to problem solve complex IT issues and processes.
Ability to see big-picture designs from basic specifications.
Ability to build collaborative relationships.
Ability to articulate complex technology solution concepts to a wide variety of stakeholders.
Ability to work collaboratively with other technology architects, Enterprise Architects, I/O Teams, and business stakeholders.
Skills
Responsibilities
Collaborates with multiple teams within I/O, and other areas of the business in efforts to plan, design, and document technology-based services and infrastructure architectures that meet business objectives and add value to the enterprise., Continually seeks areas of improvement within technologies and drives the reduction of technical debt through participating in technology selection processes and providing subject matter expertise., Designs solution architectures that meet business needs., Ensures CSI processes are performing well, and that feedback is evaluated and integrated as appropriate., Focuses efforts on business relationships that build trust with the I/O organization., Leads continual service improvement efforts around designed services and solutions., Participates in evaluations, proof of concept work, and solution prototyping of services and technologies., Participates in the creation of architectural roadmaps for multiple technology platforms, and in the creation of reference architectures and standards., Participates in the design and documentation of ITIL based processes for use within I/O and business units., Participates in the design and maintenance of Service Lifecycle processes., Participates in the design of IT Services and documentation that meet the needs of Upstream / Downstream teams., Performs high-level capacity planning and management methodologies for technical platforms and services., Provides architectural leadership in the identification of new technology partnerships., Supports project management efforts to drive strategic initiatives., Supports technical planning for BC/DR efforts around major platforms and services.
Certifications
Security Requirements
This position is identified as level three (3). This position must ensure the security and confidentiality of records and information to prevent substantial harm, embarrassment, inconvenience, or unfairness to any individual on whom information is maintained. The integrity of information must be maintained as outlined in the company Administrative Manual.
Segregation of Duties
Segregation of duties will be used to ensure that errors or irregularities are prevented or detected on a timely basis by employees in the normal course of business. This position must adhere to the segregation of duties guidelines in the Administrative Manual.
Employment Type
Regular
ADA Requirements
1.1 General Office Worker, Sedentary, Campus Travel - Someone who normally works in an office setting or remotely and routinely travels for work within walking distance of location of primary work assignment.
To apply to this job, click Apply Now
Show Less
Report",4.1,1001 to 5000 Employees,1948,Company - Private,Insurance Carriers,Insurance,$1 to $5 billion (USD)
Data Analyst,$82K - $133K (Employer est.),Effectual4.2 ★,Remote,"Position Summary
An Effectual Data Analyst gathers, cleans, and studies data sets to help solve problems. Data Analysts support operations and conduct data analytics projects to provide information and insights for stakeholders for decision-making or solution development. They implement data standards and deploy automation tools to extract, synthesize, and validate data from different sources and transform data into usable metrics. Data Analysts construct data sets, monitor data quality, troubleshoot, and resolves database issues to ensure data integrity. Utilizes scripting and querying tools like Python, R or SQL, data visualization/Bl tools, statistical methods, and data modeling to produce reports, data files, and dashboards. Data analysts have the knowledge and skills to turn raw data into information and insight.
A Glimpse into the Daily Routine of a Data Analyst
A ""typical"" day in the life of a data analyst might include:
Gather data: Analysts often collect data themselves. This could include conducting surveys, tracking visitor characteristics on a company website, or utilizing open-source data sets that are freely available.
Clean data: Raw data might contain duplicates, errors, or outliers. Cleaning the data means maintaining the quality of data in a spreadsheet or through a programming language so that your interpretations won't be wrong or skewed.
Model data: This entails creating and designing the structures of a data set. You might choose what types of data to store and collect, establish how data categories are related to each other, and work through how the data appears.
Interpret data: Interpreting data will involve finding patterns or trends in data that will help you answer the question at hand.
Present: Communicating the results of your findings will be a key part of your job. You do this by putting together visualizations like charts and graphs, writing reports, and presenting information to interested parties.
Essential Duties and Responsibilities
Analyzing data using statistical techniques and providing reports
Filtering and cleaning data
Designing and maintaining data systems and databases; including fixing coding errors and other data-related problems
Acquiring and mining data from the primary and secondary resources, then organizing the data in a format that can be easily read by human or machine
Using statistical tools to interpret data sets, paying particular attention to trends and patterns that could be valuable for diagnostic and predictive analytics efforts
Create presentations and reports based on recommendations and findings
Preparing reports for executive leadership that effectively communicate trends, payers and predictions using relevant data
Collaborating with developers, engineers, architects, and organizational leaders to identify opportunities for process improvements, recommend system modifications, and help develop policies for data governance
Creating appropriate documentation that allows stakeholders to understand the steps of the data analysis process and duplicate or replicate the analysis if necessary
Qualifications
Bachelor's or Master's degree in a relevant field, such as Data Science, Computer Science, Statistics, or Mathematics
3-5 years of experience as a Data Analyst or similar role in professional services or consulting firm
Strong programming skills in languages such as Python or R
Experience with SQL and database management
Knowledge of data warehousing concepts and data integration techniques
Familiarity with data visualization tools, such as Tableau, Power BI, or Qlik
Excellent problem-solving and critical-thinking abilities
Strong communication and presentation skills, with the ability to convey complex information to non-technical stakeholders
Ability to work independently and collaborate effectively in a team-oriented environment
Attention to detail and a commitment to delivering high-quality results within tight deadlines
AWS skills (AWS Cloud Practitioner cert is a must)
Needs minimal direction
Can handle and work within an environment with high ambiguity
Nice-to-Have Skills and Experience
AWS Certified Data Analytics Specialty
Company Offered Benefits
Full-time employees are eligible to participate in our employee benefit programs:
Medical, dental, and vision health insurances,
Short term disability, long term disability and life insurances,
401k with Company match
Paid time off (PTO) (120 hours PTO that accrue over one year)
Paid time off for major holidays (14 days per year)
These and any other employee benefit offerings are subject to management's discretion and may change at any time.
Physical Demands and Work Environment
The work is generally performed in an office environment. Physical demands include sitting, keyboarding, verbal communication, written communication. Employees are occasionally required to stand; walk; reach with hands and arms; climb or balance; and stoop, kneel, crouch, or crawl. The physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this position. Reasonable accommodation may be made to enable individuals with disabilities to perform the functions.
Salary Range for this position: $81,500-$132,600
CA ID: IT10000704 ""Salary ranges provided are for informational purposes only and may vary depending on factors such as experience, qualifications, and geographic location. The final salary offer will be determined based on the candidate's skills and alignment with the role requirements.""
This job description may not be inclusive of all assigned duties, responsibilities, or aspects of the job described, and may be amended anytime at the sole discretion of the Employer. Duties and responsibilities are subject to possible modification to reasonably accommodate individuals with disabilities. To perform this job successfully, the incumbents will possess the skills, aptitudes, and abilities to perform each duty proficiently. This document does not create an employment contract, implied or otherwise, other than an ""at will"" relationship. Effectual Inc. is an EEO employer and does not discriminate on the basis of any protected classification in its hiring, promoting, or any other job-related opportunity.
Show Less
Report",4.2,201 to 500 Employees,2018,Company - Private,Information Technology Support Services,Information Technology,Unknown / Non-Applicable
"Director, IT Data Integration",$159K - $180K (Employer est.),Panoramic Health2.6 ★,"Tempe, AZ","The Director of Data Integration is responsible for leading a team of data engineers, data modelers, data analysts and data architects in supporting data integration activities with external and internal partners. This includes delivering all data acquisition efforts from nationally recognized HIE’s, EMR practices, and other clinical data sources to support analytic and reporting needs across Panoramic Health business and migrate data integration activities to Azure based Databricks platform.

Director is responsible for overall delivery of data integration efforts in collaboration with product management, infrastructure, and other business partners as needed. This includes managing the day-to-day delivery of the integration activities to meet the short term and long-term needs of the business. The Director takes a leadership role in setting team vision and direction, ensures standards and policies are maintained and systems and solutions are compatible with standard data integration architecture, tools, policies, and procedures.
To be successful in the role, you need a “get things done” mindset with the ability to make quick decisions scope and prioritize activities based on dynamic business and customer needs. The ideal candidate has a passion for improving healthcare, proven ability to see the big picture, customer service focus, and solution-oriented mindset.

This position can work remotely and person can live anywhere in the United States.

Duties and Responsibilities
(List the job's essential or primary duties and responsibilities. Duties are prioritized according to their importance and/or the frequency performed. Note: Duties and responsibilities are functions of the job and should not reflect the special talents or performance of an employee).
Develop and execute continuously improve the data integration and data warehouse technology strategy, in alignment with overall business strategy, and product roadmap.
Develop and execute a modern cloud-based data architecture to support the organization’s current and future needs.
Collaborate with Business Owners and Product Manager to prioritize, design, and develop technical solutions to automate and streamline businesses processes in the organization.
Provide technical guidance and recommendations for enterprise data needs.
Provides production support which includes operating and/or supporting change management, release management, system monitoring and incident response.
Manage capacity and spend management across data integration activities.
Participates in activities to improve departmental and organizational performance.
Performs other duties, as assigned.
Be champion for agile software application development and change management practices.
Set best practices in database design and analytics development processes; setup code reviews & technical design sessions, writing and reviewing technical design specifications.
Define the Data Solutions platform architecture and integration with analytics tools. Spearhead the development of robust, reusable, and scalable Data solutions platform
Functional and Technical Competencies
(Specialized skills, knowledge and abilities required to perform the essential functions of the role)
Experience working with and presenting to the executive leadership team, clients, and board of directors.
Experience working in fast-paced medium-sized organizations.
Track record of using data to drive decision making, create compelling business cases, and report on success metrics.
Project management experience with responsibility to ensure that multiple projects are completed within time and budget.
Experience with agile methodologies and project tracking-collaboration software.
Experience managing in a cloud-based data management platform.
Knowledge of HIPAA, and healthcare data security practices
Education/Training and Certification, Licensure, Registration Requirements
(Minimum level of education necessary to perform the essential job duties. Please only consider the basic job requirement for knowledge.)
Bachelors degreeis computer science or relevant field
Knowledge of HIPAA, and healthcare data security practices
Experience
(Minimum number of years of relevant experience required to perform the essential functions of the role.)
Bachelor's degree strongly preferred in Information Technology or equivalent work experience.
8+ years of experience in data domain, in a healthcare industry preferred.
5+ years of experience leading data engineering teams and implementing data warehousing platform using industry standard patterns and Ralph Kimball or Bill Inman approach.
5+ years of experience in software development, preferably with a combination of big and small company environments.
5+ years of experience in Data Integration, Data Warehousing, and Data Architecture roles.
2+ years in Healthcare - Provider and/or Payer experience.
Environment and/or Physical Factors
(Work environment characteristics and physical demands that are representative of those which an employee encounters while performing the essential functions of the role.)
Prolonged periods sitting at a desk and working on a computer.
Must be able to lift up to 15 pounds at a time.
#LI-Remote

This role has a salary range of $159,000 to $180,000 and regular, full-time employees working 30 or more hours per week are eligible for comprehensive benefits including Medical, Dental, Vision, Life, 401(K), Paid time off (PTO).

The Company is committed to the principles of equal employment. We are committed to complying with all federal, state, and local laws providing equal employment opportunities, and all other employment laws and regulations. It is our intent to maintain a work environment which is free of harassment, discrimination, or retaliation because of age, race, color, national origin, ancestry, religion, sex, pregnancy (including childbirth, lactation and related medical conditions), physical or mental disability, genetic information (including testing and characteristics), veteran status, uniformed servicemember status, or any other status protected by federal, state, or local laws. The company is dedicated to the fulfillment of this policy in regard to all aspects of employment, including but not limited to recruiting, hiring, placement, transfer, training, promotion, rates of pay, and other compensation, termination, and all other terms, conditions, and privileges of employment

For information about our Privacy Policy, please visit here
Show Less
Report",2.6,1001 to 5000 Employees,2012,Company - Private,Health Care Services & Hospitals,Healthcare,Unknown / Non-Applicable
AWS Data Architect,$70.00 - $75.00 Per Hour (Employer est.),Hire Force Global,Remote,-1,2.6,-1,-1,-1,-1,-1,-1
Data Engineer / Architect,$50.00 - $51.00 Per Hour (Employer est.),Business Integra Inc3.8 ★,Remote,"Role: Data Engineer / Architect
Location: - Remote
Contact
Experience level: 7+ years
Required skills:
- Shell Scripting
- SQL, Python, Certificate Management
- Delphix, Genrocket, TDM
Job Description:
The Data Architect works in all data environments which includes data design, database architecture, metadata and repository creation. The Data Architect work assignments are varied and frequently require interpretation and independent determination of the appropriate courses of action.The Data Architect responsible for developing blueprints for all data repositories, evaluating hardware and software platforms, and integrating systems. Translates business needs into long-term data architecture solutions. Defines, designs and builds dimensional database schemas. Evaluates reusability of current data for separate analyses. Conducts data sheering to rid the system of old, unused or duplicate data. Reviews object and data models and the metadata repository to structure the data for better management and quicker access. Understands department, segment, and organizational strategy and operating objectives, including their linkages to related areas. Makes decisions regarding own work methods, occasionally in ambiguous situations, and requires minimal direction and receives guidance where needed. Follows established guidelines/procedures.
Required Qualifications
Bachelor's degree in computer science, Information Technology or related field
Less than 5 years of technical experience
Operational Data Integration for real-time APIs
Big Data Integration & Analytics
Must be passionate about contributing to an organization focused on continuously improving consumer experiences.
Preferred Qualifications
Master's Degree
Job Type: Contract
Salary: $50.00 - $51.00 per hour
Schedule:
8 hour shift
Experience:
Informatica: 1 year (Preferred)
SQL: 1 year (Preferred)
Data warehouse: 1 year (Preferred)
Work Location: Remote
Show Less
Report",3.8,201 to 500 Employees,2001,Company - Private,Information Technology Support Services,Information Technology,$25 to $100 million (USD)
Software Architect (REMOTE),$100K - $150K (Employer est.),Dynata3.2 ★,"Maumee, OH","RESPONSIBILITES
Design and implement services and system architecture for your projects, and provide feedback to other team members
Help improve our code quality through writing unit tests, automation and performing code reviews
Participate in brainstorming sessions and contribute ideas to our technology, algorithms and products
Work with the product and design teams to understand end-user requirements, formulate use cases, and then translate that into a pragmatic and effective technical solution
Dive into difficult problems and successfully deliver results on schedule
REQUIREMENTS:
10+ years of general experience in software development
5+ years of experience in systems architecture, service-based architecture, or enterprise application architecture.
5+ years of experience developing cloud-based solutions in Azure, AWS, or GCP. AWS preferred. Relevant certifications are a plus.
Strong knowledge of domain driven design concepts.
Hands-on experience designing, implementing, and deploying APIs that scale to serve hundreds of millions of requests per day.
Strong knowledge of various API architectural styles such as REST, RPC, gRPC, SOAP, GraphQL, and pub/sub.
Working knowledge of OSI layer 4 and 7 networking protocols such as TCP, UDP, TLS, DNS, HTTP/1.1, HTTP/2, WebSocket, and AMQP.
Strong knowledge of application and data security principles and practices.
Able to work with a variety of programming languages such as C/++, Rust, Go, Java, Scala, Python, JavaScript, Swift, Objective-C, Kotlin, Groovy, and C#.
Strong knowledge of application observability using logs, traces, and metrics.
Familiarity with relational database design and normalization up to 3NF.
Hands-on experience with various NoSQL data stores such as document, graph, key-value, columnar, time series, or ledger.
Experience designing eventually consistent solutions using pub/sub messaging technologies.
Familiarity with deploying infrastructure as code.
BENEFITS:
Flexible work environment - hybrid (if near an office) or 100% remote
Work-life balance
Medical benefits, Retirement matching
Generous paid time off
Learning Management System available through the Intranet providing free access to nearly 500 online training modules and personal development programs
Dynata offers their new colleague the opportunity to work in an open and global culture, where they welcome feedback and ideas from their colleagues. You will be working in a challenging and inspiring environment with talented colleagues from all over the world.
We have great opportunities for growth and professional development.
And much more!
At Dynata, we are committed to fostering an inclusive, accessible environment, where all employees and customers feel valued, respected and supported. We are dedicated to building a workforce that reflects the diversity of our customers and communities in which we live and serve. Dynata welcomes and encourages applications from people with disabilities. We are committed to an inclusive work culture for all our employees. Accommodations by request can be made for all aspects of the selection process.
Dynata is also an affirmative action employer OE/Minority/Female/Veteran/Disabled/Sexual Orientation/Gender Identity
The salary range for this position in is $100K-$150K/yr; however, base pay offered may vary depending on location, job-related knowledge, skills, and experience. A discretionary incentive program may be provided as part of the compensation package, in addition to a full range of medical and other benefits, dependent on full-time employment status.
Show Less
Report",3.2,1001 to 5000 Employees,1977,Company - Private,Research & Development,Management & Consulting,$100 to $500 million (USD)
Sr. Data Architect,$90K - $120K (Employer est.),Michigan Medicine3.9 ★,Remote,"Summary:
The Michigan Data Collaborative Data Architect will design and construct relational databases for data warehousing, develop data modeling, and will be responsible for implementation, data acquisition, access analysis, data model design, archiving, recovery, and load strategy. The architect will coordinate new data development ensuring consistency and integration with existing warehouse structures, and review business requests for data and data usage, researching data sources for new and better data feeds. In addition, they will assist in continuous improvement efforts in enhancing performance and providing increased functionality. The Data Architect will possess broad knowledge of principles, practices, and procedures of field of specialization to the completion of difficult assignments and will have the field experience in the aspects mentioned. The Data Architect will work under the supervision of the team manager and technical lead. Under FLSA, this is the exempt job classification for this title. Incumbents in this position must meet the full criteria for exempt status: salary level, salary basis, and duties tests.
Supervision Received:
This position will report to the Michigan Data Collaborative Tech Team Manager within the Enterprise Data and Information Services (EDIS) Division of Health Information Technology & Services (HITS).
Responsibilities:
Designs and constructs relational databases for data warehousing for the Michigan Data Collaborative.
Develops data models and is responsible for data acquisition and access analysis as well as design, archive, recovery, load strategy and implementation.
Coordinates new data development ensuring consistency and integration with existing warehouse structure.
Reviews business requests for data and data usage, researches data sources for new and better data feeds.
Assists in continuous improvement efforts in enhancing performance and providing increased functionality.
Required Qualifications:
Bachelor's Degree in Computer Science, Information Systems or related field
3-5 years of professional experience in one or more of the following:
Designing, developing, and building data structures for databases, data warehouses, and/or data marts
Collecting and loading data into data structures
Defining and assessing input data formats and layouts
Maintaining and refreshing data loaded into data structures
Performing data quality analysis and edit checking to ensure data is fit for use
Desired Qualifications:
Experience working with healthcare data, including claims and clinical information, and familiarity with clinical coding systems such as ICD-10, HCPCS, CPT-4
Familiarity with Collaborative Quality Initiatives (CQI) organizations, knowledge of population health concepts, and clinical, quality, utilization reporting methodologies
Familiarity of data security concepts, especially around Protected Health Information (PHI) and HIPAA regulated data
Experience working in LINUX/UNIX environments
Experience working in Oracle database environments
Experience working with Informatica or other ETL technology
Experience working with a data modeling tool such as ER Studio
Ability to work with analysts, end users, clinicians, researchers, and others to identify and understand deliverable requirements; ability to present technical information to disparate audiences
Proven track record of delivering projects on time, in line with requirements, and with a high degree of accuracy
Solid and effective written and oral communication skills and excellent analytic and problem-solving ability
Ability to work effectively and collaboratively in a team environment while also being comfortable with independent tasks and projects; ability to dynamically shift priorities and approaches given emerging customer and team needs
Job Type: Full-time
Pay: $90,000.00 - $120,000.00 per year
Benefits:
401(k)
401(k) matching
Dental insurance
Employee assistance program
Employee discount
Flexible spending account
Health insurance
Life insurance
Paid time off
Professional development assistance
Referral program
Vision insurance
Schedule:
8 hour shift
Monday to Friday
Application Question(s):
Do you need, or will you need in the future, any immigration-related support or sponsorship from Michigan Medicine in order to begin or continue employment with Michigan Medicine?
Education:
Bachelor's (Preferred)
Experience:
Data modeling: 3 years (Preferred)
Data warehouse: 3 years (Preferred)
ETL: 3 years (Preferred)
Linux: 3 years (Preferred)
Oracle: 3 years (Preferred)
Work Location: Remote
Show Less
Report",3.9,10000+ Employees,-1,Hospital,Health Care Services & Hospitals,Healthcare,Unknown / Non-Applicable
Data Engineer,$70.00 Per Hour (Employer est.),Tellus solutions3.7 ★,"Sunnyvale, CA","Job Description:
The role will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams.
The ideal candidate is an experienced data pipeline builder and data wrangler who enjoy optimizing data systems and building them from the ground up.
The Data Engineer will support our software developers, database architects, and data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple teams, systems and products.
The right candidate will be excited by the prospect of optimizing or even re-designing our data architecture to support our next generation of products and data initiatives.
Responsibilities:
Create and maintain optimal data pipeline architecture for data intensive applications.
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using Azure SQL, Cosmo DB, Databricks and other legacy databases.
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.
Keep our data separated and secure across national boundaries through multiple data centers and Azure regions.
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
Work with data and analytics experts to strive for greater functionality in our data systems.
Qualifications for Data Engineer
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Extensive Experience on Databricks on Azure Cloud platform, deep understanding on Delta lake, Lake House Architecture.
Programming experience on Python, Shell scripting, PySpark, and other data programming language.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with Data Visualization Dashboard, Metrics and etc.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
Skills:
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Working knowledge of message queuing, stream processing, and highly scalable 'big data' data stores.
Familiar with Deployment tool like Docker and building CI/CD pipelines.
Experience supporting and working with cross-functional teams in a dynamic environment.
8+ years' experience in software development, Data engineering, and
Bachelor's degree in computer science, Statistics, Informatics, Information Systems or another quantitative field. Postgraduate/master's degree is preferred.
Experience in Machine Learning and Data Modeling is a plus.
Job Type: Contract
Salary: Up to $70.00 per hour
Benefits:
401(k)
Dental insurance
Health insurance
Schedule:
8 hour shift
Day shift
Application Question(s):
Only US Citizen and Green Card Holder
Experience:
Python, Shell scripting, PySpark: 5 years (Required)
Azure SQL: 5 years (Required)
Work Location: On the road
Show Less
Report",3.7,51 to 200 Employees,2006,Company - Private,Information Technology Support Services,Information Technology,$5 to $25 million (USD)
Data Modeler (Data Architect),-1,Luby Software4.3 ★,United States,"Come with us and become a #Luber

If you love technology we have some exciting news for you: SO DO WE!

Check out our package and the reasons to become a #Luber:
https://drive.google.com/file/d/1BbXpYhkboXQaHHiV0oSVWJij-3GnP_Qi/view?usp=sharing

We are seeking an experienced and skilled Data Modeler with a strong background in the retail industry. The ideal candidate will have expertise in designing and implementing dimensional data models in Erwin, as well as experience with the Snowflake and Databricks platforms, and building models from Kafka/JSON source data. As a Data Modeler, you will play a crucial role in designing, developing, and maintaining data models to support our retail analytics and business intelligence initiatives.

Responsabilidades e atribuições

What will be your attributions at #Luby?
Develop and maintain Erwin data models that align with business requirements and best practices for the retail industry.
Collaborate with cross-functional teams to gather data requirements and understand business processes and objectives.
Design and implement efficient and scalable data models to support data integration, data warehousing, and reporting needs.
Perform data profiling and analysis to identify data quality issues and recommend data cleansing and transformation strategies.
Optimize data models for performance and ensure data integrity and consistency.
Collaborate with data engineers to implement data pipelines and ETL processes using ADF, Databricks, and Snowflake.
Work closely with data scientists and analysts to ensure data models meet analytical and reporting requirements.
Document data models, data flows, and data dictionary for reference and future enhancements.
Stay up to date with emerging trends and technologies in data modeling, retail analytics, and cloud-based data platforms.

Requisitos e qualificações

Position's Requirements:
Bachelor's degree in Computer Science, Information Systems, or a related field. A Master's degree is a plus.
Proven experience as a Data Modeler, Data Architect, or similar role in the retail industry.
Strong knowledge of data modeling concepts, techniques, and best practices.
Hands-on experience with Snowflake, Databricks, and Kafka JSON messages.
Proficiency in SQL, ETL processes, and data integration methodologies.
Availability to work full time.
Familiarity with Azure and Big Data technologies.
Excellent analytical and problem-solving skills with attention to detail.
Strong communication and collaboration skills to work effectively with cross-functional teams.
Ability to prioritize and manage multiple projects and deliverables simultaneously.
Knowledge of retail industry trends, metrics, and business processes is a plus.

Informações adicionais

Our benefits range:

We hire through ""PJ"" contracts while also offering many benefits (...so you get the best of both worlds \o/)

Fully Remote
Health Care (Regular, Vision and Dental included)
LubyCare (Wellness and Mental Health Program)
Life Insurance
Gympass
Flexible Hours
Bonus per year (80h)
English classes
Program of indication
Multilaser e-commerce discounts - 30% on any purchase on their website, everytime!

A Luby é uma Software House brasileira com sólida presença internacional. Temos mais de 8 anos de atuação no mercado de Bancos e Fintechs americanas, assim como 20 anos de desenvolvimento de soluções digitais para o mercado nacional.

Atualmente, a Luby conta com mais de 260 colaboradores que usam as tecnologias mais atuais do mercado em Squads Multidisciplinares espalhados pelo Brasil.

Aqui, buscamos grandes talentos para fazerem parte da missão Luby de ser A referência técnica no Brasil. Seja em projetos nacionais ou internacionais.
Show Less
Report",4.3,201 to 500 Employees,2002,Contract,Software Development,Information Technology,Unknown / Non-Applicable
Sr. Data Engineer - Remote,-1,Chamberlain Group3.7 ★,Illinois,"Chamberlain Group is a global leader in access solutions with top brands, such as LiftMaster and Chamberlain, found in millions of homes, businesses, and communities worldwide.
As a leader in the Smart Home industry, we boast one of the largest IoT install bases, with innovative products consisting of cameras, locks, card readers, garage door openers, gates and more, all powered by our myQ digital ecosystem.
This role is responsible for providing technical expertise and leadership to design and deliver end-to-end data engineering solutions to support advanced analytics capabilities and drive innovation and decision-making
across Chamberlain.
Essential Duties and Responsibilities
Build and maintain real-time and batch data pipelines across the advanced analytics platform.
Design, develop and orchestrate highly robust and scalable ETL pipelines.
Design and implement Dimensional and NoSQL data modelling as per the business requirements.
Develop highly optimal codebase and perform Spark optimizations for Big Data use cases.
Design, develop and deploy optimal monitoring and testing strategy for the data products.
Collaborate with stakeholders and advanced analytics business partners to understand business needs and translate requirements into scalable data engineering solutions.
Collaborate with data scientists to prepare data for model development and production.
Collaborate with data visualization and reporting application developers to ensure the sustainability of production applications and reports.
Collaborate with data architects on the enhancement of Chamberlain’s enterprise data architecture and platforms.
Provide leadership to third-party contractors.
Comply with health and safety guidelines and rules.
Protect CGI’s reputation by keeping information confidential.
Maintain professional and technical knowledge by attending educational workshops, professional publications, establishing personal networks, and participating in professional societies.
Minimum Qualifications
Education/Certifications:
Bachelor’s degree in computer science or related quantitative field of study
Experience:
4+ years of professional experience
Knowledge, Skills, and Abilities:
Natural sense of urgency, teamwork, and collaboration reflected in daily work ethic.
Proficient in Spark or Databricks, Cloud Data Engineering Services preferably Azure, Streaming frameworks like Event Hubs or Kafka.
Proficient in Microsoft Office.
Familiarity with modern Machine Learning Operationalization techniques.
Agile methodologies.
Familiarity with Data visualization tools, such as Qlik or Power BI.
Preferred Qualifications
Education/Certifications:
Master’s degree in computer science or related quantitative field of study
Experience:
4+ years of professional experience
2+ years of professional experience delivering engineering for advanced analytics or data science solutions
Knowledge, Skills, and Abilities:
Agile methodologies
Experience with IoT Data Architecture.
Machine Learning Operationalization (MLOps) proficiency.
REST API design and development.
Proficiency with streaming design patterns.

The pay range for this position is $103,300.00 to $177.475.00; base pay offered may vary depending on a number of factors including, but not limited to, the position offered, location, education, training, and/or experience. In addition to base pay, also offered is a comprehensive benefits package and 401k contribution (all benefits are subject to eligibility requirements).
This position is eligible for participation in a short-term incentive plan subject to the terms of the applicable plans and policies.
#LI-Remote
We're an organization who values its human capital and provides support to assist its employees succeed.

Chamberlain Group is proud to be an Equal Opportunity Employer. You will be considered for this position based upon your experience and education, without regard to race, color, religion, sex, national origin, age, sexual orientation, ancestry; marital, disabled or veteran status. We are committed to creating and maintaining a workforce environment that is free from any form of discriminations or harassment.

Persons with disabilities who anticipate needing accommodations for any part of the application process may contact, in confidence
Recruiting@Chamberlain.com
.

NOTE: Staffing agencies, headhunters, recruiters, and/or placement agencies, please do not contact our hiring managers via email or phone or other methods.
Start your job application: click Apply Now
Show Less
Report",3.7,1001 to 5000 Employees,1900,Company - Private,Consumer Product Manufacturing,Manufacturing,$500 million to $1 billion (USD)
Azure - Senior Data Engineering Architect,$108K - $210K (Employer est.),Publicis Sapient3.8 ★,"Arlington, TX","Azure - Senior Data Engineering Architect
Full-time
Company Description
Publicis Sapient is a digital transformation partner helping established organizations get to their future, digitally-enabled state, both in the way they work and the way they serve their customers. We help unlock value through a start-up mindset and modern methods, fusing strategy, consulting and customer experience with agile engineering and problem-solving creativity. As digital pioneers with 20,000 people and 53 offices around the globe, our experience spanning technology, data sciences, consulting and customer obsession – combined with our culture of curiosity and relentlessness – enables us to accelerate our clients’ businesses through designing the products and services their customers truly value. Publicis Sapient is the digital business transformation hub of Publicis Groupe. For more information, visit publicissapient.com.
Job Description
Publicis Sapient is looking for a hands-on Senior Manager to join our team of bright thinkers and doers. You’ll use your problem-solving creativity to design, architect, and develop high-end technology solutions that solve our clients’ most complex and challenging problems across different industries. We are on a mission to transform the world, and you will be instrumental in shaping how we do it with your ideas, thoughts, and solutions.
Your impact:
Develop, design, and implement consumer data models based on business requirements and objectives.
Collaborate with various stakeholders, such as business analysts, architects, and developers, to understand data needs and convert these needs into effective data models.
Evaluate and optimize existing data models for improvement.
Ensure that data models adhere to industry best practices, standards, and guidelines.
Conduct data profiling and analysis to identify data quality issues and propose data cleansing and remediation strategies.
Collaborate with database administrators to optimize database performance and maintain data integrity.
Work closely with ETL developers to integrate data models into data integration processes.
Stay updated on the latest trends and technologies in data modeling, cloud computing, and database design.
Mentor, support and manage team members
Qualifications
Your Skills and Experience:
Demonstrable experience in enterprise level data platforms involving implementation of end-to-end data pipelines
Hands-on experience with at least one of the leading public cloud data platforms (Amazon Web Services, Azure or Google Cloud)
Experience with column-oriented database technologies (e.g., Big Query, Redshift, Vertica), NoSQL database technologies (e.g., DynamoDB, BigTable, Cosmos DB, etc.) and traditional database systems (e.g., SQL Server, Oracle, MySQL)
Experience in architecting data pipelines and solutions for both streaming and batch integrations using tools/frameworks like Glue ETL, Lambda, Google Cloud DataFlow, Azure Data Factory, Spark, Spark Streaming, etc.
Metadata definition and management via data catalogs, service catalogs, and stewardship tools such as OpenMetadata, DataHub, Alation, AWS Glue Catalog, Google Data Catalog.
Test plan creation and test programming using automated testing frameworks, data validation and quality frameworks, and data lineage frameworks
Data modeling, querying, and optimization for relational, NoSQL, timeseries, graph databases, data warehouses and data lakes
Data processing programming using SQL, DBT, Python, and similar tools
Logical programming in Python, Spark, PySpark, Java, Javascript, and/or Scala
Cloud-native data platform design with a focus on streaming and event-driven architectures
Participate in integrated validation and analysis sessions of components and subsystems on production servers
Data ingest, validation, and enrichment pipeline design and implementation
SDLC optimization across workstreams within a solution
Bachelor’s degree in Computer Science, Engineering, or related field
Additional Information
Pay Range:$108,000 -$210,000
Benefits of Working Here:
Flexible vacation policy; time is not limited, allocated, or accrued
16 paid holidays throughout the year
Generous parental leave and new parent transition program
Tuition reimbursement
Corporate gift matching program
As part of our dedication to an inclusive and diverse workforce, Publicis Sapient is committed to Equal Employment Opportunity without regard for race, color, national origin, ethnicity, gender, protected veteran status, disability, sexual orientation, gender identity, or religion. We are also committed to providing reasonable accommodations for qualified individuals with disabilities and disabled veterans in our job application procedures. If you need assistance or an accommodation due to a disability, you may contact us at [email protected] or you may call us at +1-617-621-0200.
To apply to this job, click Apply Now
Show Less
Report",3.8,10000+ Employees,1990,Company - Public,Business Consulting,Management & Consulting,Unknown / Non-Applicable
Sr Data Engineer/data architect,$70.00 - $90.00 Per Hour (Employer est.),Devcare Solutions3.6 ★,"Columbus, OH","Role : Data Architect / Bigdata Architect / Hadoop / senior data engineer/ senior Bigdata
skills: oracle, SQL, Hadoop, bigdata , cloud era, Hive, data migration etc.
8+ years Data analysis/architecture experience in Waterfall and Agile Methodology in various domains (prefer Healthcare) in a data warehouse environment.
Good knowledge of relational database, Hadoop big data platform and tools, data vault and dimensional model design.
Strong SQL experience (prefer Oracle, Hive and Impala) in creating DDL’s and DML’s in Oracle, Hive and Impala (minimum of 8 years’ experience).
Experience in analysis, design, development, support and enhancements in data warehouse environment with Cloudera Bigdata Technologies (with a minimum of 8-9 years’ experience in Hadoop, MapReduce, Sqoop, PySpark, Spark, HDFS, Hive, Impala, Stream Sets, Kudu, Oozie, Hue, Kafka, Yarn, Python, Flume, Zookeeper, Sentry, Cloudera Navigator) along with Informatica.
Experience (minimum of 8 years) in working with Sqoop scripts, PySpark programs, HDFS commands, HDFS file formats (Parquet, Avro, ORC etc.), Stream Sets pipelines, jobs scheduling, hive/impala queries, Unix commands, scripting and shell scripting etc.
Experience in migrating data from relational database (prefer Oracle) to big data – Hadoop platform is a plus.
Experience eliciting, analyzing and documenting functional and non-functional requirements.
Ability to document business, functional and non-functional requirements, meeting minutes, and key decisions/actions.
Experience in identifying data anomalies.
Experience building data sets and familiarity with PHI and PII data.
Ability to establish priorities & follow through on projects, paying close attention to detail with minimal supervision.
Effective communication, presentation, & organizational skills.
Good experience in working with Visio, Excel, PowerPoint, Word, etc.
Effective team player in a fast paced and quick delivery environment.
Required Education: BS/BA degree or combination of education & experience.
DESIRED Skill Sets:
Demonstrate effective leadership, analytical and problem-solving skills
Required excellent written and oral communication skills with technical and business teams.
Ability to work independently, as well as part of a team
Stay abreast of current technologies in area of IT assigned
Establish facts and draw valid conclusions
Recognize patterns and opportunities for improvement throughout the entire organization
Ability to discern critical from minor problems and innovate new solutions
Skill
Data analysis/architecture experience in Waterfall and Agile Methodology in various domains (prefer Healthcare) in a data warehouse environment.
Good knowledge of relational database, Hadoop big data platform and tools, data vault and dimensional model design.
Strong SQL experience (prefer Oracle, Hive and Impala) in creating DDL’s and DML’s in Oracle, Hive and Impala
analysis, design, development, support and enhancements in data warehouse environment with Cloudera Bigdata Technologies, along with Informatica
Experience in migrating data from relational database (prefer Oracle) to big data – Hadoop platform is a plus.
Job Type: Contract
Salary: $70.00 - $90.00 per hour
Benefits:
Dental insurance
Health insurance
Vision insurance
Schedule:
8 hour shift
Monday to Friday
Experience:
total: 10 years (Required)
oracle: 4 years (Required)
SQL: 3 years (Required)
cloud era: 3 years (Required)
hadoop / Bigdata: 3 years (Required)
data architect: 1 year (Required)
Data warehouse: 1 year (Required)
Willingness to travel:
100% (Required)
Work Location: On the road
Speak with the employer
+91 6148083833
Show Less
Report",3.6,51 to 200 Employees,2005,Company - Private,Information Technology Support Services,Information Technology,Unknown / Non-Applicable
"Data Architect, IT",$83K - $129K (Glassdoor est.),UofL Health3.4 ★,"Louisville, KY","Overview:
We are Hiring for our Information Technology team.
Shift Options: Full Time & Days

About Us
UofL Health is a fully integrated regional academic health system with seven hospitals, four medical centers, nearly 200 physician practice locations, more than 700 providers, the Frazier Rehabilitation Institute and the Brown Cancer Center.
With more than 12,000 team members—physicians, surgeons, nurses, pharmacists and other highly skilled health care professionals—UofL Health is focused on one mission: delivering patient-centered care to each and every patient each and every day.

Our Mission
As an academic health care system, we will transform the health of the communities we serve through compassionate, innovative, patient-centered care.

Job Summary
The Data Architect supports the design, development and implementation of all data initiatives at ULH. Leads the enterprise information management strategy fostering IT – Business collaboration in understanding of enterprise data, binding disparate, heterogenous data sources together in a framework for access and sharing of data, developing data trust across the organization and instituting best practices and standards in data use.

Leads the implementation, enhancement and on-going support of enterprise data platform utilizing data modeling concepts for model extension and ETL programs to transform and ingest data.
Supports the data through its life cycle utilizing data governance principles that ensure data quality, integrity, stewardship, security, literacy and adoption.
Develops and enforces implementation of standards and best practices involved in data modeling (conceptual/logical/physical models), data architecture design patterns (EDW/data marts/data lakes) and ETL.
Conducts research and makes recommendations on products, tools, services, protocols and standards that will support ULH’s data management strategy.
Works in concert with BI Developers and business teams to understand business requirements and translating those requirements into developing value-add BI/Analytics solutions.
Designs and maintains a curriculum for coaching and training current and prospective end users to better understand how these tools can enhance business decision making capabilities.
Provides Level 1, 2 and 3 support for day-to-day production issues maintaining documentation in the appropriate tracking systems while adhering to prescribed escalation & change control procedures. Includes on call rotation.
Adheres to all Security Standards as set forth by the organization and National guidelines.
Additional tasks/responsibilities as defined.
Responsibilities:
Works closely with Analytics leadership team, business teams and IT infrastructure teams to design, implement and support the goals and objectives of the organization set by the leadership.
Leads the implementation, enhancement and on-going support of enterprise data platform utilizing data modeling concepts for model extension and ETL programs to transform and ingest data.
Conducts research and makes recommendations on products, tools, services, protocols and standards that will support ULH’s data management and BI strategies.
Supports the data through its life cycle utilizing data governance principles that ensure data quality, integrity, stewardship, security, literacy and adoption.
Proactively communicate and collaborate with internal and external customers to analyze information needs and functional requirements and delivery.
Performs Tier 1, 2 and 3 Application/Systems support.
Maintains relationship with vendors of hospital applications to understand current and future features and functionality and product life cycle.
Qualifications:
Education / Accreditation / Licensure (required & preferred):
Bachelor’s Degree in Business, Information Science or Computer Science required. Master’s Degree highly preferred

Experience (required and preferred):
7+ years of experience in supporting/developing/extending data warehouse/data mart solutions required.
5+ years of experience with data modeling concepts translating business requirements into conceptual, logical and physical models required.
5+ years of experience in ETL development preferably with SSIS required.
Expert knowledge of data governance practices and data life cycle management highly desired.
Experience in Agile development methodology for analytics projects required.
Experience and ability in working directly with vendors, customers and other IT teams.
Apply Now: click Apply Now
Show Less
Report",3.4,1001 to 5000 Employees,-1,Hospital,Health Care Services & Hospitals,Healthcare,$100 to $500 million (USD)
AWS Data Engineer,$109K - $131K (Employer est.),Techflairs4.5 ★,"Washington, DC","Bachelor’s degree in computer science or engineering or equivalent work experience
AWS Solutions Architect – Associate certification within past five years
AWS Solutions Architect – Professional certification within past five years
AWS Certified Data Analytics – Specialty or AWS Certified Big Data – Specialty certifications
Solutions architecture experience in an enterprise environment with emphasis on data systems
Specific experience designing, executing and supporting AWS data lakes at scale
Experience designing, optimizing, and maintaining relational and non-relational databases including MySQL, MS SQL, Redshift, AWS RDS and other NoSQL databases
Experience with the design and building of ETL packages, data pipelines and connecting these to BI applications
Running production workload on AWS cloud
Workload migration to AWS cloud
Knowledge of data movement and data presentation tools such as; Informatica, MS SSIS, AWS Glue, Cognos, Tableau
Ability to pass a background check and pass the criteria for a CJIS environment
Willingness to research and self-study to keep technical skills relevant in a highly complex environment
Ability to multi-task and prioritize deadlines as needed to deliver results
Ability to work independently or as part of a team
Mentors and coach colleague. Seeks opportunities for continuous improvement
Excellent verbal and written communication skills with great attention to detail and accuracy
Experience working in an Agile/Scrum environment
Job Types: Contract, Temporary
Pay: $108,665.12 - $130,865.52 per year
Experience level:
8 years
Schedule:
8 hour shift
Monday to Friday
Ability to commute/relocate:
Washington, DC 20001: Reliably commute or planning to relocate before starting work (Required)
Experience:
designing, optimizing, and maintaining relational: 3 years (Required)
design and building of ETL packages, data pipelines: 2 years (Required)
Running production workload on AWS cloud: 3 years (Required)
Workload migration to AWS cloud: 2 years (Required)
Work Location: In person
Show Less
Report",4.5,1 to 50 Employees,2002,Company - Private,Information Technology Support Services,Information Technology,$25 to $100 million (USD)
Data Engineer,$110K (Employer est.),Capitol Federal2.9 ★,"Topeka, KS","Job Description:
Pay: up to $110,000 Annually
Job Type: Full Time
The Data Engineer assists in setting overall development roadmap and standards for the Bank and helps evaluate and architect the use of data solutions, using industry best practices. This position works as part of a collaborative team to design, code, and implement data solutions to support internal business requirements or external customers and vendors. An innovative mindset and an ability to translate complex business scenarios into a technical solution is required. This position performs a variety of tasks under general supervision. The position reports directly to an IT manager and requires regular, predictable and timely attendance at work to meet department workload demands.
Paid time off and holiday available on your first day! Benefits available to anyone working 20 hours or more per week!
CapFed® is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees.
Job Type: Full-time
Work Location: In person
Show Less
Report",2.9,501 to 1000 Employees,1893,Company - Public,Banking & Lending,Financial Services,$100 to $500 million (USD)
Sr Data Platform Architect - Remote AZ,$89K - $123K (Glassdoor est.),Blue Cross Blue Shield of Arizona4.1 ★,"Phoenix, AZ","Awarded a Healthiest Employer, Blue Cross Blue Shield of Arizona aims to fulfill its mission to inspire health and make it easy. BCBSAZ offers a variety of health insurance products and services to meet the diverse needs of individuals, families, and small and large businesses as well as providing information and tools to help individuals make better health decisions.
This remote work opportunity requires residency, and work to be performed, within the State of Arizona
About the Job
Create and maintain optimal data pipeline architecture that is coherent and scalable, based on best practices of integrating data into a consolidated repository.Build the infrastructure required for optimal extraction, transformation, and loading (ETL) of data from a wide variety of data sources using SQL, cloud, and big data technologies.
End-to-end solutions architecture of enterprise data solutions and platforms
10+ years’ experience architecting enterprise data solutions
5+ years of relevant data management consulting or industry experience (Enterprise Data Architecture, EDW, ETL, MDM, Data Catalogs and Lineage, Data Quality, Data Strategy
Lead the design, development, deployment of solutions including data ingestion, storage and manipulation.
Design the technology framework, including data streams, integrations, transformations, databases, and data warehouses
Expertise in data platforms and technologies, including data lakes, data warehouses, data analytics, data management, data governance, business process automation
Experience architecting and developing cloud data solutions especially in Azure
5+ years of hands-on experience building conceptual, logical, and physical data models
Experience with data warehousing and data integration (ETL/ELT), using ETL tools.
Knowledge of modeling database schemas for large datasets.
Knowledge of metadata-driven enterprise reporting platforms.
Purpose of the job
As a member of delivery team, supports new development/project and production support, as the highest-level technology domain expert. Assesses business requirements; collects and identifies technical specifications; and develops technology solutions. Envisions and creates solutions that meet requirements; models pieces an infrastructure and points of integration; proves feasibility of a design; creates design artifacts required to deliver and maintain infrastructure; guides solution through to completion, implementation, and support in production.
With Enterprise Architecture team, ensures new technology solutions are designed for optimal access and usefulness, and leverages existing technologies for specific technical domain(s), and understands system-wide impacts. Assists in near/mid-term roadmap creation, to address gaps and move towards future state architecture to support growth, optimization and innovation.
REQUIRED QUALIFICATIONS
Required Work Experience
5 years’ experience in IS/business experience, programming, engineering and/or systems analysis and a proven track record of successfully delivering BI and/or data warehousing projects.
2 years experience architecting BI solutions including Data Warehouses, Master Data Management, Dashboards and Reporting systems
Required Education
High-School Diploma or GED in general field of study
Required Licenses
N/A
Required Certifications
N/A
PREFERRED QUALIFICATIONS
Preferred Work Experience
5 years of experience with relational data structures, theories, principles and practices.
1 year of experience with deployment / administration of Microsoft SQL reporting services (SSRS, SSAS, SSIS).
2 years of experience with various BI tools like Tableau, MicroStrategy, Brio, Domo and Power BI
2 years of experience modeling data to conceptual, logical and physical models
2 years of experience with ETL tools
Preferred Education
Bachelor’s degree in Computer Science, Information Systems, or related field
Preferred Licenses
N/A
Preferred Certifications
Technical Certifications in Microsoft SQL
ITIL v3+ Practitioner Certification
Data solution certifications from governing bodies like TDWI, DAMA, Kimball, Hortonworks, Cloudera
ESSENTIAL job functions AND RESPONSIBILITIES
Understand and document high-level master data management (MDM) requirements of the business and drive the definition of data standards and implementation best practices working with the BI and enterprise architecture teams.
Establish domain specific standards, near/mid-term strategy, and roadmaps (0-18 months), in adherence to, and in support of Enterprise standards, strategy and roadmaps.
Assist in creating the vision for future state technologies and architecture and participate in setting Enterprise standards and mid/long-term strategy/roadmaps (18-60 months), acting as domain specific subject matter experts.
Responsible for domain specific content/collateral, based on the EA standards/ methodologies, to document the current state and future state architecture.
Develop technology specifications and ensure that new technology solutions are designed for optimal access and usefulness, and leverage existing technologies when possible.
Apply architectural and engineering concepts to design a solution that meets operational requirements, such as scalability, maintainability, security, reliability, extensibility, flexibility, availability and manageability.
Participate and lead research and development efforts (proofs of concept, prototypes), as subject matter experts, when introducing new technologies.
Provide technical expertise to propose level of effort projections, work breakdown structures and technical resource planning for proposed and current work to support the Project Management Office (PMO) and Project Review Board (PRB) Processes.
Educate and influence others in order to gain buy-in on proposed solutions.
Provide input to management throughout the project management lifecycle (PMLC).
Assists managers with developing the service level agreements (SLAs) and deployment of key performance measures.
Participate in various phases of the SDLC to perform QA/architectural review functions and to ensure adherence to Enterprise Architecture (EA) technology standards and project specific solutions architecture. (i.e., design reviews).
Ensures technology solutions are production ready and meet the defined specifications, and that the solution can be maintained via production support methodologies and resources.
Assist in IS Service Management policy and processes to effectively support domain. Assisted processes would include Incident Management, Problem Management, Change Management, Knowledge Management and Performance Management.
Review the ongoing implementation solution for improvement opportunities.
Facilitate communications between IS workgroups and business stakeholders for technical issues and/or major changes; acting as the technical domain subject matter expert.
Provide technical guidance to coach and mentor team members; provide performance feedback to manager(s).
Keep current and informed of domain related technologies and best practices.
Serve as technical owner and IT focal point for domain specific solutions.
Provide coaching and mentoring to team members in the areas of technical skills and competencies.
The position requires a full-time work schedule. Full-time is defined as working at least 40 hours per week, plus any overtime as requested or needed to perform job responsibilities.
Perform all other duties as assigned.
REQUIRED COMPETENCIES
Required Job Skills
Intermediate skill in use of office equipment, including copiers, fax machines, scanner and telephones
Intermediate PC proficiency
Intermediate proficiency in spreadsheet, database and word processing software
Required Professional Competencies
Demonstrated thorough understanding of modern enterprise architecture, hands-on experience with enterprise business intelligence platforms.
Integrity and Trust
Ability to utilize strong analytical skills, take appropriate risks, while dealing with ambiguity and make effective decisions using available data.
Ability to be approachable, develop peer relationships and build synergy with a diverse team in an ever-changing environment
Ability to take appropriate risks, using available information.
Anticipate downstream technical needs and steer architectural designs to appropriately factor in considerations.
Strong analytical skills to support independent and effective decisions..
Ability to be customer focused with strong verbal and written communications skills and the ability to interact professionally with a diverse group of executives, managers, and subject matter experts.
Demonstrated thorough understanding of modern enterprise architecture, hands-on experience with enterprise business intelligence platforms.
Knowledge and skills in data warehousing design, methodologies and tools.
Be driven for results and work effectively with management, project managers, business analysts, developers, engineers, architects, system administrators, and QA to conceive, design, and deliver successful BI solutions.
Able to operate at highly varying levels of abstraction including business strategy, product strategy, technical design and implementation
Work with all levels of management and functional areas in BCBSAZ and understand the potential implications of system changes to those areas.
Ability to be self-aware and emotionally intelligent, able to give and receive constructive feedback and continue self-development.
Required Leadership Experience and Competencies
Provide leadership, promote teamwork, meet objectives and exercise independent judgment
Experience leading and implementing projects and working collaboratively with other departments levels
Ability to prioritize tasks and work with multiple priorities, sometimes under limited time constraints.
Ability to build synergy with a diverse team in an ever-changing environment
PREFERRED COMPETENCIES
Preferred Job Skills
Expert knowledge designing highly redundant, scalable, multi-tier enterprise transaction processing systems from front end to back end.
Knowledge of HIPAA security and privacy standards.
In depth knowledge of healthcare and health plan data structures and business processes and workflows.
Preferred Professional Competencies
N/A
Preferred Leadership Experience and Competencies
N/A
Our Commitment
BCBSAZ does not discriminate in hiring or employment on the basis of race, ethnicity, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, protected veteran status or any other protected group.
Thank you for your interest in Blue Cross Blue Shield of Arizona. For more information on our company, see azblue.com. If interested in this position, please apply.
Show Less
Report",4.1,1001 to 5000 Employees,1939,Nonprofit Organization,Insurance Carriers,Insurance,Unknown / Non-Applicable
Senior Data Engineer,$100K - $179K (Employer est.),RVO Health4.0 ★,"Minneapolis, MN","AT A GLANCE
RVO Health is looking for a talented Senior Data Engineer to join our team! As a Senior Data Engineer at RVO Health, you will have the chance to build technology that drives real improvements to consumer health outcomes and has the potential to have widespread impact across the healthcare industry. You will design, develop, test, and maintain big data pipelines for ingestion, segmentation, and reporting to drive our vision!
What You'll Do:
Provide technology ownership for data solutions for projects that the team has been tasked with.
Work with a cross functional team of business analysts, architects, engineers, data analysts and data scientists to formulate both business and technical requirements.
Design and build data pipelines from various data sources to a target data warehouse using batch data load strategies utilizing cutting edge cloud technologies.
Conceptualizing and generating infrastructure that allows data to be accessed and analyzed effectively.
Documenting database designs that include data models, metadata, ETL specifications and process flows for business data project integrations.
Perform periodic code reviews and test plans to ensure data quality and integrity.
Provide input into strategies as they drive the team forward with delivery of business value and technical acumen.
Execute on proof of concepts, where appropriate, to help improve our technical processes.
What We're Looking For:
5+ years of Data Engineering experience
4+ years of experience working on Spark (RDDs / Data Frames / Dataset API) using Scala/Python to build and maintain complex ETL pipelines.
4+ years of experience in the big data space
Experience in translating business requirements into technical data solutions on a large scale.
2+ years of experience working on AWS (Kinesis / Kafka / S3 / RedShift) Or Azure.
Able to research and troubleshoot potential issues presented by stakeholders within the data ecosystem.
Experience with GitHub and CI/CD processes
Experience with Compute technologies like EMR and Databricks
Experience working with job orchestration (eg., Airflow / AWS Step Function)
Experience with Data Modeling, Data warehousing
Working with Kubernetes is a plus
Strong analytical and interpersonal skills.
Enthusiastic, highly motivated and ability to learn quickly.
Able to work through ambiguity in a fast-paced, dynamically changing business environment.
Ability to manage multiple tasks at the same time with minimal supervision.
This position may occasionally require travel for training and other work-related duties.
""Pursuant to various state Fair Pay Acts, below is a summary of compensation elements for this role at the company. The following benefits are provided by RVO Health, subject to eligibility requirements.""
Starting Salary: $100,000 - $178,500*
Note actual salary is based on geographic location, qualifications and experience
Health Insurance Coverage (medical, dental, and vision)
Life Insurance
Short and Long-Term Disability Insurance
Flexible Spending Accounts
Paid Time Off
Holiday Pay
401(k) with match
Employee Assistance Program
Paid Parental Bonding Benefit Program
Who We Are:
Founded in 2022, RVO Health is a new healthcare platform of digital media brands, services and technologies focused on building relationships with people throughout their health & wellness journey. We meet people where they are in their personal health journeys and connect them with both the information and the care they need. RVO Health was created by joining teams from both Red Ventures and UnitedHealth Group's Optum Health. Together we're focused on delivering on our vision of a stronger and healthier world.
RVO Health is comprised of Healthline Media (Healthline, Medical News Today, Psych Central, Greatist and Bezzy), Healthgrades, FindCare and PlateJoy; Optum Perks, Optum Store and the virtual coaching platforms Real Appeal, Wellness Coaching, and QuitForLife.
We offer competitive salaries and a comprehensive benefits program for full-time employees, including medical, dental and vision coverage, paid time off, life insurance, disability coverage, employee assistance program, 401(k) plan and a paid parental leave program.
RVO Health is an equal opportunity employer that does not discriminate against any employee or applicant because of race, creed, color, religion, gender, sexual orientation, gender identity/expression, national origin, disability, age, genetic information, veteran status, marital status, pregnancy or any other basis protected by law. Employment at RVO Health is based solely on a person's merit and qualifications.
We are committed to providing equal employment opportunities to qualified individuals with disabilities. This includes providing reasonable accommodation where appropriate. Should you require a reasonable accommodation to apply or participate in the job application or interview process, please contact accommodations@rvohealth.com.
We do not provide visa sponsorship at this time.
RVO Health Privacy Policy: https://rvohealth.com/legal/privacy
Show Less
Report",4.0,1001 to 5000 Employees,2022,Company - Private,Hospitals & Health Clinics,Healthcare,Unknown / Non-Applicable
Azure Data Engineer,$90K (Employer est.),Berkley Environmental4.5 ★,"Atlanta, GA","W. R. Berkley Corporation, founded in 1967, is one of the nation’s premier commercial lines property casualty insurance providers. Founded in 2004, Berkley Environmental has underwriting and account executive units in seven regions. Berkley Environmental offers an array of coverages for virtually all classes traditionally known to have environmental liability exposures on both an admitted and non-admitted basis. We provide a comprehensive portfolio of commercial property casualty insurance, automobile liability and workers’ compensation, along with claim services, providing expertise to meet the unique business needs of our customers. W.R. Berkley Corporation has reached a milestone and is celebrating 50 years, click here to read more on the history of the company.
Responsibilities
In your role as an Azure Data Engineer, you will be responsible for expanding and optimizing data and pipeline architectures, and for optimizing data collection and flow across functional teams. Your responsibilities include assisting software developers, database architects, data analysts, and data scientists with data initiatives and ensuring a consistent data delivery architecture is put in place throughout ongoing projects.
Design and implement data pipelines using Azure technologies such as Azure Data Factory, Azure Stream Analytics, and Azure SQL Database
Migrate on-premises data stores to Azure cloud platforms
Implement data transformations using Azure Databricks
Collaborate with data scientists to design and implement machine learning models using Azure Machine Learning
Optimize data pipelines for performance and scalability
Monitor and troubleshoot data pipelines within Azure Data Factory
Collaborate with cross-functional teams to understand business requirements and translate them into technical solutions
Participates in the testing process through test review and analysis, test witnessing and certification of software.
Work with technical resources to ensure accurate translation of specifications into workable application code. Work with outside vendors and sister companies on coordinating data capture.
Qualifications
3+ years of experience as a data engineer.
Strong experience with Azure cloud technologies, including Azure Data Factory, Azure Data Bricks, Azure Synapse Analytics, and Azure SQL Database, T-SQL, SSIS, and SSAS Tabular.
Experience with data transformation and manipulation using Azure Databricks or similar tools.
Experience working in an Agile development environment.
Familiar with a variety of the field’s concepts, practices, and procedures and a strong focus on data integrity.
Demonstrates strong written and oral communications skills. Ability, desire, and focus to meet deadlines.
Demonstrates ability to work with all levels of individuals.
Demonstrates organizational skills while working on multiple projects; and communicate effectively within the team.
Experience with machine learning is a plus.
Education Requirement
Bachelor's degree in Computer Science, Information Technology, or a related field.
Technology Stack
Azure SQL Data Warehouse
Azure Data Factory
Azure Data Lake
Azure Analysis Services
Azure Synapse Analytics
Azure DevOps
Databricks/Spark-SQL
Python
Azure Functions and Logic Apps
Serverless Architecture
Additional Company Details
We do not accept unsolicited resumes from third party recruiting agencies or firms.
Job Type: Full-time
Pay: From $90,000.00 per year
Benefits:
401(k)
Dental insurance
Employee assistance program
Flexible schedule
Health insurance
Health savings account
Paid time off
Parental leave
Professional development assistance
Referral program
Vision insurance
Experience level:
4 years
Schedule:
Day shift
Monday to Friday
Work Location: Hybrid remote in Atlanta, GA 30346
Show Less
Report",4.5,Unknown,-1,Company - Public,Insurance Carriers,Insurance,Unknown / Non-Applicable
Data Architect (Azure),$140K - $160K (Employer est.),LTI - Larsen & Toubro Infotech3.8 ★,"Charlotte, NC","Role: Azure Data Architect.
Location: Charlotte, NC (Onsite or Hybrid Model (3 days onsite/week)
Duration: FTE.
Responsibilities:
You are an expert in Azure Data Analytics having thorough understanding of Azure Data Platform tools
Expertise and hands-on experience on Azure Platform among: Data Factory, Azure Spark
Collaborate with project stakeholders like database administrators, technical architects, , business analysts, big data admins, security experts, information modelling experts to determine project needs and plan development and implementation strategies.
To define, review, and explain Data Architecture requirements & design to all the project stakeholders
Lead the migration of data from legacy systems to newly developed solution.
To create strategies and design solutions for wide variety use cases like Data Migration (end to end ETL process), database optimization, data architectural solutions for Analytics and Big Data Projects
To design, develop and troubleshoot highly complex technical problems in OLAP/OLTP/DW, Analytics, Big Data environments and provide solutions for Enterprise level Applications utilizing Azure Data Platform
To implement data quality processes for use with MDM, BI solutions, data warehouses, EAI solutions, etc.
Work on streamlining data flows and data models consistently
Have a keen focus on improving and tuning data quality, accessibility, performance and security needs
Skills Required
Bachelor/ master’s degree in computer science engineering,
Self-driven, and able to think holistically of the product roadmap
Performing reviews of data Architecture and Designs
Research new technologies and data modelling methods
Creative in solving complex business problems
Hands-on experience in business analysis, pre-sales, solution proposals, development
Excellent written & verbal communication
Job Type: Full-time
Salary: $140,000.00 - $160,000.00 per year
Benefits:
401(k)
401(k) matching
Dental insurance
Health insurance
Paid time off
Vision insurance
Schedule:
Monday to Friday
Ability to commute/relocate:
Charlotte, NC 28202: Reliably commute or planning to relocate before starting work (Required)
Experience:
Data Architect: 10 years (Required)
Azure: 8 years (Required)
Azure data factory: 5 years (Required)
Azure DataBricks: 5 years (Required)
Data modeling: 8 years (Required)
Adobe Spark: 5 years (Required)
Data Migration: 4 years (Required)
OLAP: 6 years (Required)
Work Location: In person
Show Less
Report",3.8,10000+ Employees,1997,Company - Private,Information Technology Support Services,Information Technology,Unknown / Non-Applicable
Azure Data Engineer,$78K - $162K (Employer est.),Leidos3.8 ★,Remote,"Description
The Public Health Portfolio of Leidos is seeking a Azure Data Engineer in Atlanta, GA to support the CDC OCIO Cloud Modernization program.

This CDC OCIO Cloud Modernization program assists the CDC in migrating over 400 applications from on-premises to cloud solutions.

The Azure Data Engineer is a key asset in the design, development, and deployment of cloud-based solutions.
Key Responsibilities:
The Azure Data Engineer will:
Apply technical knowledge and experience on scrum teams to develop cloud data solutions that meet business and IT needs, that may be used to create cloud data processing models.
May leverage technologies to modernize data architecture using monitoring, performance data architecture, migration of data/Database
Requirements:
BS degree and 5 years of prior relevant experience OR 9+ years of prior relevant experience with no degree.
2 or more years of experience working with cloud native technologies (Azure or AWS)
3 years of Data Engineering Experience
Strong programming and/or scripting experience with back-end languages such as Python, Java, .NET, C# etc.
Experience with developing ETL pipelines in one or more of the following tools: Azure Data factory, Event hubs, Event grid, Azure functions, Data Flow, Hadoop, AWS Glue
Experience with Databricks and/or Spark.
Experience working in/with Agile development teams
Preferred:
Experience with technologies such as CosmoDB, AzureSQL, Redis, Synapse
Experience with orchestration tool such as Airflow or Oozie
Strong experience with SQL
Experience with Kotlin’
Experience with migrations to major cloud
Knowledge with Public health/health care data (HL7, FHIR, vocabulary, and HHS data standards)
Certification: AWS Certified Solution Architect- Associate, Azure Data Engineer Associate, Databrick Certified Data Engineer Associate
Ability to Obtain NACI clearance
hhscdc
Pay Range:
Pay Range $78,000.00 - $120,000.00 - $162,000.00
The Leidos pay range for this job level is a general guideline only and not a guarantee of compensation or salary. Additional factors considered in extending an offer include (but are not limited to) responsibilities of the job, education, experience, knowledge, skills, and abilities, as well as internal equity, alignment with market data, applicable bargaining agreement (if any), or other law.
#Remote
#Featuredjob
Start your job application: click Apply Now
Show Less
Report",3.8,10000+ Employees,1969,Company - Public,Aerospace & Defense,Aerospace & Defense,$10+ billion (USD)
Sr. Data Architect,-1,Planet Fitness3.4 ★,Remote,"About Us:
Founded in 1992 in Dover, NH, Planet Fitness is one of the largest and fastest-growing franchisors and operators of fitness centers in the United States by number of members and locations. We have over 2,400+ stores in 50 states, the District of Columbia, Puerto Rico, Canada, Panama, Mexico, and Australia. More than 90% of Planet Fitness stores are owned and operated by independent business men and women.

At Planet Fitness, our unique mission has always been to enhance people’s lives by providing a high-quality fitness experience in a welcoming, non-intimidating environment. And we’re proud of the amazing Planet Fitness team that supports our clubs and team members. They are comprised of dynamic, dedicated, and talented individuals who represent our values of integrity, transparency, passion, respect, and excellence (while having fun!) in everything they do.

Joining the PF family means being part of a company that cares about bettering the health and wellbeing of our communities. It means being a part of a supportive, engaging workforce with an inclusive culture that values diversity and creates an environment where everyone can feel they belong. It means encouraging professional growth and development. It means making true, lasting connections with your co-workers with celebrations, team building activities and engaging corporate events! It means creating a positive impact in our local communities through our Judgement Free Generation® philanthropic initiative. It means being part of a brand that you can be proud of!

For the past 30 years, we’ve helped millions of people in their fitness journey and revolutionized the industry along the way. And we’re just getting started!
Overview:
The Sr. Data Architect will be responsible for creating and maintaining a scalable enterprise data architecture at Planet Fitness. In this role, you will facilitate the development of data modeling standards, guidelines, and techniques. You will collaborate across the data engineering, business intelligence engineering, and data governance teams to ensure data architectures are consistent and adhere to defined policies and standards. And as our Sr. Data Architect, you will also collaborate with the broader technology organization to implement data management best practices and improve data quality at the source of truth/system of record.

For team collaboration purposes, the ideal candidate currently resides in the CST or EST zones.
Responsibilities:
Create and maintain data architecture designs that support business and technical requirements for high-quality, performant data solutions.
Implement data modeling standards and ensure adherence within data management solutions.
Research and recommend tools and services to improve data management processes and support architectural standards and patterns.
Participate in data solution prototyping initiatives.
Create and maintain documentation related to data architecture standards, protocols, and frameworks.
Implement culture of continuous improvement of data architecture approaches to align to best practices and data management technology evolution.
Foster environment of continuous learning, maintain current knowledge of emerging technologies and industry trends, and present ideas for innovation.
Perform analytical exploration and examination of data from multiple data sources.
Participate in enforcing data quality and governance best practices in the data platform.
Work with a multi-disciplinary team consisting of data analysts, data engineers, developers and data consumers in an agile, fast-paced environment.
Work with and support a team that is globally located.
Participate in review processes that involve architecture, design and quality assurance to preemptively identify conflicts and ensure consistency of implementation.
Ensure strict adherence to documentation best practices and change control processes.
Perform other duties as assigned.
Qualifications:
Bachelor’s degree in Computer Science, Information Technology, Data Analytics, Information Systems or a related field
10+ years of direct experience in Big Data, Data Warehousing, Data Analytics, and/or Information Management related projects
6+ years of direct experience in cloud data solution architectures, design and development including ETL, data warehousing, data lakes, and big data
5+ years of experience using SQL including development of stored procedures, functions, triggers and views
5+ years of direct experience with one or more database/data warehouse technologies (e.g., Oracle, MSSQL, MySQL, PostgreSQL, Hadoop, Teradata, Redshift, Snowflake)
5+ years of direct experience working in a cloud environment such as AWS, Azure or GCP
Excellent critical thinking and problem-solving skills
Must be self-sufficient and proactive
Deep understanding of agile development methods including: core values, guiding principles, and key agile practices
A strong understanding of data mining, predictive modeling, and statistical analysis
Experience working in retail business (preferred)
Experience working in a franchised business (preferred)
Extremely detail-oriented, efficient, and organized with an exceptional ability to establish and balance multiple priorities and objectives
Excellent presentation and communication skills along with the ability to communicate effectively across all levels of the organization
Able to establish and maintain effective, collaborative work relationships with diverse individuals, internally and externally
Creative, progressive, thought leadership with the ability to influence at all levels of the organization
Dedicated learner with a natural curiosity for consistent growth
Exhibits comfort, ease, and flexibility working in an extremely fast-paced ever-changing, deadline-driven environment
Cooperative team player with an upbeat, positive, “can-do” attitude!
Perks:
Remote work allowed
Volunteer days off
Competitive salaries and comprehensive benefits package, including medical, pharmacy, dental and vision benefits
Generous vacation/holiday pay
401(k) Retirement
Employee Stock Purchase Program
Childcare reimbursement
Pet care reimbursement
Learning and development programs
Discount programs, including vacations, theme parks, shopping, meal delivery services & much more
Free Black Card membership and fun exercise incentives
Company-sponsored social events
Apply Now: click Apply Now
Show Less
Report",3.4,201 to 500 Employees,1992,Company - Public,Beauty & Wellness,Personal Consumer Services,$5 to $25 million (USD)
AWS Data Architect,$90.00 Per Hour (Employer est.),Blue Ocean Ventures3.5 ★,"Santa Monica, CA","Responsibilities / Qualifications:
· Candidate must have 10+ years of IT working experience with at least 5 years of experience on AWS Cloud environment is preferred.
· Working experience with Agile Methodology
· Experience working with source code management tools such as GitHub
Experience working with Jenkins or any CI/CD Pipelines using AWS Services
Job Type: Contract
Pay: From $90.00 per hour
Benefits:
401(k)
Dental insurance
Vision insurance
Schedule:
8 hour shift
Day shift
Ability to commute/relocate:
Santa Monica, CA 90401: Reliably commute or planning to relocate before starting work (Required)
Experience:
Data architect: 10 years (Preferred)
Work Location: In person
Speak with the employer
+91 7022159709
Show Less
Report",3.5,51 to 200 Employees,-1,Company - Private,HR Consulting,Human Resources & Staffing,Unknown / Non-Applicable
IT Architect (Azure Data Engineer architect – Synapse Analytics),-1,Ampcus Incorporated3.6 ★,Virginia,"Responsibilities:
Provide technical architecture guidance and expertise in developing, architecting, and maintaining Azure Synapse Analytics end-to-end solution, Azure Databricks, spark pool, and monitoring of high-volume of complex data warehouse and analytical processes.

Experience in designing and architecting end-to-end Analytics solutions in Synapse.
Experience in designing and architecting Change data capture frameworks.
Demonstrable experience in designing and orchestrating data pipelines to load data efficiently in Synapse dedicated SQL Pool.
Experience in Azure Data Lake, Azure Data Factory, Azure data flow, Azure functions and Databricks.
Experience in architecting workload management solutions in Azure Synapse dedicated SQL pool, Serverless pool, and Spark pool.
Experience in architecting solutions to optimize dedicated SQL pools in Azure Synapse Analytics using different data distribution methods, partitioning, and query optimization.
Experience in architecting consumption patterns like Analytical, Operational, Real-time, and bulk consumption patterns.
Experience in optimization of data ingestion, curation, Synapse analytics, analyzing large data sets, and Knowledge of Performance/cost optimization techniques
Experience in large-scale warehouse migration from on-prem to cloud.
PowerBI architect experience is preferred. Relevant certification is a plus.
Show Less
Report",3.6,501 to 1000 Employees,2004,Company - Private,Information Technology Support Services,Information Technology,$25 to $100 million (USD)
Sr Data Engineer,$112K - $152K (Glassdoor est.),Voloridge Investment Management4.7 ★,"Jupiter, FL","At Voloridge Investment Management our quantitative systems are deeply dependent on vast quantities of data. The Senior Data Engineer must understand the many different and evolving use cases for data at Voloridge and design systems that supply high-performance datasets for advanced analytics. In this role the Sr. Data Engineer / Architect will provide mentorship and impart experience to the data engineering team.
Summary of Job Functions
Collaborate effectively with Stakeholders, Project Managers, Software Engineers, Data Analysts, QA Analysts, DBAs, and Data Engineers
Build and maintain data pipelines based on functional and non-functional requirements
Proactively seek out information and overcome obstacles to deliver projects efficiently
Ensure that data pipelines incorporate best practices related to performance, scaling, extensibility, fault tolerance, instrumentation, and maintainability
Ensure that data pipelines are kept simple and not overly engineered
Produce and maintain design and operational documentation
Analyze complex data problems and engineer elegant solutions
Stay abreast of emerging technologies and make relevant recommendations
Upgrade existing data models and pipelines leveraging newer features and techniques
Work in a Kanban environment
Mentor less experienced data engineers
Participate in engineering standards and best practices evolution
Participate in an on-call rotation
Lead investigations to troubleshoot pipeline issues
Minimum Requirements
10+ years with hands-on data engineering and deep knowledge of data architecture fundamentals including:
Extensive experience building ETL/ELT pipelines from a variety of data sources
Broad experience with SQL Server 2019+, including advanced SQL Server features such as Table Partitioning, Columnstore
Deep knowledge and measurable experience in performance tuning TSQL, execution plan analysis blocking/deadlock analysis and index optimization
Extensive experience using SSMS to create and maintain SQL Server tables, views, functions, stored procedures, and user-defined table types
Comprehensive experience with data modeling indexes, Temporal tables, CLR, and Service Broker
Deep understanding of the development of data pipelines with either SSIS or Python and building data pipelines using multiple external data sources and transport mechanisms
Strong initiative, collaboration, accountability, impartiality, and communication
Strong analytical skills, a real passion for working with data and strong interest in solving data problems
Strong track record for judging core requirements and meeting deadlines
Experience managing master data
Experience writing C#, PowerShell, and Python
Experience with Git source control integration with SSMS
Experience working in a Kanban SDLC and a strong understanding of traditional Kanban SDLC workflows
Experience with deploying changes through segregated Development, QA, UAT and Production SDLC stages
Experience owning mission-critical processes
Bachelor’s degree in Computer Science, Information Systems, or related disciplines
Ability to work onsite in our Jupiter, FL office
Preferred Skills and Previous Experience
Python programming using libraries such as Pandas, Numpy, csv, Traceback, JSON, PyODBC, Math
Experience with source code branching and pull requests / code reviews
Experience with AWS
Experience working with trading / financial / investment / accounting data
Experience with tools such as Red Gate, Grafana, OpsGenie and JAMS
Experience with MPP databases such as Greenplum
MS/PhD in Computer Science, Information Systems, or related disciplines
Compensation and Benefits
Highly competitive base salary
Profit sharing bonus
Health, dental, vision, life, and disability insurance
401K
Additional Information
Voloridge Investment Management is an SEC registered investment advisor. A private investment company founded in 2009, our mission is to deliver superior risk-adjusted returns for qualified investors, using advanced proprietary modeling technology, conservative investment tactics and sophisticated risk management.
Voloridge Investment Management is an Equal Opportunity Employer. All qualified applicants are encouraged to apply and will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, protected veteran status, or any other legally protected characteristic or status.
Show Less
Report",4.7,51 to 200 Employees,2009,Company - Private,Investment & Asset Management,Financial Services,Unknown / Non-Applicable
Azure Data Architect,$70.00 - $80.00 Per Hour (Employer est.),VaaridaTech,Remote,"Job Description:
More than 10 years of experience in leading the design and development of data and analytics projects in a global company.
Experience in working for projects across cross functional teams, building sustainable processes and coordinating release schedules.
MS SQL experience with data modeling
Experience in working with Microsoft Azure and strong knowledge about ADLS, Blob Storage, Data Factory, SQL Server, and Warehouses.
Experience in Cloud based EDW platforms (Snowflake, Synapse, Redshift, Big Query etc.)
Build and launch new data models that provide intuitive analytics for the analysts and customers.
Help build high performance and flexible streaming pipelines that can rapidly evolve to handle new technologies, techniques, and modeling approaches.
Build data expertise and own data ingestion pipelines.
Write complex ETL processes and framework using Azure Data Factory ADF
Implement large-scale near real-time streaming data processing pipelines.
Strong knowledge of Spring frameworks Experience with Kafka messaging platform
Experience with Big Data/streaming platforms such as Spark, Flink, Kafka Streams, and/or EventHub
Experience using Azure Cloud (Azure vm, Azure cognitive search, HDI, Azure functions, ADLS, etc.)
Familiarity with containers, micro-services and APIs Experience working with different operating systems (Unix, Windows, Linux)
Job Type: Contract
Pay: $70.00 - $80.00 per hour
Schedule:
8 hour shift
Monday to Friday
Experience:
Data modeling (Preferred)
Work Location: Remote
Speak with the employer
+91 7039531330
Show Less
Report",-1,Unknown,-1,Company - Public,-1,-1,Unknown / Non-Applicable
Data Engineer,$150K - $180K (Employer est.),"Amino, Inc.4.4 ★","San Francisco, CA","About Amino - What We Do
At Amino, we are a leading innovator in healthcare, empowering individuals to take charge of their healthcare journey. Our powerful digital tools help navigate and unlock the full potential of health plan options. With Amino's cutting-edge solutions, health plan members can easily understand and make informed decisions about their benefits, considering factors such as available programs, provider network quality, and cost.
We are excited to announce that we have recently secured additional funding to fuel our growth and continue developing market-leading navigation tools. As part of this journey, we are looking for a talented and driven Data Engineer to join us. You will play a vital role in helping millions of people understand and optimize their health plan options.
The Role
As a Data Engineer at Amino, you will be at the heart of our organization. Your primary responsibilities will involve processing, transforming, and organizing large and complex datasets that power our products. We are expanding our data sources and enhancing our current offerings, and we need a Data Engineer to help us build competitive and compliant healthcare guidance products.
Key Priorities and Projects:
Collaborate with Product Managers, Architects, and senior leadership to translate high-level requirements into detailed plans.
Integrate new data sources from vendors and internal systems into our ETL (Extract, Transform, Load) pipelines.
Enhance our editorial tools for creating and maintaining accurate data about health entities.
Modernize our orchestration infrastructure using open-source tools like dbt and Dagster.
Impact you will have:
Revamp and expand critical data pipelines that drive our existing and future products.
Mentor other junior data engineers and share your expertise.
Collaborate closely with data scientists and software engineers in related teams.
Influence the foundational aspects of data modeling and warehousing, benefiting various teams across the company.
Utilize modern data stack technologies to build the foundation for Amino's next-generation data assets.
Technologies you will work with:
Snowflake, Python 3, dbt, Docker, AWS, Looker, Databricks, Spark, Jenkins CI/CD, Airflow, Dagster, Terraform, PostgreSQL, RDS, Elasticsearch, and Kinesis.
Skills and Experience you should possess:
Familiarity with various relational and non-relational databases.
Proficiency in writing clean and well-tested code using Python.
Experience handling and working with large datasets and the associated tools.
Previous exposure to ETL pipelines and familiarity with data modeling and data warehousing best practices (experience with dbt is preferred).
Strong collaboration and feedback skills, with a willingness to seek and incorporate input from others.
Excellent documentation and verbal communication skills, capable of conveying technical concepts to peers and non-technical stakeholders.
Bonus Skills:
Experience handling PHI or PII
Deep understanding of the healthcare domain, particularly with healthcare claims data.
We offer
We're committed to helping you achieve your best work in a supportive, growth-oriented environment. We have seriously big goals, and expectations are high and we'll equip you with the tools and resources you need to be successful.
Expected base salary: $150k to $180k plus standard company benefits and a generous option grant. Amino values transparency and has included the reasonable estimate of the base salary range for this full-time role at any approved US location. Individual pay is determined by a range of factors, including job-related skills, experience, relevant education or training, licensure or certifications, and other business and organizational needs. Amino does not typically hire at or near the top of a salary range.
We offer full-time employees 100% paid employee healthcare premiums; dependent premium coverage depends on the plan.
401(k) and FSA programs
This position, like all roles at the firm, will have a good deal of autonomy. We're a remote-first team and have designed our culture for a balance of synchronous and asynchronous work with people operating from all over the country. To support your remote office, we provide every new Amino with a generous office set-up allowance plus a monthly stipend for internet/phone.
PTO is non accrual and we expect Amino's to take a minimum of 15 days a year.

We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. We know the reputation and track record that the tech industry has, and work hard to be exceptional in this regard.
Our Culture
We are a small team who believes that success is a group activity. You should expect to learn from everyone at Amino, and be excited to share your knowledge. You will play a big part in influencing the shape of the product and be empowered to provide your thoughts and ideas.
We believe in collaboration, respect, and curiosity. We believe in having a growth mindset, and have a passion for solving problems that have never been faced before. Everyone's input is valued, be it about code, data models, business models, or product ideas.
Show Less
Report",4.4,1 to 50 Employees,2013,Company - Private,Internet & Web Services,Information Technology,Unknown / Non-Applicable
AWS Data Architect,$80.98 - $85.82 Per Hour (Employer est.),Reveille Technologies3.3 ★,"Santa Monica, CA","Role : AWS Data Architect
Location : Santa Monica, CA or Raleigh, NC (hybrid)
Responsibilities / Qualifications:
Candidate must have 10+ years of IT working experience with at least 5 years of experience on AWS Cloud environment is preferred
Experience and knowledge of AWS Cloud Architectures, Databases, Data models and Data integration patterns.
Conduct data profiling activities, discover data quality challenges, document the impacts to business and make recommendations for data quality improvements
Expertise in defining new architectures and ability to drive project from architecture standpoint with AWS Cloud platform.
Experience with Ingestion & Transformation framework development and enhancements
Define and design Data pipeline architecture for data ingestion processes using AWS native services.
Design and optimize data models on AWS Cloud using AWS data stores such as Redshift, RDS, S3, Glue Data Catalog, Python, Lake formation, etc
Provide direction, guidance, and oversight for data quality controls.
Identify opportunities for standardizing data descriptions, integration and archiving, and elimination of unnecessary redundancy.
Design and optimize data governance framework including the management of data, operating model, data policies and standards.
Participate in client design workshops and provide trade-offs and recommendations towards building solutions.
Collaborating with teams to resolve technical requirements, feasibility, and expectations.
Working experience with Agile Methodology
Experience working with source code management tools such as GitHub
Experience working with Jenkins or any CI/CD Pipelines using AWS Services
Thanks
Subha Shyamli
Reveille Technologies Inc.,
Direct:(336) 499-9244
Email: Subha@reveilletechnologies.com
https://www.linkedin.com/in/subha-shyamli-5b6935170/
www.reveilletechnologies.com
Job Type: Contract
Salary: $80.98 - $85.82 per hour
Schedule:
8 hour shift
Ability to commute/relocate:
Santa Monica, CA 90401: Reliably commute or planning to relocate before starting work (Required)
Experience:
AWS: 1 year (Preferred)
Work Location: In person
Show Less
Report",3.3,1 to 50 Employees,-1,Company - Private,Information Technology Support Services,Information Technology,$5 to $25 million (USD)
Data Architect,-1,FPT Software3.9 ★,Remote,"Data Architect
Job Type: Full time
Workplace: Atlanta, GA
Responsibility:
Data Operations and Analytics support to process data from Google Analytics platform to Snowflake
Provide architecture and development for a automated and continuous data pipeline from a Cox operated Google Big Query environment to a Cox operated AWS Snowflake environment
Develop transformation routines in Snowflake for ingested Google Analytics data.
Prepare design and QA plans for Above Process
Provide Google Big Query configuration assistance
Provide Data Operations orchestration for timing, alerting of the data pipeline
Learn and retain knowledge of business and team development processes
Create regular status reporting
Knowledge sharing between onshore team and between members of offshore team
Contribute to the on-going development of best practices, identification of suitable new tools and system and service improvements
Develop solutions in-line with in-house standards and practices.
Coordinate with Offshore team
Qualifications (Required):
Bachelor’s and/or master’s degree in computer science or related field
Five+ years of experience delivering high quality software products
Strong experience/working knowledge in designing architecture of with Google Big Query, Snowflake and associated data pipeline technologies
Knowledge with Google Analytics
Proven track record working on high volume, large databases that require performance tuning.
Familiarity with Jenkins/GIT dev ops
In-depth knowledge and experience of the software development lifecycle
Having experience to work/lead onsite/offshore model team.
Strong communication skills. Able to easily collaborate with peers and customers.
Technical Leadership: driving the team, work through complicated situations, problems. Get things done in very short time duration.
Experience delivering software in an Agile or Lean delivery method
Strong SQL query knowledge
Experience in production support design decisions with our business partners and the rest of the development team membersJob Description
We are looking for a Data Warehouse Architect to join our team. The Data Warehouse Architect will be responsible for designing, implementing, and maintaining data warehouse solutions. The ideal candidate will have a strong understanding of the data warehousing process and data warehouse architecture. This position will also be responsible for designing and implementing data warehouse solutions, including storage, analysis, and reporting.
Qualifications
Bachelor’s degree in Computer Science or a related field
5+ years of experience in designing, implementing, and maintaining data warehouse solutions
Experience with relational databases and ETL tools
Experience with database administration, query optimization, and ETL scripting
Experience with SSIS and reporting tools
Experience with database administration and reporting tools (e.g., SQL Server)
Experience with project management tools (e.g., Microsoft Project)
Ability to work independently with minimal supervision
Ability to work well in a team environment as well as independently
Job Type: Contract
Schedule:
8 hour shift
Application Question(s):
How much rate you expected for this position ?
Experience:
Data Architect: 5 years (Preferred)
Big Query: 4 years (Preferred)
Snowflake: 4 years (Preferred)
Work Location: Remote
Show Less
Report",3.9,10000+ Employees,1999,Company - Public,Information Technology Support Services,Information Technology,$500 million to $1 billion (USD)
Senior Data Architect,$85.00 - $90.00 Per Hour (Employer est.),Teamware Solutions (quantum leap consulting).4.5 ★,"New York, NY","Role: Azure Databricks Architect with PySpark and Snowflake exp
Location: NYC, NY (1271 Avenue of the Americas, New York, NY 10020) - 100% onsite from Day 1.
Max Rate: $90/hr on c2c
Exp level : 15+ years
Skills:
Great hands-on experience with Azure Databricks platform. Extensive experience in PySpark coding.
Excellent written and verbal communication, intellectual curiosity, a passion to understand and solve problems, consulting & customer service
Structured and conceptual mindset coupled with strong quantitative and analytical problem-solving aptitude
Exceptional interpersonal and collaboration skills within a team environment
Responsibilities:
Design, develop, and deploy Databricks jobs to process and analyze large volumes of data.
Collaborate with data engineers and data scientists to understand data requirements and implement appropriate data processing pipelines.
Optimize Databricks jobs for performance and scalability to handle big data workloads.
Monitor and troubleshoot Databricks jobs, identify and resolve issues or bottlenecks.
Implement best practices for data management, security, and governance within the Databricks environment.
Job Type: Contract
Salary: $85.00 - $90.00 per hour
Schedule:
8 hour shift
Ability to commute/relocate:
New York, NY: Reliably commute or planning to relocate before starting work (Required)
Experience:
Data modeling: 1 year (Preferred)
Work Location: In person
Show Less
Report",4.5,1001 to 5000 Employees,2003,Company - Private,Information Technology Support Services,Information Technology,Unknown / Non-Applicable
Azure Data Architect,$150K - $180K (Employer est.),Hitachi Vantara Corporation3.3 ★,Remote,"Position Overview:
We are looking for a highly skilled Azure Data Architect to join our team. As an Azure Data Architect, you will be responsible for designing and implementing scalable and efficient data architecture solutions on the Azure cloud platform. Your primary focus will be on creating robust data models, optimizing data storage and retrieval, and ensuring the overall integrity and security of data. You will collaborate with cross-functional teams to understand business requirements and translate them into effective data architecture solutions that support data-driven decision-making.

Responsibilities:
Design and implement end-to-end data architecture solutions on the Azure cloud platform.
Collaborate with business stakeholders, data engineers, and data scientists to understand data requirements and design scalable and flexible data models.
Develop data ingestion strategies and frameworks to efficiently capture and integrate data from various sources into Azure data services.
Define data storage and retrieval mechanisms, including data partitioning, indexing, and compression, to optimize performance and cost efficiency.
Implement data governance and data management practices to ensure data quality, consistency, and compliance with relevant regulations.
Create and maintain data pipelines and ETL/ELT processes to transform, cleanse, and integrate data across different data sources.
Collaborate with security and compliance teams to establish and enforce data security measures, including data encryption, access controls, and data masking.
Perform data profiling, analysis, and troubleshooting to identify and resolve data-related issues.
Stay up to date with the latest advancements in Azure data services and recommend innovative solutions to enhance data architecture capabilities.
Provide technical guidance and mentorship to junior team members and promote best practices in data architecture design and implementation.

Qualifications:
Bachelor's or Master's degree in Computer Science, Engineering, or a related field.
Extensive experience designing and implementing data architecture solutions on the Azure cloud platform.
Strong proficiency in Azure data services such as Azure SQL Database, Azure Synapse Analytics, Azure Data Lake Storage, Azure Databricks, and Azure Cosmos DB.
Deep understanding of data modeling principles and experience with relational, dimensional, and NoSQL data modeling techniques.
Solid knowledge of ETL/ELT processes, data integration patterns, and data warehouse concepts.
Familiarity with big data processing frameworks like Apache Spark or Hadoop.
Proficiency in SQL and programming languages such as Python or Scala.
Experience with data governance, data security, and compliance practices in Azure.
Strong problem-solving and analytical skills with the ability to troubleshoot and resolve complex data-related issues.
Excellent communication and collaboration skills to work effectively with stakeholders at all levels.
Ability to manage multiple projects and priorities in a fast-paced and dynamic environment.

Preferred Qualifications:
Relevant certifications in Azure or data architecture.
Experience with streaming data processing using technologies like Apache Kafka or Azure Event Hubs.
Knowledge of machine learning and AI technologies and their integration with data architecture.
Understanding of data visualization and reporting tools.
Familiarity with DevOps practices and CI/CD pipelines in the context of data architecture.
As required by the equal pay and transparency acts, the expected base salary for this position is $150k-$180k + Bonus+ Benefits
The expected pay is determined based on a variety of factors including, but not limited to, depth of experience in the practice area. Employees are eligible to participate in Hitachi Vantara's bonus/variable/commission pay programs, where applicable, and are subject to the program's conditions and restrictions.
Our Company
Hitachi Vantara is part of the Global Hitachi family. We balance innovation with an open, friendly culture and the backing of a long-established parent company, known for its ethical reputation. We guide customers from what's now to what's next by unlocking the value of their data and applications to solve their digital challenges, achieving outcomes that benefit both business and society.
Our people are our biggest asset, they drive our innovation advantage and we strive to offer a flexible and collaborative workplace where they can thrive. Diversity of thought is welcomed and our employee base is represented by several active Employee Resource Group communities. We offer industry leading benefits packages (flexible working, generous pension and private healthcare) and promote a creative and inclusive culture. If driving real change gives you a sense of pride and you are passionate about powering social good, we'd love to hear from you.
Our Values
We strive to create an inclusive environment for all and are open to considering home working, compressed/flexible hours and flexible arrangements. Get in touch with us to explore how we might be able to accommodate your specific needs.
We are proud to say we are an equal opportunity employer and welcome all applicants for employment without attention to race, colour, religion, sex, sexual orientation, gender identity, national origin, veteran or disability status. With Japanese roots going back over 100 years, our culture is founded on the values of our parent company expressed as the Hitachi Spirit:
Wa – Harmony, Trust, Respect
Makoto – Sincerity, Fairness, Honesty, Integrity
Kaitakusha-Seishin – Pioneering Spirit, Challenge
#LI-MS2
To apply to this job, click Apply Now
Show Less
Report",3.3,10000+ Employees,1989,Subsidiary or Business Segment,Information Technology Support Services,Information Technology,Unknown / Non-Applicable
Data Warehouse Architect,$84K - $117K (Glassdoor est.),Intellibee Inc4.5 ★,"Lansing, MI","Job Title: Data Warehouse Architect
Location: Lansing, MI
Designs, implements and supports data warehousing.
Implements business rules via stored procedures, middleware, or other technologies.
Defines user interfaces and functional specifications.
Responsible for verifying accuracy of data, and the maintenance and support of the data warehouse.
Knowledge of data warehouse end-to-end implementation processes, from business requirement logical modeling, physical database design, ETL, end-user tools, database, SQL, performance tuning.
Demonstrated problem resolution skills with team of persons, and strong leadership with implementation team.
Experience in data warehouse design and data modeling (both relational and dimensional) and development and maintenance of multi-dimensional data models.
Development experience in implementation of data warehousing utilizing RDBMS.
Understanding of data warehouse Metadata concepts, tools and different data warehouse methodologies.
Expertise in SQL and proficiency in database tuning techniques.
Responsible for the ongoing architecture and design of the data warehouse, data mart, and reporting environments.
Develop strategies for flexibility and scalability, and define the future technical architecture direction for the business intelligence reporting physical environment.
Relies on experience and judgment to plan and accomplish goals, independently performs a variety of complicated tasks, a wide degree of creativity and latitude is expected.
Responsible for proper selection of appropriate hardware, software, tools and system lifecycle techniques for the different components of the end-to-end data warehouse architecture including ETL, metadata, data profiling software, database platform, performance monitoring, reporting and analytic tools.
Defining and documenting the technical architecture of the data warehouse, including the physical components and their functionality.
Setting or enforcing standards and overall architecture for data warehouse systems.
Monitoring the data warehousing industry and assisting in establishing the organization's data warehousing strategy and section of strategic warehousing tools and techniques.
Ensuring compatibility of the different components of the DW architecture and ensuring alignment with broader IT strategies and goals.
Ability to educate the project teams on the standards and architecture of each component of the data warehouse architecture.
Very strong written and oral communication skills, including some presentation skills.
Years of experience: 8 or more years of experience in the field
Roles and Responsibilities:
Participates in designing, developing and refining the client Azure database services to ensure that it is secure, reliable, and robust. Implements changes to the Azure environment to increase performance and efficiencies.
Develops and implements detection and disaster recovery activities to test Azure services; participates in detecting, investigating, documenting, and reporting actual or potential Azure environment security violations, intrusions, failures, performance or other issues.
Designs Azure data migration backbone infrastructure, to provide reliable, optimized, high performance cloud services.
Design CEDS (Common Education Data Standard) complaint database and data structure in Azure environment.
Evaluates security products and tests security systems performance; assists in planning, implementing, and testing disaster recovery procedures; participates in making formal risk assessments related to the client Azure environment.
Required:
TSQL: 10+ Years
PowerShell: 6+ Years
Azure DevOps: 6+ Years
Scrum: 6+ Years
Job Types: Full-time, Contract
Schedule:
8 hour shift
Experience:
Data modeling: 5 years (Preferred)
TSQL: 10 years (Preferred)
PowerShell: 6 years (Preferred)
Azure DevOps: 6 years (Preferred)
Scrum: 6 years (Preferred)
Work Location: On the road
Show Less
Report",4.5,1 to 50 Employees,-1,Company - Public,-1,-1,Unknown / Non-Applicable
"Software Engineer, Data Products",$119K - $163K (Glassdoor est.),LaunchDarkly4.1 ★,"Oakland, CA","Please note, before progressing to our application, this position is based in the San Francisco Bay Area and not suitable for remote candidates.
About the Job:
We are looking for exceptional Software Engineers to make a profound impact on how data products will be integrated into companies' software in the future. We are integrating data into everything LaunchDarkly offers on top of our unrivaled feature management platform.
As a Data Products - Software Engineer, you will help us architect and write fast, reliable, and scalable data processing tools to process data from our thousands of customers and their hundreds of millions of users around the world. We're looking for someone who knows what it takes to deliver value to customers and takes pride in the quality of their work.
The primary technologies we use daily include Golang, Scala, Kinesis, and Flink. If working as a part of such a poly-functional team to bring to change how experimentation is done forever appeals to you then come join the Experimentation team at LaunchDarkly.
Responsibilities:
Build and expand our data platform and services
Help us identify the best technologies for our evolving data needs
Collaborate with product team to spec and deliver user-facing features
Monitor and improve data pipeline performance
Actively participate in code reviews
Improve engineering standards, tooling, and processes
Qualifications:
Proven experience and fluency in a JVM or functional language
Experience building data platforms (e.g. using Flink, Kafka, DataFlow, Hadoop, Spark)
Strong communication skills, a positive attitude, and empathy
You write code that can be easily understood by others, with an eye towards maintainability
You hold yourself and others to a high bar when working with production systems
You value high code quality, automated testing, and other engineering best practices
Pay:
Target pay range for a Level P3 in San Francisco/Bay Area: $144,000 - $169,000*
Restricted Stock Units (RSUs), health, vision, and dental insurance, and mental health benefits in addition to salary.
LaunchDarkly operates from a place of high trust and transparency; we are happy to state the pay range for our open roles to best align with your needs. Exact compensation may vary based on skills, experience, degree level, and location.
About LaunchDarkly:
LaunchDarkly is a Feature Management Platform that serves trillions of feature flags daily to help software teams build better software, faster. Feature flagging is an industry standard methodology of wrapping a new or risky section of code or infrastructure change with a flag. Each flag can easily be turned off independent of code deployment (aka ""dark launching""). LaunchDarkly has SDKs for all major web and mobile platforms. We are building a diverse team so that we can offer robust products and services. Our team culture is dynamic, friendly, and supportive. Our headquarters are in Oakland.
At LaunchDarkly, we believe in the power of teams. We're building a team that is humble, open, collaborative, respectful and kind. We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, gender identity, sexual orientation, age, marital status, veteran status, or disability status.
One of our company values is 'Widen the Circle'. Which means we seek out diversity of perspectives to get better results. We understand everyone has their own unique talents and experiences. We encourage you to apply to this role even if you don’t think you meet 100% of the qualifications outlined above. We can find out together if it's the right match for your skillset.
We've partnered with KeyValues to help demonstrate the amazing culture we've built here at LaunchDarkly, find more info at https://www.keyvalues.com/launchdarkly.
LaunchDarkly is also committed to giving back to our community and is a part of Pledge 1%, an organization that helps companies make this a priority. Through this initiative and its charitable arm, the LaunchDarkly Foundation, the company is committed to such causes as supporting education for the underserved, homelessness relief and moving towards having a net-zero carbon footprint. You can find more about the LaunchDarkly Foundation and the organizations we serve at https://launchdarkly.com/foundation/.
Do you need a disability accommodation?
Fill out this accommodations request form and someone from our People Operations team will contact you for assistance.
Show Less
Report",4.1,501 to 1000 Employees,2014,Company - Private,Enterprise Software & Network Solutions,Information Technology,$100 to $500 million (USD)
GCP Data Modeler/ Architect,$70.00 Per Hour (Employer est.),Infinity Quest4.0 ★,"Dublin, OH","Qualifications & Experience
Required
· Must have designed, developed, and supported a complex software solution.
· Proficient in SQL.
· Good Understanding in dimensional/multidimensional data modeling.
· Experience with graph, transactional, and operational data modeling is a plus.
· Familiarity with all stages of the product development cycle. Experience maintaining engineering best practices, including defect tracking, design reviews, and appropriate testing.
· Hold strong organizational and problem-solving skills.
· Take a pragmatic, product-oriented approach.
· Possess the ability to work cross-functionally with minimal supervision.
Preferred
· B.S. in Computer Science, Electrical Engineering, Mathematics, Statistics, Physics, or similar quantitative fields/work experience.
· Experience with cloud environments
· 7+ years of experience in data modeling.
· 3-7+ years of experience in at least one scripting language (Python, Perl, JavaScript, Shell)
· 2+ years of experience working on streaming data applications
· 3+ years of experience with Agile engineering practices
· 3+ years of experience developing Java-based software solutions, scripting and OOP languages
· 3+ years of experience with UNIX/Linux, including basic commands and shell scripting
· 2+ years of experience with GCP
· 1+ years in the healthcare industry and knowledge of their business practices.
Job Type: Contract
Salary: From $70.00 per hour
Schedule:
8 hour shift
Experience:
Data modeling: 1 year (Required)
Python: 1 year (Required)
DVT: 1 year (Required)
Data Validation Tool: 1 year (Required)
Terraform: 1 year (Required)
BigQuery: 1 year (Required)
Work Location: On the road
Show Less
Report",4.0,201 to 500 Employees,2006,Company - Private,Information Technology Support Services,Information Technology,Unknown / Non-Applicable
Data Architect,$70.00 - $75.00 Per Hour (Employer est.),American Unit Inc4.3 ★,Remote,"Hello,
My name is James work as a Technical Recruiter at American Unit Inc.
Below is the Job Description, If you are interested please share me your updated resume along with the contact details to james@americanunit.comor call me at (214) 286 5251.
Role: Data Architect with PBM (Pharmacy Benefit Management)
Location: Remote
Duration: Long term Contract
Client: LTI Mindtree/ UHG (United Health Group Inc)
Job Description:
Looking for Pharmacy Benefit Management / Part -D Data Architecture and Data Domain Experience.
Looking for someone who has actually worked with a PBM such as express script caremark OntumRx Medlmanct, Prime Therapeutics, Argus Health or other Tier 2 Pharmacy Benefit Administrator.
Data Architecture, Data Engineering, Data Management, Cloud Data Management etc. with a PBM client asap.
Roles and Responsibilities:
· Lead successful delivery of Centene – PBM NBI Medicaid Plans Implementationsacross 21 US States, Commercial Plans, Centene Employee Benefits & Ambetter Exchanges Plans Implementations, SHARP Healthcare, Health Partners Plans of PA, and Anthem Medicaid Plans Implementations
· NBI Implementation direct discussions with Centene PBM Stakeholders
· Managing the delivery of NBI [New Business Implementation] & MOB [Maintenance of Benefits] cases on daily basis
· Defect Manager in setting up War room calls, collaborate with all primary stakeholders such as BRMs, Clinical Team, Coders, Pharmacy and Network Pricing Team, Testing Team, CVS Health RxClaim IT Team etc. to bring out the issues on to closure
· Daily Scrum and Operations call status with Client Stakeholders
· Prepare RTM to track against Requirements
· Prepare Issues Report
· Collaboration with multi-vendor onshore and offshore team
· Analyze Production Correction Issues and present RCAs
· Present RCA Improvement action plan to improve quality standards
· Mentoring and training project members to enable them to perform their activities effectively
Thanks & Regards
James
Sr.Technical Recruiter
American Unit, Inc
2901 Dallas Pkwy, Suite 333, Plano, TX -75093
✉: james@americanunit.com;
☎: +1 (214) 286 5251
: https://www.linkedin.com/in/james-au-111914229/
http://www.americanunit.com
Job Type: Contract
Salary: $70.00 - $75.00 per hour
Experience:
Pharmacy Benefit Management: 1 year (Required)
Work Location: Remote
Speak with the employer
+91 8977644995
Show Less
Report",4.3,201 to 500 Employees,2003,Company - Private,Enterprise Software & Network Solutions,Information Technology,$25 to $100 million (USD)
Big Data Architect,$93K - $166K (Employer est.),PSRTEK4.5 ★,"Denver, CO","Role: Data Architect
Location: Denver CO, (Day 1 Onsite)
Job Description
Big Data Architect experienced to Manage the Data with core foundational Data Architecture knowledge (12 to 15+yrs)
Data Archival, taxonomy, classification, Tagging,
Business Cataloging
Access control to Data
Data Governance
Data Management
Data Archival
Build Business glossary
Build Metadata
AWS Technologies skills or any cloud technologies a plus
Job Type: Contract
Salary: $92,559.20 - $165,638.64 per year
Ability to commute/relocate:
Denver, CO 80014: Reliably commute or planning to relocate before starting work (Required)
Experience:
Big Data: 10 years (Preferred)
Work Location: In person
Speak with the employer
+91 609-934-3291
Show Less
Report",4.5,Unknown,-1,Company - Private,Information Technology Support Services,Information Technology,Unknown / Non-Applicable
"Engineering Director, Commercial Data Engineering",$170K - $255K (Employer est.),Amex4.2 ★,"Phoenix, AZ","You Lead the Way. We’ve Got Your Back.
With the right backing, people and businesses have the power to progress in incredible ways. When you join Team Amex, you become part of a global and diverse community of colleagues with an unwavering commitment to back our customers, communities and each other. Here, you’ll learn and grow as we help you create a career journey that’s unique and meaningful to you with benefits, programs, and flexibility that support you personally and professionally.
At American Express, you’ll be recognized for your contributions, leadership, and impact—every colleague has the opportunity to share in the company’s success. Together, we’ll win as a team, striving to uphold our company values and powerful backing promise to provide the world’s best customer experience every day. And we’ll do it with the utmost integrity, and in an environment where everyone is seen, heard and feels like they belong.
Join Team Amex and let's lead the way together.

As part of our diverse tech team, you can architect, code and ship software that makes us an essential part of our customers’ digital lives. Here, you can work alongside talented engineers in an open, supportive, inclusive environment where your voice is valued, and you make your own decisions on what tech to use to solve challenging problems. Amex offers a range of opportunities to work with the latest technologies and encourages you to back the broader engineering community through open source. And because we understand the importance of keeping your skills fresh and relevant, we give you dedicated time to invest in your professional development. Find your place in technology on #TeamAmex

How will you make an impact in this role?
We’re looking for an experienced data engineering leader to join our Commercial Data Engineering organization. We build data-centric solutions to support the Global Commercial Services product suite including B2B payments, large corporate clients, and our small and medium enterprise ecosystem. You’ll lead your team and partner cross functionally to create innovative, scalable, resilient data systems that enable us to unlock the value of our data for all of our products.
Cultivate an environment of continuous improvement through technical guidance, coaching, mentoring, and feedback.
Lead one or more data engineering teams that iterate on our large-scale distributed, high-performance data platform.
Establish and maintain strong relationships with key stakeholders and cross functional partners to deliver collaboratively.
Perform hands-on architecture, design, development, and testing.
Drive high-level & detailed technical designs and conduct designs & code reviews as needed.
Implement process improvements to streamline areas for your team such as hiring, onboarding, software delivery, and internal/external communication.
Recruit and retain engineering talent.

Minimum Qualifications
Excellent written and verbal communication skills.
Expertise with a major cloud vendor (AWS/GCP).
Expertise with spark, python, SQL.
Experience leading high-performing data engineering teams focused on iterative delivery.
Experience partnering cross functionally and being a hands-on leader to drive successful execution.
Experience with CI/CD and strong understanding of implementing iterative software delivery practices.
Preferred Qualifications
Experience building unified data driven solutions with a data-lakehouse architecture.
Experience building event driven data streaming solutions
Salary Range: $170,000.00 to $255,000.00 annually + bonus + equity (if applicable) + benefits
The above represents the expected salary range for this job requisition. Ultimately, in determining your pay, we'll consider your location, experience, and other job-related factors.
We back our colleagues and their loved ones with benefits and programs that support their holistic well-being. That means we prioritize their physical, financial, and mental health through each stage of life. Benefits include:
Competitive base salaries
Bonus incentives
6% Company Match on retirement savings plan
Free financial coaching and financial well-being support
Comprehensive medical, dental, vision, life insurance, and disability benefits
Flexible work arrangements and schedules with hybrid and virtual options with Amex Flex
20+ weeks paid parental leave for all parents, regardless of gender, offered for pregnancy, adoption or surrogacy
Free access to global on-site wellness centers staffed with nurses and doctors (depending on location)
Free and confidential counseling support through our Healthy Minds program
Career development and training opportunities
For a full list of Team Amex benefits, visit our Colleague Benefits Site.
At American Express, you’ll be recognized for your contributions, leadership, and impact—every colleague has the opportunity to share in the company’s success. Together, we’ll win as a team, striving to uphold our company values and powerful backing promise to provide the world’s best customer experience every day. And we’ll do it with the utmost integrity, and in an environment where everyone is seen, heard and feels like they belong.
American Express is an equal opportunity employer and makes employment decisions without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, veteran status, disability status, age, or any other status protected by law.
We back our colleagues with the support they need to thrive, professionally and personally. That's why we have Amex Flex, our enterprise working model that provides greater flexibility to colleagues while ensuring we preserve the important aspects of our unique in-person culture. Depending on role and business needs, colleagues will either work onsite, in a hybrid model (combination of in-office and virtual days) or fully virtually.
US Job Seekers/Employees - Click here to view the “Know Your Rights” poster and supplement and the Pay Transparency Policy Statement.
If the links do not work, please copy and paste the following URLs in a new browser window: https://www.dol.gov/agencies/ofccp/posters to access the three posters.
Start your job application: click Apply Now
Show Less
Report",4.2,10000+ Employees,1850,Company - Public,Financial Transaction Processing,Financial Services,$10+ billion (USD)
Data Architect,$65.00 - $75.00 Per Hour (Employer est.),Synkriom Technology Pvt. Ltd.4.5 ★,Remote,"Responsibilities:
Collaborate with clients to understand their data integration needs and requirements.
Design, develop, and implement data integration solutions using TAMR platform.
Configure and customize TAMR workflows, data models, and matching rules to ensure accurate and efficient data integration.
Develop and maintain data pipelines using Python for extracting, transforming, and loading data from various sources into TAMR.
Utilize AWS, Azure, and Snowflake to build scalable and secure data infrastructure and optimize data processing and storage.
Perform data quality analysis and identify opportunities for data cleansing and enrichment.
Collaborate with cross-functional teams including data engineers, data scientists, and business analysts to deliver comprehensive data integration solutions.
Conduct testing and troubleshooting of data integration processes to ensure data accuracy and integrity.
Qualifications:
Bachelor's degree in Computer Science, Information Systems, or a related field.
3-5 years of hands-on experience in data integration projects, preferably using TAMR.
Strong proficiency in Python programming language for data manipulation and transformation.
Experience working with cloud platforms such as AWS and Azure, including data storage, compute, and analytics services.
Familiarity with Snowflake data warehouse and its integration with data integration tools.
Solid understanding of data integration concepts, data modeling, and ETL/ELT processes.
Knowledge of data quality assessment and data governance practices.
Strong analytical and problem-solving skills with the ability to handle complex data integration challenges.
Excellent communication and collaboration skills to work effectively with clients and cross-functional teams.
Ability to adapt to a fast-paced and dynamic work environment.
--
Job Type: Contract
Salary: $65.00 - $75.00 per hour
Schedule:
8 hour shift
Experience:
Data Architecture: 4 years (Required)
TAMR: 2 years (Required)
Azure and AWS: 5 years (Required)
Python: 3 years (Required)
Overall Technical: 10 years (Required)
Work Location: Remote
Show Less
Report",4.5,201 to 500 Employees,2015,Company - Private,Information Technology Support Services,Information Technology,$5 to $25 million (USD)
"Software Engineer, Data Products",$119K - $163K (Glassdoor est.),LaunchDarkly4.1 ★,"Oakland, CA","Please note, before progressing to our application, this position is based in the San Francisco Bay Area and not suitable for remote candidates.
About the Job:
We are looking for exceptional Software Engineers to make a profound impact on how data products will be integrated into companies' software in the future. We are integrating data into everything LaunchDarkly offers on top of our unrivaled feature management platform.
As a Data Products - Software Engineer, you will help us architect and write fast, reliable, and scalable data processing tools to process data from our thousands of customers and their hundreds of millions of users around the world. We're looking for someone who knows what it takes to deliver value to customers and takes pride in the quality of their work.
The primary technologies we use daily include Golang, Scala, Kinesis, and Flink. If working as a part of such a poly-functional team to bring to change how experimentation is done forever appeals to you then come join the Experimentation team at LaunchDarkly.
Responsibilities:
Build and expand our data platform and services
Help us identify the best technologies for our evolving data needs
Collaborate with product team to spec and deliver user-facing features
Monitor and improve data pipeline performance
Actively participate in code reviews
Improve engineering standards, tooling, and processes
Qualifications:
Proven experience and fluency in a JVM or functional language
Experience building data platforms (e.g. using Flink, Kafka, DataFlow, Hadoop, Spark)
Strong communication skills, a positive attitude, and empathy
You write code that can be easily understood by others, with an eye towards maintainability
You hold yourself and others to a high bar when working with production systems
You value high code quality, automated testing, and other engineering best practices
Pay:
Target pay range for a Level P3 in San Francisco/Bay Area: $144,000 - $169,000*
Restricted Stock Units (RSUs), health, vision, and dental insurance, and mental health benefits in addition to salary.
LaunchDarkly operates from a place of high trust and transparency; we are happy to state the pay range for our open roles to best align with your needs. Exact compensation may vary based on skills, experience, degree level, and location.
About LaunchDarkly:
LaunchDarkly is a Feature Management Platform that serves trillions of feature flags daily to help software teams build better software, faster. Feature flagging is an industry standard methodology of wrapping a new or risky section of code or infrastructure change with a flag. Each flag can easily be turned off independent of code deployment (aka ""dark launching""). LaunchDarkly has SDKs for all major web and mobile platforms. We are building a diverse team so that we can offer robust products and services. Our team culture is dynamic, friendly, and supportive. Our headquarters are in Oakland.
At LaunchDarkly, we believe in the power of teams. We're building a team that is humble, open, collaborative, respectful and kind. We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, gender identity, sexual orientation, age, marital status, veteran status, or disability status.
One of our company values is 'Widen the Circle'. Which means we seek out diversity of perspectives to get better results. We understand everyone has their own unique talents and experiences. We encourage you to apply to this role even if you don’t think you meet 100% of the qualifications outlined above. We can find out together if it's the right match for your skillset.
We've partnered with KeyValues to help demonstrate the amazing culture we've built here at LaunchDarkly, find more info at https://www.keyvalues.com/launchdarkly.
LaunchDarkly is also committed to giving back to our community and is a part of Pledge 1%, an organization that helps companies make this a priority. Through this initiative and its charitable arm, the LaunchDarkly Foundation, the company is committed to such causes as supporting education for the underserved, homelessness relief and moving towards having a net-zero carbon footprint. You can find more about the LaunchDarkly Foundation and the organizations we serve at https://launchdarkly.com/foundation/.
Do you need a disability accommodation?
Fill out this accommodations request form and someone from our People Operations team will contact you for assistance.
Show Less
Report",4.1,501 to 1000 Employees,2014,Company - Private,Enterprise Software & Network Solutions,Information Technology,$100 to $500 million (USD)
Data Engineer,$110K (Employer est.),Capitol Federal2.9 ★,"Topeka, KS","Job Description:
Pay: up to $110,000 Annually
Job Type: Full Time
The Data Engineer assists in setting overall development roadmap and standards for the Bank and helps evaluate and architect the use of data solutions, using industry best practices. This position works as part of a collaborative team to design, code, and implement data solutions to support internal business requirements or external customers and vendors. An innovative mindset and an ability to translate complex business scenarios into a technical solution is required. This position performs a variety of tasks under general supervision. The position reports directly to an IT manager and requires regular, predictable and timely attendance at work to meet department workload demands.
Paid time off and holiday available on your first day! Benefits available to anyone working 20 hours or more per week!
CapFed® is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees.
Job Type: Full-time
Work Location: In person
Show Less
Report",2.9,501 to 1000 Employees,1893,Company - Public,Banking & Lending,Financial Services,$100 to $500 million (USD)
Azure - Senior Data Engineering Architect,$108K - $210K (Employer est.),Publicis Sapient3.8 ★,"Arlington, TX","Azure - Senior Data Engineering Architect
Full-time
Company Description
Publicis Sapient is a digital transformation partner helping established organizations get to their future, digitally-enabled state, both in the way they work and the way they serve their customers. We help unlock value through a start-up mindset and modern methods, fusing strategy, consulting and customer experience with agile engineering and problem-solving creativity. As digital pioneers with 20,000 people and 53 offices around the globe, our experience spanning technology, data sciences, consulting and customer obsession – combined with our culture of curiosity and relentlessness – enables us to accelerate our clients’ businesses through designing the products and services their customers truly value. Publicis Sapient is the digital business transformation hub of Publicis Groupe. For more information, visit publicissapient.com.
Job Description
Publicis Sapient is looking for a hands-on Senior Manager to join our team of bright thinkers and doers. You’ll use your problem-solving creativity to design, architect, and develop high-end technology solutions that solve our clients’ most complex and challenging problems across different industries. We are on a mission to transform the world, and you will be instrumental in shaping how we do it with your ideas, thoughts, and solutions.
Your impact:
Develop, design, and implement consumer data models based on business requirements and objectives.
Collaborate with various stakeholders, such as business analysts, architects, and developers, to understand data needs and convert these needs into effective data models.
Evaluate and optimize existing data models for improvement.
Ensure that data models adhere to industry best practices, standards, and guidelines.
Conduct data profiling and analysis to identify data quality issues and propose data cleansing and remediation strategies.
Collaborate with database administrators to optimize database performance and maintain data integrity.
Work closely with ETL developers to integrate data models into data integration processes.
Stay updated on the latest trends and technologies in data modeling, cloud computing, and database design.
Mentor, support and manage team members
Qualifications
Your Skills and Experience:
Demonstrable experience in enterprise level data platforms involving implementation of end-to-end data pipelines
Hands-on experience with at least one of the leading public cloud data platforms (Amazon Web Services, Azure or Google Cloud)
Experience with column-oriented database technologies (e.g., Big Query, Redshift, Vertica), NoSQL database technologies (e.g., DynamoDB, BigTable, Cosmos DB, etc.) and traditional database systems (e.g., SQL Server, Oracle, MySQL)
Experience in architecting data pipelines and solutions for both streaming and batch integrations using tools/frameworks like Glue ETL, Lambda, Google Cloud DataFlow, Azure Data Factory, Spark, Spark Streaming, etc.
Metadata definition and management via data catalogs, service catalogs, and stewardship tools such as OpenMetadata, DataHub, Alation, AWS Glue Catalog, Google Data Catalog.
Test plan creation and test programming using automated testing frameworks, data validation and quality frameworks, and data lineage frameworks
Data modeling, querying, and optimization for relational, NoSQL, timeseries, graph databases, data warehouses and data lakes
Data processing programming using SQL, DBT, Python, and similar tools
Logical programming in Python, Spark, PySpark, Java, Javascript, and/or Scala
Cloud-native data platform design with a focus on streaming and event-driven architectures
Participate in integrated validation and analysis sessions of components and subsystems on production servers
Data ingest, validation, and enrichment pipeline design and implementation
SDLC optimization across workstreams within a solution
Bachelor’s degree in Computer Science, Engineering, or related field
Additional Information
Pay Range:$108,000 -$210,000
Benefits of Working Here:
Flexible vacation policy; time is not limited, allocated, or accrued
16 paid holidays throughout the year
Generous parental leave and new parent transition program
Tuition reimbursement
Corporate gift matching program
As part of our dedication to an inclusive and diverse workforce, Publicis Sapient is committed to Equal Employment Opportunity without regard for race, color, national origin, ethnicity, gender, protected veteran status, disability, sexual orientation, gender identity, or religion. We are also committed to providing reasonable accommodations for qualified individuals with disabilities and disabled veterans in our job application procedures. If you need assistance or an accommodation due to a disability, you may contact us at [email protected] or you may call us at +1-617-621-0200.
Apply Now: click Apply Now
Show Less
Report",3.8,10000+ Employees,1990,Company - Public,Business Consulting,Management & Consulting,Unknown / Non-Applicable
Data Modeler (Data Architect),-1,Luby Software4.3 ★,United States,"Come with us and become a #Luber

If you love technology we have some exciting news for you: SO DO WE!

Check out our package and the reasons to become a #Luber:
https://drive.google.com/file/d/1BbXpYhkboXQaHHiV0oSVWJij-3GnP_Qi/view?usp=sharing

We are seeking an experienced and skilled Data Modeler with a strong background in the retail industry. The ideal candidate will have expertise in designing and implementing dimensional data models in Erwin, as well as experience with the Snowflake and Databricks platforms, and building models from Kafka/JSON source data. As a Data Modeler, you will play a crucial role in designing, developing, and maintaining data models to support our retail analytics and business intelligence initiatives.

Responsabilidades e atribuições

What will be your attributions at #Luby?
Develop and maintain Erwin data models that align with business requirements and best practices for the retail industry.
Collaborate with cross-functional teams to gather data requirements and understand business processes and objectives.
Design and implement efficient and scalable data models to support data integration, data warehousing, and reporting needs.
Perform data profiling and analysis to identify data quality issues and recommend data cleansing and transformation strategies.
Optimize data models for performance and ensure data integrity and consistency.
Collaborate with data engineers to implement data pipelines and ETL processes using ADF, Databricks, and Snowflake.
Work closely with data scientists and analysts to ensure data models meet analytical and reporting requirements.
Document data models, data flows, and data dictionary for reference and future enhancements.
Stay up to date with emerging trends and technologies in data modeling, retail analytics, and cloud-based data platforms.

Requisitos e qualificações

Position's Requirements:
Bachelor's degree in Computer Science, Information Systems, or a related field. A Master's degree is a plus.
Proven experience as a Data Modeler, Data Architect, or similar role in the retail industry.
Strong knowledge of data modeling concepts, techniques, and best practices.
Hands-on experience with Snowflake, Databricks, and Kafka JSON messages.
Proficiency in SQL, ETL processes, and data integration methodologies.
Availability to work full time.
Familiarity with Azure and Big Data technologies.
Excellent analytical and problem-solving skills with attention to detail.
Strong communication and collaboration skills to work effectively with cross-functional teams.
Ability to prioritize and manage multiple projects and deliverables simultaneously.
Knowledge of retail industry trends, metrics, and business processes is a plus.

Informações adicionais

Our benefits range:

We hire through ""PJ"" contracts while also offering many benefits (...so you get the best of both worlds \o/)

Fully Remote
Health Care (Regular, Vision and Dental included)
LubyCare (Wellness and Mental Health Program)
Life Insurance
Gympass
Flexible Hours
Bonus per year (80h)
English classes
Program of indication
Multilaser e-commerce discounts - 30% on any purchase on their website, everytime!

A Luby é uma Software House brasileira com sólida presença internacional. Temos mais de 8 anos de atuação no mercado de Bancos e Fintechs americanas, assim como 20 anos de desenvolvimento de soluções digitais para o mercado nacional.

Atualmente, a Luby conta com mais de 260 colaboradores que usam as tecnologias mais atuais do mercado em Squads Multidisciplinares espalhados pelo Brasil.

Aqui, buscamos grandes talentos para fazerem parte da missão Luby de ser A referência técnica no Brasil. Seja em projetos nacionais ou internacionais.
Show Less
Report",4.3,201 to 500 Employees,2002,Contract,Software Development,Information Technology,Unknown / Non-Applicable
Data Engineer,$70.00 Per Hour (Employer est.),Tellus solutions3.7 ★,"Sunnyvale, CA","Job Description:
The role will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams.
The ideal candidate is an experienced data pipeline builder and data wrangler who enjoy optimizing data systems and building them from the ground up.
The Data Engineer will support our software developers, database architects, and data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple teams, systems and products.
The right candidate will be excited by the prospect of optimizing or even re-designing our data architecture to support our next generation of products and data initiatives.
Responsibilities:
Create and maintain optimal data pipeline architecture for data intensive applications.
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using Azure SQL, Cosmo DB, Databricks and other legacy databases.
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.
Keep our data separated and secure across national boundaries through multiple data centers and Azure regions.
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
Work with data and analytics experts to strive for greater functionality in our data systems.
Qualifications for Data Engineer
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Extensive Experience on Databricks on Azure Cloud platform, deep understanding on Delta lake, Lake House Architecture.
Programming experience on Python, Shell scripting, PySpark, and other data programming language.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with Data Visualization Dashboard, Metrics and etc.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
Skills:
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Working knowledge of message queuing, stream processing, and highly scalable 'big data' data stores.
Familiar with Deployment tool like Docker and building CI/CD pipelines.
Experience supporting and working with cross-functional teams in a dynamic environment.
8+ years' experience in software development, Data engineering, and
Bachelor's degree in computer science, Statistics, Informatics, Information Systems or another quantitative field. Postgraduate/master's degree is preferred.
Experience in Machine Learning and Data Modeling is a plus.
Job Type: Contract
Salary: Up to $70.00 per hour
Benefits:
401(k)
Dental insurance
Health insurance
Schedule:
8 hour shift
Day shift
Application Question(s):
Only US Citizen and Green Card Holder
Experience:
Python, Shell scripting, PySpark: 5 years (Required)
Azure SQL: 5 years (Required)
Work Location: On the road
Show Less
Report",3.7,51 to 200 Employees,2006,Company - Private,Information Technology Support Services,Information Technology,$5 to $25 million (USD)
Senior Data Engineer,$100K - $179K (Employer est.),RVO Health4.0 ★,"Minneapolis, MN","AT A GLANCE
RVO Health is looking for a talented Senior Data Engineer to join our team! As a Senior Data Engineer at RVO Health, you will have the chance to build technology that drives real improvements to consumer health outcomes and has the potential to have widespread impact across the healthcare industry. You will design, develop, test, and maintain big data pipelines for ingestion, segmentation, and reporting to drive our vision!
What You'll Do:
Provide technology ownership for data solutions for projects that the team has been tasked with.
Work with a cross functional team of business analysts, architects, engineers, data analysts and data scientists to formulate both business and technical requirements.
Design and build data pipelines from various data sources to a target data warehouse using batch data load strategies utilizing cutting edge cloud technologies.
Conceptualizing and generating infrastructure that allows data to be accessed and analyzed effectively.
Documenting database designs that include data models, metadata, ETL specifications and process flows for business data project integrations.
Perform periodic code reviews and test plans to ensure data quality and integrity.
Provide input into strategies as they drive the team forward with delivery of business value and technical acumen.
Execute on proof of concepts, where appropriate, to help improve our technical processes.
What We're Looking For:
5+ years of Data Engineering experience
4+ years of experience working on Spark (RDDs / Data Frames / Dataset API) using Scala/Python to build and maintain complex ETL pipelines.
4+ years of experience in the big data space
Experience in translating business requirements into technical data solutions on a large scale.
2+ years of experience working on AWS (Kinesis / Kafka / S3 / RedShift) Or Azure.
Able to research and troubleshoot potential issues presented by stakeholders within the data ecosystem.
Experience with GitHub and CI/CD processes
Experience with Compute technologies like EMR and Databricks
Experience working with job orchestration (eg., Airflow / AWS Step Function)
Experience with Data Modeling, Data warehousing
Working with Kubernetes is a plus
Strong analytical and interpersonal skills.
Enthusiastic, highly motivated and ability to learn quickly.
Able to work through ambiguity in a fast-paced, dynamically changing business environment.
Ability to manage multiple tasks at the same time with minimal supervision.
This position may occasionally require travel for training and other work-related duties.
""Pursuant to various state Fair Pay Acts, below is a summary of compensation elements for this role at the company. The following benefits are provided by RVO Health, subject to eligibility requirements.""
Starting Salary: $100,000 - $178,500*
Note actual salary is based on geographic location, qualifications and experience
Health Insurance Coverage (medical, dental, and vision)
Life Insurance
Short and Long-Term Disability Insurance
Flexible Spending Accounts
Paid Time Off
Holiday Pay
401(k) with match
Employee Assistance Program
Paid Parental Bonding Benefit Program
Who We Are:
Founded in 2022, RVO Health is a new healthcare platform of digital media brands, services and technologies focused on building relationships with people throughout their health & wellness journey. We meet people where they are in their personal health journeys and connect them with both the information and the care they need. RVO Health was created by joining teams from both Red Ventures and UnitedHealth Group's Optum Health. Together we're focused on delivering on our vision of a stronger and healthier world.
RVO Health is comprised of Healthline Media (Healthline, Medical News Today, Psych Central, Greatist and Bezzy), Healthgrades, FindCare and PlateJoy; Optum Perks, Optum Store and the virtual coaching platforms Real Appeal, Wellness Coaching, and QuitForLife.
We offer competitive salaries and a comprehensive benefits program for full-time employees, including medical, dental and vision coverage, paid time off, life insurance, disability coverage, employee assistance program, 401(k) plan and a paid parental leave program.
RVO Health is an equal opportunity employer that does not discriminate against any employee or applicant because of race, creed, color, religion, gender, sexual orientation, gender identity/expression, national origin, disability, age, genetic information, veteran status, marital status, pregnancy or any other basis protected by law. Employment at RVO Health is based solely on a person's merit and qualifications.
We are committed to providing equal employment opportunities to qualified individuals with disabilities. This includes providing reasonable accommodation where appropriate. Should you require a reasonable accommodation to apply or participate in the job application or interview process, please contact accommodations@rvohealth.com.
We do not provide visa sponsorship at this time.
RVO Health Privacy Policy: https://rvohealth.com/legal/privacy
Show Less
Report",4.0,1001 to 5000 Employees,2022,Company - Private,Hospitals & Health Clinics,Healthcare,Unknown / Non-Applicable
"Engineering Director, Commercial Data Engineering",$170K - $255K (Employer est.),Amex4.2 ★,"Phoenix, AZ","You Lead the Way. We’ve Got Your Back.
With the right backing, people and businesses have the power to progress in incredible ways. When you join Team Amex, you become part of a global and diverse community of colleagues with an unwavering commitment to back our customers, communities and each other. Here, you’ll learn and grow as we help you create a career journey that’s unique and meaningful to you with benefits, programs, and flexibility that support you personally and professionally.
At American Express, you’ll be recognized for your contributions, leadership, and impact—every colleague has the opportunity to share in the company’s success. Together, we’ll win as a team, striving to uphold our company values and powerful backing promise to provide the world’s best customer experience every day. And we’ll do it with the utmost integrity, and in an environment where everyone is seen, heard and feels like they belong.
Join Team Amex and let's lead the way together.

As part of our diverse tech team, you can architect, code and ship software that makes us an essential part of our customers’ digital lives. Here, you can work alongside talented engineers in an open, supportive, inclusive environment where your voice is valued, and you make your own decisions on what tech to use to solve challenging problems. Amex offers a range of opportunities to work with the latest technologies and encourages you to back the broader engineering community through open source. And because we understand the importance of keeping your skills fresh and relevant, we give you dedicated time to invest in your professional development. Find your place in technology on #TeamAmex

How will you make an impact in this role?
We’re looking for an experienced data engineering leader to join our Commercial Data Engineering organization. We build data-centric solutions to support the Global Commercial Services product suite including B2B payments, large corporate clients, and our small and medium enterprise ecosystem. You’ll lead your team and partner cross functionally to create innovative, scalable, resilient data systems that enable us to unlock the value of our data for all of our products.
Cultivate an environment of continuous improvement through technical guidance, coaching, mentoring, and feedback.
Lead one or more data engineering teams that iterate on our large-scale distributed, high-performance data platform.
Establish and maintain strong relationships with key stakeholders and cross functional partners to deliver collaboratively.
Perform hands-on architecture, design, development, and testing.
Drive high-level & detailed technical designs and conduct designs & code reviews as needed.
Implement process improvements to streamline areas for your team such as hiring, onboarding, software delivery, and internal/external communication.
Recruit and retain engineering talent.

Minimum Qualifications
Excellent written and verbal communication skills.
Expertise with a major cloud vendor (AWS/GCP).
Expertise with spark, python, SQL.
Experience leading high-performing data engineering teams focused on iterative delivery.
Experience partnering cross functionally and being a hands-on leader to drive successful execution.
Experience with CI/CD and strong understanding of implementing iterative software delivery practices.
Preferred Qualifications
Experience building unified data driven solutions with a data-lakehouse architecture.
Experience building event driven data streaming solutions
Salary Range: $170,000.00 to $255,000.00 annually + bonus + equity (if applicable) + benefits
The above represents the expected salary range for this job requisition. Ultimately, in determining your pay, we'll consider your location, experience, and other job-related factors.
We back our colleagues and their loved ones with benefits and programs that support their holistic well-being. That means we prioritize their physical, financial, and mental health through each stage of life. Benefits include:
Competitive base salaries
Bonus incentives
6% Company Match on retirement savings plan
Free financial coaching and financial well-being support
Comprehensive medical, dental, vision, life insurance, and disability benefits
Flexible work arrangements and schedules with hybrid and virtual options with Amex Flex
20+ weeks paid parental leave for all parents, regardless of gender, offered for pregnancy, adoption or surrogacy
Free access to global on-site wellness centers staffed with nurses and doctors (depending on location)
Free and confidential counseling support through our Healthy Minds program
Career development and training opportunities
For a full list of Team Amex benefits, visit our Colleague Benefits Site.
At American Express, you’ll be recognized for your contributions, leadership, and impact—every colleague has the opportunity to share in the company’s success. Together, we’ll win as a team, striving to uphold our company values and powerful backing promise to provide the world’s best customer experience every day. And we’ll do it with the utmost integrity, and in an environment where everyone is seen, heard and feels like they belong.
American Express is an equal opportunity employer and makes employment decisions without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, veteran status, disability status, age, or any other status protected by law.
We back our colleagues with the support they need to thrive, professionally and personally. That's why we have Amex Flex, our enterprise working model that provides greater flexibility to colleagues while ensuring we preserve the important aspects of our unique in-person culture. Depending on role and business needs, colleagues will either work onsite, in a hybrid model (combination of in-office and virtual days) or fully virtually.
US Job Seekers/Employees - Click here to view the “Know Your Rights” poster and supplement and the Pay Transparency Policy Statement.
If the links do not work, please copy and paste the following URLs in a new browser window: https://www.dol.gov/agencies/ofccp/posters to access the three posters.
Start your job application: click Apply Now
Show Less
Report",4.2,10000+ Employees,1850,Company - Public,Financial Transaction Processing,Financial Services,$10+ billion (USD)
Data Architect (Azure),$140K - $160K (Employer est.),LTI - Larsen & Toubro Infotech3.8 ★,"Charlotte, NC","Role: Azure Data Architect.
Location: Charlotte, NC (Onsite or Hybrid Model (3 days onsite/week)
Duration: FTE.
Responsibilities:
You are an expert in Azure Data Analytics having thorough understanding of Azure Data Platform tools
Expertise and hands-on experience on Azure Platform among: Data Factory, Azure Spark
Collaborate with project stakeholders like database administrators, technical architects, , business analysts, big data admins, security experts, information modelling experts to determine project needs and plan development and implementation strategies.
To define, review, and explain Data Architecture requirements & design to all the project stakeholders
Lead the migration of data from legacy systems to newly developed solution.
To create strategies and design solutions for wide variety use cases like Data Migration (end to end ETL process), database optimization, data architectural solutions for Analytics and Big Data Projects
To design, develop and troubleshoot highly complex technical problems in OLAP/OLTP/DW, Analytics, Big Data environments and provide solutions for Enterprise level Applications utilizing Azure Data Platform
To implement data quality processes for use with MDM, BI solutions, data warehouses, EAI solutions, etc.
Work on streamlining data flows and data models consistently
Have a keen focus on improving and tuning data quality, accessibility, performance and security needs
Skills Required
Bachelor/ master’s degree in computer science engineering,
Self-driven, and able to think holistically of the product roadmap
Performing reviews of data Architecture and Designs
Research new technologies and data modelling methods
Creative in solving complex business problems
Hands-on experience in business analysis, pre-sales, solution proposals, development
Excellent written & verbal communication
Job Type: Full-time
Salary: $140,000.00 - $160,000.00 per year
Benefits:
401(k)
401(k) matching
Dental insurance
Health insurance
Paid time off
Vision insurance
Schedule:
Monday to Friday
Ability to commute/relocate:
Charlotte, NC 28202: Reliably commute or planning to relocate before starting work (Required)
Experience:
Data Architect: 10 years (Required)
Azure: 8 years (Required)
Azure data factory: 5 years (Required)
Azure DataBricks: 5 years (Required)
Data modeling: 8 years (Required)
Adobe Spark: 5 years (Required)
Data Migration: 4 years (Required)
OLAP: 6 years (Required)
Work Location: In person
Show Less
Report",3.8,10000+ Employees,1997,Company - Private,Information Technology Support Services,Information Technology,Unknown / Non-Applicable
Data & Analytics Engineer,$80K - $107K (Glassdoor est.),Robert W. Baird4.3 ★,"Louisville, KY","As we continue to grow and add top talent to the Baird family of technical associates, we are looking for a Data & Analytics Engineer for our growing data team. This is a key role on our IT Data Team requiring a broad range of skills and the ability to step into different roles depending on the size and scope of the business need. The self-motivated candidate will have proven experience architecting successful data solutions on key projects in a collaborative environment. Success will come from being able to prioritize, deliver value incrementally, problem solve, and manage changing priorities. You will work closely with our business partners and interface with both technical and non-technical colleagues.
This position is hybrid, working a combination of remote and in-office in our new collaborative work space. We offer a collaborative culture with a continuous learning, agile/lean environment and adding value to the Baird business. Learn more about Baird IT here.

As a Data & Analytics Engineer, you will:
Data Architecture
Specialize in data modeling, both 3NF and dimensional, with experience in conceptual, logical, physical, and industry data modeling. Strong knowledge and experience with data architecture methodologies.
Apply the appropriate level of modeling theory, pattern recognition, and abstractions to architect and design a pragmatic solution that functionally meets the business and technical requirements.
Partner with internal business units to define information requirements and translate them into appropriate data solutions.
Collaborate with IT and business partners to lead data discovery, profiling, analysis, and quality assessments in order to obtain clear information requirements.
Develop and validate source to target mappings and transformation logic required to support business needs. Understand the importance of capturing data lineage.
Architect, implement and verify end-to-end data solutions.
Develop test plans needed to ensure a quality deliverable. Participate in validation testing, coordinate user acceptance testing and training to ensure the final implementation enables the user to solve their business problem.
General Data Management
Play a critical role in architecting our data and analytics solution landscape
Demonstrate competence, experience, knowledge, understanding, and advocacy of data management concepts, data warehousing, BI, and analytics.
Demonstrate ability to perform appropriate level of strategic thinking by viewing initiatives both within the immediate project context as well as the overall architectural vision.
Participate and/or Lead in data architectural design and strategy discussions.
Data Delivery
Work with the business users to conduct data discovery engagements and can quickly identify, and prototype, a solution that brings together multiple data sources into one coherent concept and understanding. (data blending)
Leverage existing tools to create data visualizations and mentors the business to be self-sufficient.
Collaborate – build relationships!
Identify and communicate project risks and impediments and proactively work with other members of the Analytics team to complete high-value deliverables as identified by business partners and team leadership.
Partner with Analytics team members to translate business and functional requirements into technical designs
Strive to understand the data consumption needs of the business community, as well as the problems faced by business users involving the access and use of data
Help Analytics teams develop solutions that enable businesses to capitalize on business insights and drive toward gaining a competitive advantage
What makes this opportunity great:
Information technology is a core part of Baird’s business strategy and plays a critical role in the growth and transformation of the firm.
On Computerworld’s ‘Best Company to Work For’ list for five consecutive years with a collaborative culture that values diverse backgrounds and perspectives while emphasizing teamwork and a strong sense of partnership.
Support and flexibility to grow and be your best at work, at home, and in the community.
What we look for:
Minimum of 3-5 years of experience in Data Solution delivery in a complex environment working collaboratively in a team setting
Proficient in Data Solution tools and concepts such as:
Business Intelligence tools: Microsoft tools (SQL Server Management Studio, SSRS, SSAS, Power Pivot, Power Query, PowerBI), Alteryx
Database: SQL Server
Data Query tools: SQL, T-SQL
Data Management and Quality: data mapping, data profiling, metadata repository, relational data modeling, master data management
Data Modeling: ER/Studio Data Architect, 3NF and dimensional modeling
Data Warehousing concepts: Inmon, Kimball, Data Lake
Data Integration concepts and strategies: EII, ETL, EL-T and EAI
#LI-SB1
Commitment to Inclusion & Diversity
Baird is committed to inclusion & diversity for our clients, our associates and the communities where we live and work. This commitment stems from our culture of integrity, genuine concern for others and respect for the individual. We view inclusion & diversity as an ongoing journey – one of shared responsibility, continuous improvement and a focus on progress. We invite you to join us as we work together to foster an environment where diversity unites rather than divides us.
Apply Now: click Apply Now
Show Less
Report",4.3,1001 to 5000 Employees,1919,Company - Private,Investment & Asset Management,Financial Services,$1 to $5 billion (USD)
Senior Data Engineer,$111K - $147K (Glassdoor est.),Steampunk4.5 ★,"McLean, VA","Overview:
In today’s rapidly evolving technology landscape, an organization’s data has never been a more important aspect in achieving mission and business goals. Our data exploitation experts work with our clients to support their mission and business goals by creating and executing a comprehensive data strategy using the best technology and techniques, given the challenge.

At Steampunk, our goal is to build and execute a data strategy for our clients to coordinate data collection and generation, to align the organization and its data assets in support of the mission, and ultimately to realize mission goals with the strongest effectiveness possible.

For our clients, data is a strategic asset. They are looking to become a facts-based, data-driven, customer-focused organization. To help realize this goal, they are leveraging visual analytics platforms to analyze, visualize, and share information. At Steampunk you will design and develop solutions to high-impact, complex data problems, working with the best and data practitioners around. Our data exploitation approach is tightly integrated with Human-Centered Design and DevSecOps.
Contributions:
We are looking for seasoned Senior Data Engineer to work with our team and our clients to develop enterprise grade data platforms, services, and pipelines. We are looking for more than just a ""Senior Data Engineer"", but a technologist with excellent communication and customer service skills and a passion for data and problem solving.
Lead and architect migration of data environments with performance and reliability.
Assess and understand the ETL jobs, workflows, BI tools, and reports
Address technical inquiries concerning customization, integration, enterprise architecture and general feature / functionality of data products
Experience in crafting database / data warehouse solutions in cloud (Preferably AWS. Alternatively Azure, GCP).
Key must have skill sets – Python, AWS
Support an Agile software development lifecycle
You will contribute to the growth of our Data Exploitation Practice!
Qualifications:
US Citizen Only
Ability to hold a position of public trust with the US government.
8+ years experience with a Bachelor's Dergee or 6+ years of experience with a Master's Degree
5-7 years industry experience coding commercial software and a passion for solving complex problems.
5-7 years direct experience in Data Engineering with experience in tools such as:
Big data tools: Hadoop, Spark, Kafka, etc.
Relational SQL and NoSQL databases, including Postgres and Cassandra.
Data pipeline and workflow management tools: Azkaban, Luigi, Airflow, etc.
AWS cloud services: EC2, EMR, RDS, Redshift (or Azure equivalents)
Data streaming systems: Storm, Spark-Streaming, etc.
Search tools: Solr, Lucene, Elasticsearch
Object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.
Advanced working SQL knowledge and experience working with relational databases, query authoring and optimization (SQL) as well as working familiarity with a variety of databases.
Experience with message queuing, stream processing, and highly scalable ‘big data’ data stores.
Experience manipulating, processing, and extracting value from large, disconnected datasets.
Experience manipulating structured and unstructured data for analysis
Experience constructing complex queries to analyze results using databases or in a data processing development environment
Experience with data modeling tools and process
Experience architecting data systems (transactional and warehouses)
Experience aggregating results and/or compiling information for reporting from multiple datasets
Experience working in an Agile environment
Experience supporting project teams of developers and data scientists who build web-based interfaces, dashboards, reports, and analytics/machine learning models
About steampunk:
Steampunk is a Change Agent in the Federal contracting industry, bringing new thinking to clients in the Homeland, Federal Civilian, Health and DoD sectors. Through our Human-Centered delivery methodology, we are fundamentally changing the expectations our Federal clients have for true shared accountability in solving their toughest mission challenges. As an employee owned company, we focus on investing in our employees to enable them to do the greatest work of their careers – and rewarding them for outstanding contributions to our growth. If you want to learn more about our story, visit http://www.steampunk.com.

We are an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status, protected veteran status, or any other characteristic protected by law. Steampunk participates in the E-Verify program.
Show Less
Report",4.5,201 to 500 Employees,2003,Company - Private,Information Technology Support Services,Information Technology,Unknown / Non-Applicable
AWS Data Engineer,$109K - $131K (Employer est.),Techflairs4.5 ★,"Washington, DC","Bachelor’s degree in computer science or engineering or equivalent work experience
AWS Solutions Architect – Associate certification within past five years
AWS Solutions Architect – Professional certification within past five years
AWS Certified Data Analytics – Specialty or AWS Certified Big Data – Specialty certifications
Solutions architecture experience in an enterprise environment with emphasis on data systems
Specific experience designing, executing and supporting AWS data lakes at scale
Experience designing, optimizing, and maintaining relational and non-relational databases including MySQL, MS SQL, Redshift, AWS RDS and other NoSQL databases
Experience with the design and building of ETL packages, data pipelines and connecting these to BI applications
Running production workload on AWS cloud
Workload migration to AWS cloud
Knowledge of data movement and data presentation tools such as; Informatica, MS SSIS, AWS Glue, Cognos, Tableau
Ability to pass a background check and pass the criteria for a CJIS environment
Willingness to research and self-study to keep technical skills relevant in a highly complex environment
Ability to multi-task and prioritize deadlines as needed to deliver results
Ability to work independently or as part of a team
Mentors and coach colleague. Seeks opportunities for continuous improvement
Excellent verbal and written communication skills with great attention to detail and accuracy
Experience working in an Agile/Scrum environment
Job Types: Contract, Temporary
Pay: $108,665.12 - $130,865.52 per year
Experience level:
8 years
Schedule:
8 hour shift
Monday to Friday
Ability to commute/relocate:
Washington, DC 20001: Reliably commute or planning to relocate before starting work (Required)
Experience:
designing, optimizing, and maintaining relational: 3 years (Required)
design and building of ETL packages, data pipelines: 2 years (Required)
Running production workload on AWS cloud: 3 years (Required)
Workload migration to AWS cloud: 2 years (Required)
Work Location: In person
Show Less
Report",4.5,1 to 50 Employees,2002,Company - Private,Information Technology Support Services,Information Technology,$25 to $100 million (USD)
AWS Data Architect IV,$98K - $142K (Glassdoor est.),Habemco3.5 ★,"Upper Lake, CA",-1,4.5,-1,-1,-1,-1,-1,-1
Sr Data Engineer/data architect,$70.00 - $90.00 Per Hour (Employer est.),Devcare Solutions3.6 ★,"Columbus, OH","Habemco is a shared services company wholly owned and operated by the Habematolel Pomo of Upper Lake, a federally recognized Native American tribe located in Northern California. Our talented team provides cross-functional support services to various tribal business and government entities. Habemco’s primary support services power the Tribe’s flagship online lending brand, Uprova, and any future brands, through product development, technology, and other support needed for growth. The Habemco team plays a critical role in ensuring a successful future for our customers, our employees, and the Tribe.
Headquartered in a beautiful, yet remote part of California, the Tribe recognizes that to compete in the highly competitive FinTech industry, the Tribe must access expertise throughout the nation. In addition to employees that work remotely, the Tribe has employees clustered at headquarters in Upper Lake, California, and a call center in Lenexa, Kansas.

Show More
Report",3.6,51 to 200 Employees,2005,Company - Private,Information Technology Support Services,Information Technology,Unknown / Non-Applicable
Senior Data Architect (Remote),$150K - $200K (Employer est.),KBX3.8 ★,"Wichita, KS","Your Job
KBX Technology Solutions, LLC, a provider of transportation technology to industry leaders, is seeking a highly skilled Data Architect to join our dynamic team. You will be responsible for designing and implementing scalable, secure, and efficient data architectures that leverage cloud-native technologies and principles. You will play a critical role in defining data strategies, ensuring data integrity, and enabling advanced analytics and insights in our cloud-native environment.
Our Team
This role will be part of our Platform Architecture team. The Platform is the core foundation that all of products are built. Software, Cloud, and Data architects are part of one team that develop the strategy and guidelines for all of core capabilities and products.
What You Will Do

Design and Develop Data Architecture: Collaborate with cross-functional teams to design and develop scalable and robust data architectures that align with cloud-native principles. Evaluate and select appropriate technologies, tools, and frameworks to support data storage, processing, integration, and analytics.
Cloud-Native Data Solutions: Architect, implement, and optimize data solutions leveraging cloud-native technologies such as Kubernetes, Kafka, microservices, containers, and managed data services. Ensure that data solutions are highly available, scalable, and cost-effective in a cloud environment.
Data Modeling and Governance: Define and enforce data modeling and governance best practices. Develop data models, data dictionaries, data catalog, and data integration patterns to ensure consistency, standardization, and quality of data across the organization. Establish data governance frameworks, policies, and procedures to promote data integrity and security.
Data Integration and ETL: Design and oversee implementation of data integration processes, including Extract, Transform, Load (ETL) workflows, APIs, data pipelines, and data streaming. Collaborate with data engineers and developers to ensure seamless and efficient data integration between various systems and applications.
Contribute & Share Knowledge: Participate in various transformation initiatives across KBX requiring data-centric architecture and enablement guidance and contribute to the data management & enablement community within Koch companies to drive strategy development, modeling, and knowledge systems for leveraging data.

Who You Are (Basic Qualifications)
Experience translating business strategy into value creation through data by creating roadmaps and the data strategy while collaborating and implementing with cross functional teams.
Experience in integration of complex, cross-corporate processes, and information strategies, and/or designing strategic metrics and scorecards.
Experience in Information Technology systems and ability to understand how data interacts with the enterprise digital foundation.
Experience in data lake and data warehouse technologies
Strong knowledge of cloud platforms such as AWS, Azure, or Google Cloud Platform (GCP).
Proficiency in data modeling, data integration, and data governance concepts and best practices.
Proficiency in SQL and NoSQL databases

What Will Put You Ahead
Experience in machine learning model development, training, and lifecycle management
Familiarity with data integration tools and ETL processes.
Experience with cloud-native data technologies, such as Kubernetes, Kafka, microservices, containers, and managed data services.
Solid understanding of data security, privacy, and compliance requirements.
Strong analytical and critical thinking skills.
Excellent communication and collaboration abilities.
Experience working within large organizations, and the ability to develop strong relationships required.
Experience with business intelligence and data analytics
For this role, we anticipate paying $150,000 - $200,000 per year. This role is eligible for variable pay, issued as a monetary bonus or in another form.
At Koch companies, we are entrepreneurs. This means we openly challenge the status quo, find new ways to create value and get rewarded for our individual contributions. Any compensation range provided for a role is an estimate determined by available market data. The actual amount may be higher or lower than the range provided considering each candidate's knowledge, skills, abilities, and geographic location. If you have questions, please speak to your recruiter about the flexibility and detail of our compensation philosophy.
Hiring Philosophy
All Koch companies value diversity of thought, perspectives, aptitudes, experiences, and backgrounds. We are Military Ready and Second Chance employers. Learn more about our hiring philosophy here.
Who We Are
As a Koch company, KBX provides the global transportation, logistics and technology solutions that help our customers deliver life's essentials to people all over the world. We develop and deploy cutting-edge technologies to deliver better solutions for increasingly complex supply chains. Our team of tenacious problem-solvers are driven to create real, long-term value for our customers.
At Koch, employees are empowered to do what they do best to make life better. Learn how our business philosophy helps employees unleash their potential while creating value for themselves and the company.
Our Benefits
Our goal is for each employee, and their families, to live fulfilling and healthy lives. We provide essential resources and support to build and maintain physical, financial, and emotional strength focusing on overall wellbeing so you can focus on what matters most. Our benefits plan includes medical, dental, vision, flexible spending and health savings accounts, life insurance, ADD, disability, retirement, paid vacation/time off, educational assistance, and may also include infertility assistance, paid parental leave and adoption assistance. Specific eligibility criteria is set by the applicable Summary Plan Description, policy or guideline and benefits may vary by geographic region. If you have questions on what benefits apply to you, please speak to your recruiter.
Equal Opportunities
Equal Opportunity Employer, including disability and protected veteran status. Except where prohibited by state law, all offers of employment are conditioned upon successfully passing a drug test. This employer uses E-Verify. Please visit the following website for additional information: http://www.kochcareers.com/doc/Everify.pdf
To apply to this job, click Apply Now
Show Less
Report",3.8,10000+ Employees,1940,Company - Private,Energy & Utilities,"Energy, Mining & Utilities",$10+ billion (USD)
Senior data engineer,$114K - $152K (Glassdoor est.),bp4.1 ★,"Houston, TX","Location
US: Houston - Westlake Campus
Travel required
Up to 10% travel should be expected with this role
Job category
Digital & technology
Relocation available
This role is eligible for relocation within country
Job type
Professionals
Job code
RQ26058419
Experience level
Intermediate

Job summary
Entity:
Innovation & Engineering

Job Family Group:
IT&S Group

Job Summary:
Part of a cross-disciplinary team, working closely with other data engineers, software engineers, data scientists, data managers and business partners.

Architects, designs, implements and maintains reliable and scalable data infrastructure to move, process and serve data.

Writes, deploys and maintains software to build, integrate, manage, maintain, and quality-assure data at bp.

Adheres to and advocates for software engineering best practices (e.g. technical design, technical design review, unit testing, monitoring & alerting, checking in code, code review, documentation),

Responsible for deploying secure and well-tested software that meets privacy and compliance requirements; develops, maintains and improves CI / CD pipeline,

Responsible for service reliability and following site-reliability engineering best practices: on-call rotations for services they maintain, responsible for defining and maintaining SLAs. Design, build, deploy and maintain infrastructure as code. Containerizes server deployments.

Actively contributes to improve developer velocity.

Mentors others.

Job Description:
BS degree in computer science or related field
Deep and hands-on experience (typically 5+ years) designing, planning, building, productionizing, maintaining and documenting reliable and scalable data infrastructure and data products in complex environments
Development experience in one or more object-oriented programming languages (e.g. Python, Scala, Java, C#)
Advanced database and SQL knowledge
Experience designing and implementing large-scale distributed data systems
Deep knowledge and hands-on experience in technologies across all data lifecycle stages
Strong stakeholder management and ability to lead initiatives through technical influence
Continuous learning and improvement mindset
Desired
No prior experience in the energy industry required
Why join us
At bp, we support our people to learn and grow in a diverse and exciting environment. We believe that our team is strengthened by diversity. We are committed to fostering an inclusive environment in which everyone is respected and treated fairly.
There are many aspects of our employees’ lives that are important, so we offer benefits to enable your work to fit with your life. These benefits can include flexible working options, a generous paid parental leave policy, and excellent retirement benefits, among others!
We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation.

Travel Requirement
Up to 10% travel should be expected with this role

Relocation Assistance:
This role is eligible for relocation within country

Remote Type:
This position is a hybrid of office/remote working

Skills:

Legal Disclaimer:
We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, sex, gender, gender expression, sexual orientation, age, marital status, neurodiversity/neurocognitive functioning, veteran status or disability status. Individuals with disabilities may request a reasonable accommodation related to bp’s recruiting process (e.g., accessing the job application, completing required assessments, participating in telephone screenings or interviews, etc.). If you would like to request an accommodation related to the recruitment process, please contact us to request accommodations.
If you are selected for a position and depending upon your role, your employment may be contingent upon adherence to local policy. This may include pre-placement drug screening, medical review of physical fitness for the role, and background checks.
Start your job application: click Apply Now
Show Less
Report",4.1,10000+ Employees,1908,Company - Public,Energy & Utilities,"Energy, Mining & Utilities",$10+ billion (USD)
GCP Data Modeler/ Architect,$70.00 Per Hour (Employer est.),Infinity Quest4.0 ★,"Dublin, OH","Qualifications & Experience
Required
· Must have designed, developed, and supported a complex software solution.
· Proficient in SQL.
· Good Understanding in dimensional/multidimensional data modeling.
· Experience with graph, transactional, and operational data modeling is a plus.
· Familiarity with all stages of the product development cycle. Experience maintaining engineering best practices, including defect tracking, design reviews, and appropriate testing.
· Hold strong organizational and problem-solving skills.
· Take a pragmatic, product-oriented approach.
· Possess the ability to work cross-functionally with minimal supervision.
Preferred
· B.S. in Computer Science, Electrical Engineering, Mathematics, Statistics, Physics, or similar quantitative fields/work experience.
· Experience with cloud environments
· 7+ years of experience in data modeling.
· 3-7+ years of experience in at least one scripting language (Python, Perl, JavaScript, Shell)
· 2+ years of experience working on streaming data applications
· 3+ years of experience with Agile engineering practices
· 3+ years of experience developing Java-based software solutions, scripting and OOP languages
· 3+ years of experience with UNIX/Linux, including basic commands and shell scripting
· 2+ years of experience with GCP
· 1+ years in the healthcare industry and knowledge of their business practices.
Job Type: Contract
Salary: From $70.00 per hour
Schedule:
8 hour shift
Experience:
Data modeling: 1 year (Required)
Python: 1 year (Required)
DVT: 1 year (Required)
Data Validation Tool: 1 year (Required)
Terraform: 1 year (Required)
BigQuery: 1 year (Required)
Work Location: On the road
Show Less
Report",4.0,201 to 500 Employees,2006,Company - Private,Information Technology Support Services,Information Technology,Unknown / Non-Applicable
Senior Azure Data Architect,-1,Lighthouse MTG LLC,Rhode Island,"Azure Data Architect
Description:
Spyglass MTG (Microsoft Technology Group) is a Microsoft Gold Certified Partner. We hire people who are professional consultants in addition to being highly competent performers in their specific discipline. As a Consultant at Spyglass MTG you will be working on projects to develop Microsoft technology focused solutions for a variety of clients in industries such as Financial Services, Healthcare, Life Sciences, Manufacturing and Higher Education. Our office is in Lincoln, RI, however our clients are typically located in the Greater Boston and New England area. You will be working in a team environment that consists of Spyglass and Client members.
As an Azure Data Architect, you will join our increasingly growing and exciting Azure Data and Analytics practice. You will be required to apply enterprise principles, standards and practices serving as the conduit for influencing our clients Enterprise Data Architecture’s direction while optimizing solutions for them. You will evaluate business needs and objectives, current and future state and transform into Azure data solutions that meet performance, scalability, reliability, and security needs. You must also provide technical guidance and oversight to development team, mentor those in less senior positions and ensure a consistent state of excellence during and post-delivery of the solution. You will be integral to the design, development, and delivery of all modern data solutions on Azure for our clients.
Candidate Expectations:
Architect, Design and deploy architecture to support data transformation, data structures, metadata, dependency, and workload management.
Experience deploying modern data solutions leveraging components like Azure functions, Azure Data Factory, Data Flows, Azure Data Lake, Azure SQL, Azure Synapse, Streaming Analytics and more.
Provide oversight and guidance to data, BI and ML engineering teams. It is expected that you provide direct experience within these core areas.
Experience with one or more languages: Python & Pyspark, T-SQL, SparkR & R, Scala.
Experience with code deployment in Azure Databricks environment.
Familiarity with DevOps tools like Azure DevOps, Jenkins, Maven etc.
Experience working with Azure data platforms, integration techniques & self-service data preparation.
Assist business users on functional and data requirements to enhance data models and pipelines.
Experience in requirements analysis, design, and prototyping.
Basic Qualifications:
8+ years of relevant professional technology experience
5+ years of experience in a programming language like SQL, Python or Scala
5+ years of working experience with SQL Server, data warehousing and data analytics projects
5+ years of experience data engineering in cloud and on-prem environments
MUST HAVE Experience deploying Azure data solution with Azure Data Factory, Azure Synapse, Data Lake or other Azure data service.
MUST HAVE Experience architecting and Azure data solution with Azure Data Factory, Azure Synapse, Data Lake or other Azure data service.
MUST HAVE Experience data engineering Azure Data Factory or Azure Synapse
Experience building scalable data platforms.
Experience with Azure solutions and infrastructure
Minimum of a Bachelor’s degree in Computer Science, Computer Engineering, Software Design, Software Engineering, or a related field, or equivalent alternative education, skills, and/or practical experience
Preferred Qualifications:
MS Certified: Data Engineering Associate
MS Certified: Azure Solutions Architect Expert
3+ years of experience with Azure SQL, Azure Synapse, SQL DW or other Cloud Data Services.
2+ years of experience with version control and DevOps or DataOps.
5+ years programming with SQL, Python, Scala or R.
5+ years developing, deploying, and testing data pipelines in Azure or other cloud provider.
5+ years of data engineering with Hadoop, Spark, Databricks, SSIS or other data integration tool.
Master’s degree in Computer Science, Computer Engineering, Software Design, Software Engineering, or a related field, or equivalent alternative education, skills, and/or practical experience.
Benefits:
Medical, Vision and Dental Plans
Life and Disability Insurance
Open PTO Policy
Holiday PTO
Paid training certification
Bonus plan
401k
Flexible working arrangements
& more
All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, transgender status, national origin, citizenship, age, disability or protected veteran status.
Show Less
Report",-1,Unknown,-1,Company - Public,-1,-1,Unknown / Non-Applicable
Data Architect,$92K - $126K (Glassdoor est.),St. Elizabeth Healthcare3.8 ★,"Crestview Hills, KY","Job Description
A Data Architect is responsible for evaluating the use of data and relating data directly to the goals and practices of the organization. Directly responsible for determining structural requirements and maintenance of the enterprise data model. Oversees the development of data models across the organization to ensure adherence to sound data management principles and, where possible, the reuse of data. Participates on a team that defines overall data policy, standards and procedures related to the database environment.

Demonstrate respect, dignity, kindness and empathy in each encounter with all patients, families, visitors and other employees regardless of cultural background.

Job Duties
Develop and document data requirements and design specifications in the form of data models, data mappings and data quality metrics. Map out structure and organization of relevant data for the organization. Support defining data conversion, integration and loading processes. Provide source to target ETL requirements and work with ETL developers to ensure efficient transformation and loading.
Develop, improve and support enterprise data standards and data architecture policies and procedures. Monitor and enforce compliance of data standards to minimize data redundancies and enhance information quality throughout the organization. Implement and document the company data architecture and data strategy.
Assist in maintaining and enhancing the metadata infrastructure, the data dictionary and business metadata and facilitate publishing this information to business and technical communities. Create business rules for data use.
Communicate and educate others on the use of sound data management principles. Interact daily with business analysts and project teams. Act as a resource for direction, training and guidance for less experienced staff. Conduct internal training on data architecture concepts.
Working together with IT technical staff, plan, manage, maintain, mature and tune enterprise data warehouse (EDW) hardware and software environments. Coordinate specific database performance monitoring and tuning tasks, including the design of optimization and indexing schemes. Coordinate and ensure data security administration, backup and recovery planning, and capacity planning.
Performs other duties as assigned.
Qualifications

Education, Credentials, Licenses:
Bachelor degree.

Bachelor degree requirement can be waived if the candidate has four or more years of previous data architecture experience.

Specialized Knowledge:
Knowledge of data warehousing principles, data dictionaries and data modeling. Strong SQL and data analysis skills. DMP certification a plus.

Kind and Length of Experience:
Minimum ten years Information Systems experience including: five (5) years Database / Data Warehouse development / architecture experience.
Show Less
Report",3.8,5001 to 10000 Employees,1861,Hospital,Health Care Services & Hospitals,Healthcare,Unknown / Non-Applicable
Software Engineer - Data Platform,$114K - $163K (Glassdoor est.),Exabeam3.8 ★,"Foster City, CA","Exabeam is a global cybersecurity leader that created New-Scale SIEM™ for advancing security operations. We help organizations detect threats, defend against cyberattacks, and defeat adversaries. The powerful combination of our cloud-scale security log management, behavioral analytics, and automated investigation experience results in an unprecedented advantage over insider threats, nation states, and other cyber criminals. We understand normal behavior, even as normal keeps changing — giving security operations teams a holistic view of incidents for faster, more complete response.
Detect. Defend. Defeat.™ Learn how at www.exabeam.com.
A Software Engineer that can help us build a hyper-scale search platform for our New Scale Security Applications. Search platform team is responsible for ingestion from our cloud native log ingestion pipeline to datalake, providing an external facing search interface to our end users and supporting query APIs into datalake for other Exabeam Security Applications to run their services. Search is one of the most commonly used application on the SIEM dashboard, and as such we need a developer who will help us meet that demanding standard.
Responsibilities:
Work alongside with PMs, Architects and other senior engineers to support and extend our back end services
Produce elegant, bulletproof code (and the tests to prove it)
Review your colleagues' code to maintain a high standard of code quality
Help investigate and resolve problems reported by our test and support teams
Participate in our on-call rotation for technical emergencies
Develop new competencies and skills

Requirements:
College graduate with a Bachelor's degree in Computer Science or equivalent discipline
Development experience with Java, or other object oriented programming language
A burning passion for acquiring wisdom and knowledge
2+ years developing with cloud platforms such as Amazon Web Services, GCP, and Microsoft Azure.
Passion and drive to learn
Why Exabeam: US
Medical, Dental, Vision benefits
FSA/HSA options
Generous PTO and Holidays
Parental leave
Base Pay Range: Bay Area Only
$120,000 - $150,000
Range is reflective of base pay only
Does not include variable pay
Base pay is dependent on experience and may vary based on geography
Exabeam is privately funded by Blue Owl Capital, Lightspeed Venture Partners, Cisco Investments, Norwest Venture Partners, Acrew Capital, Icon Ventures, and investor Shlomo Kramer. For more information visit https://www.exabeam.com or follow us on LinkedIn and Twitter. Looking for more? Check our reviews on Glassdoor.
In connection with your application and communications with Exabeam, we will have access to some of your personal information. We have technical and organizational measures in place to ensure this information is protected. For more information about how we use and/or protect your personal information, including the categories of information collected, categories of use, and purpose of use, is available on our Privacy Policy at https://www.exabeam.com/legal/privacy-policy/.
Apply Now: click Apply Now
Show Less
Report",3.8,501 to 1000 Employees,2013,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable
IT Architect (Azure Data Engineer architect – Synapse Analytics),-1,Ampcus Incorporated3.6 ★,Virginia,"Responsibilities:
Provide technical architecture guidance and expertise in developing, architecting, and maintaining Azure Synapse Analytics end-to-end solution, Azure Databricks, spark pool, and monitoring of high-volume of complex data warehouse and analytical processes.

Experience in designing and architecting end-to-end Analytics solutions in Synapse.
Experience in designing and architecting Change data capture frameworks.
Demonstrable experience in designing and orchestrating data pipelines to load data efficiently in Synapse dedicated SQL Pool.
Experience in Azure Data Lake, Azure Data Factory, Azure data flow, Azure functions and Databricks.
Experience in architecting workload management solutions in Azure Synapse dedicated SQL pool, Serverless pool, and Spark pool.
Experience in architecting solutions to optimize dedicated SQL pools in Azure Synapse Analytics using different data distribution methods, partitioning, and query optimization.
Experience in architecting consumption patterns like Analytical, Operational, Real-time, and bulk consumption patterns.
Experience in optimization of data ingestion, curation, Synapse analytics, analyzing large data sets, and Knowledge of Performance/cost optimization techniques
Experience in large-scale warehouse migration from on-prem to cloud.
PowerBI architect experience is preferred. Relevant certification is a plus.
Show Less
Report",3.6,501 to 1000 Employees,2004,Company - Private,Information Technology Support Services,Information Technology,$25 to $100 million (USD)
Data Modeler/Architect,-1,Agama Solutions3.9 ★,United States,"Bachelor’s degree in Computer Science, Information Systems , or other related field or equivalent work experience • Typically has 5+ years of IT experience with at least 3 years of data management, metadata and data quality experiences • Expertise with data quality tools for data profiling, cleansing and standardization • May require experience in implementing solutions and processes for master data and hierarchy synchronizations • Knowledge of logical data architecture

Responsibilities:
• Provides support for metadata management system development, implementation and maintenance • Works with the IT teams to understand data requirements • Collects, analyzes and summarizes data to support business decisions • Provides data that is congruent, reliable, and easily accessible by the user • Utilizes tools to monitor and mass update data changes • Translates business requirements into conceptual, logical and physical data model • Develops and maintains the logical and physical data models • Uses technology to extract and analyze raw data • Develops and maintains technical documentation regarding data • Makes recommendations for process improvements in order to support data integrity efforts • Analyzes program needs and translates them into data warehousing and data mart requirements • Designs, develops and deploys query parameters, layout, filters, and analytics for program information solutions • Recognizes and resolves conflicts between models, ensuring that data models are consistent with the enterprise model (e.g., entity names, relationships and definitions) • Communicates data integrity accuracy to the business, and escalates / communicates issues when necessary • Provides guidance on complex issues to other team members • Supports the development of automated solutions which enhance the quality of enterprise data • Performs regular data audits • Builds data migration and single source strategies • Participates in establishment of governance for metadata management across the enterprise • Ensures integration of project logical data model into enterprise conceptual data model • Works in partnership with data architects to design a common customer view of information • Oversees the design and implementation of data cleansing procedures • Works with project teams to understand the business environment in order to manage enterprise-wide information/data support systems • Researches internal and external data sources for new data and improved sources of data feeds Complexity • Works on multiple projects/issues/enhancements as a team leader • Works on complex enterprise-wide projects/issues/enhancements • Designs logical enterprise-wide data models • Provides support for master data management, logical data, quality system development, implementation and maintenance
Show Less
Report",3.9,51 to 200 Employees,-1,Contract,Computer Hardware Development,Information Technology,$5 to $25 million (USD)
Sr. Data Engineer - Remote,-1,Chamberlain Group3.7 ★,Illinois,"Chamberlain Group is a global leader in access solutions with top brands, such as LiftMaster and Chamberlain, found in millions of homes, businesses, and communities worldwide.
As a leader in the Smart Home industry, we boast one of the largest IoT install bases, with innovative products consisting of cameras, locks, card readers, garage door openers, gates and more, all powered by our myQ digital ecosystem.
This role is responsible for providing technical expertise and leadership to design and deliver end-to-end data engineering solutions to support advanced analytics capabilities and drive innovation and decision-making
across Chamberlain.
Essential Duties and Responsibilities
Build and maintain real-time and batch data pipelines across the advanced analytics platform.
Design, develop and orchestrate highly robust and scalable ETL pipelines.
Design and implement Dimensional and NoSQL data modelling as per the business requirements.
Develop highly optimal codebase and perform Spark optimizations for Big Data use cases.
Design, develop and deploy optimal monitoring and testing strategy for the data products.
Collaborate with stakeholders and advanced analytics business partners to understand business needs and translate requirements into scalable data engineering solutions.
Collaborate with data scientists to prepare data for model development and production.
Collaborate with data visualization and reporting application developers to ensure the sustainability of production applications and reports.
Collaborate with data architects on the enhancement of Chamberlain’s enterprise data architecture and platforms.
Provide leadership to third-party contractors.
Comply with health and safety guidelines and rules.
Protect CGI’s reputation by keeping information confidential.
Maintain professional and technical knowledge by attending educational workshops, professional publications, establishing personal networks, and participating in professional societies.
Minimum Qualifications
Education/Certifications:
Bachelor’s degree in computer science or related quantitative field of study
Experience:
4+ years of professional experience
Knowledge, Skills, and Abilities:
Natural sense of urgency, teamwork, and collaboration reflected in daily work ethic.
Proficient in Spark or Databricks, Cloud Data Engineering Services preferably Azure, Streaming frameworks like Event Hubs or Kafka.
Proficient in Microsoft Office.
Familiarity with modern Machine Learning Operationalization techniques.
Agile methodologies.
Familiarity with Data visualization tools, such as Qlik or Power BI.
Preferred Qualifications
Education/Certifications:
Master’s degree in computer science or related quantitative field of study
Experience:
4+ years of professional experience
2+ years of professional experience delivering engineering for advanced analytics or data science solutions
Knowledge, Skills, and Abilities:
Agile methodologies
Experience with IoT Data Architecture.
Machine Learning Operationalization (MLOps) proficiency.
REST API design and development.
Proficiency with streaming design patterns.

The pay range for this position is $103,300.00 to $177.475.00; base pay offered may vary depending on a number of factors including, but not limited to, the position offered, location, education, training, and/or experience. In addition to base pay, also offered is a comprehensive benefits package and 401k contribution (all benefits are subject to eligibility requirements).
This position is eligible for participation in a short-term incentive plan subject to the terms of the applicable plans and policies.
#LI-Remote
We're an organization who values its human capital and provides support to assist its employees succeed.

Chamberlain Group is proud to be an Equal Opportunity Employer. You will be considered for this position based upon your experience and education, without regard to race, color, religion, sex, national origin, age, sexual orientation, ancestry; marital, disabled or veteran status. We are committed to creating and maintaining a workforce environment that is free from any form of discriminations or harassment.

Persons with disabilities who anticipate needing accommodations for any part of the application process may contact, in confidence
Recruiting@Chamberlain.com
.

NOTE: Staffing agencies, headhunters, recruiters, and/or placement agencies, please do not contact our hiring managers via email or phone or other methods.
Start your job application: click Apply Now
Show Less
Report",3.7,1001 to 5000 Employees,1900,Company - Private,Consumer Product Manufacturing,Manufacturing,$500 million to $1 billion (USD)
"Data Architect, IT",$83K - $129K (Glassdoor est.),UofL Health3.4 ★,"Louisville, KY","Overview:
We are Hiring for our Information Technology team.
Shift Options: Full Time & Days

About Us
UofL Health is a fully integrated regional academic health system with seven hospitals, four medical centers, nearly 200 physician practice locations, more than 700 providers, the Frazier Rehabilitation Institute and the Brown Cancer Center.
With more than 12,000 team members—physicians, surgeons, nurses, pharmacists and other highly skilled health care professionals—UofL Health is focused on one mission: delivering patient-centered care to each and every patient each and every day.

Our Mission
As an academic health care system, we will transform the health of the communities we serve through compassionate, innovative, patient-centered care.

Job Summary
The Data Architect supports the design, development and implementation of all data initiatives at ULH. Leads the enterprise information management strategy fostering IT – Business collaboration in understanding of enterprise data, binding disparate, heterogenous data sources together in a framework for access and sharing of data, developing data trust across the organization and instituting best practices and standards in data use.

Leads the implementation, enhancement and on-going support of enterprise data platform utilizing data modeling concepts for model extension and ETL programs to transform and ingest data.
Supports the data through its life cycle utilizing data governance principles that ensure data quality, integrity, stewardship, security, literacy and adoption.
Develops and enforces implementation of standards and best practices involved in data modeling (conceptual/logical/physical models), data architecture design patterns (EDW/data marts/data lakes) and ETL.
Conducts research and makes recommendations on products, tools, services, protocols and standards that will support ULH’s data management strategy.
Works in concert with BI Developers and business teams to understand business requirements and translating those requirements into developing value-add BI/Analytics solutions.
Designs and maintains a curriculum for coaching and training current and prospective end users to better understand how these tools can enhance business decision making capabilities.
Provides Level 1, 2 and 3 support for day-to-day production issues maintaining documentation in the appropriate tracking systems while adhering to prescribed escalation & change control procedures. Includes on call rotation.
Adheres to all Security Standards as set forth by the organization and National guidelines.
Additional tasks/responsibilities as defined.
Responsibilities:
Works closely with Analytics leadership team, business teams and IT infrastructure teams to design, implement and support the goals and objectives of the organization set by the leadership.
Leads the implementation, enhancement and on-going support of enterprise data platform utilizing data modeling concepts for model extension and ETL programs to transform and ingest data.
Conducts research and makes recommendations on products, tools, services, protocols and standards that will support ULH’s data management and BI strategies.
Supports the data through its life cycle utilizing data governance principles that ensure data quality, integrity, stewardship, security, literacy and adoption.
Proactively communicate and collaborate with internal and external customers to analyze information needs and functional requirements and delivery.
Performs Tier 1, 2 and 3 Application/Systems support.
Maintains relationship with vendors of hospital applications to understand current and future features and functionality and product life cycle.
Qualifications:
Education / Accreditation / Licensure (required & preferred):
Bachelor’s Degree in Business, Information Science or Computer Science required. Master’s Degree highly preferred

Experience (required and preferred):
7+ years of experience in supporting/developing/extending data warehouse/data mart solutions required.
5+ years of experience with data modeling concepts translating business requirements into conceptual, logical and physical models required.
5+ years of experience in ETL development preferably with SSIS required.
Expert knowledge of data governance practices and data life cycle management highly desired.
Experience in Agile development methodology for analytics projects required.
Experience and ability in working directly with vendors, customers and other IT teams.
To apply to this job, click Apply Now
Show Less
Report",3.4,1001 to 5000 Employees,-1,Hospital,Health Care Services & Hospitals,Healthcare,$100 to $500 million (USD)
Data Architect,$117K - $163K (Employer est.),GEHA4.0 ★,United States,"GEHA (Government Employees Health Association, Inc., pronounced G.E.H.A.) is a nonprofit member association that provides medical and dental benefits to more than two million federal employees and retirees, military retirees and their families. We celebrate diversity and are committed to creating an inclusive environment for all employees.
GEHA has one mission: To empower federal workers to be healthy and well.
Offering one of the largest medical and dental benefit provider networks available to federal employees in the United States, GEHA empowers health and wellness by meeting its members where they are, when they need care. We serve our members with products they value and a personalized customer experience, sustained by a nimble and efficient organization.
The Data Architect, Data & Analytics role is to advise, construct and implement the development standards and technical design for the organization’s data and analytic solutions. This role will be providing key oversight and direction for the overall architecture, design and implementation to support end user data and analytic needs. This includes responsibility for input on the design of data ingestion, data management, data warehousing, data stores, data extraction and business intelligence tools. The right candidate will have an eye for understanding the needs of the business and champion enterprise data architecture and modeling that will support execution. This role will report directly to the Director - Data & Analytic Solutions and will work closely with the teams involved with data movement and utilization to ensure alignment across the longitudinal evolution of capturing data to creating actionable insights.
SKILLS
Drive architecture first mindset with a heavy focus Data Warehouse and driving Kimball modeling methodologies and business driven domains.
Establishes policies and procedures for data architecture and movement to be implemented by the Data & Analytics organization, including policies for standardizing data systems and data software across the enterprise.
Acts as technical mentor for members of the Data & Analytics team, providing input and feedback to others.
Review Technical Design Documentation and participate in peer review cycles with technical & non-technical counterparts.
Establishes and maintains documentation of programs, user guides, policies and procedures, particularly in support of the acceptance of solutions as credible to non-technical users of information.
Collaborates with Business Data Analysts, Developers and Data Analysts in the development and integration of data, insights and solutions within the purview of Data & Analytics .
Provides oversight, input, design and implementation support for new solution development, including but not limited to new data platforms, data management, primary & secondary storage environments, and business intelligence solutions.
Evaluates existing applications and systems. Recommends improvements or modifications.
Responsible for creating and maintaining the catalog of architectural diagrams used by the team.
Support Data Governance efforts, including guidance, stewardship, and frameworks for managing data across the organization and identify opportunities for data reuse, migration, or retirement.
Recommends training on new technologies to keep the GEHA development staff on the cutting edge.
Encourage and support a self-service architecture to promote a trusted source of distributed data and analytic capabilities and insights, leading the enterprise in its goal to be an insight-driven organization.
Requirements
Bachelor’s degree in Computer Information Services or a related field.
5 years of experience with enterprise data management, including hybrid and cloud environments
5 years experience with Kimball modeling for a Data Warehouse.
Proficiency with the SQL Server core data engine, SSIS, SSRS, PowerBI, Visual Studio, .NET, Powershell (and related scripting languages), MS Office Products and source management tools (e.g., TFS, Git).
Excellent working knowledge of relational databases such as MS SQL Server or Azure SQL Database including but not limited to indexing best practices and modeling.
Experience observing change management and code promotion through non-production environments..
Experience loading data stores ensuring processes are configurable, resilient, and performant.
Ability to develop data translation objects and data processing flow using modern tools and adapt to new ones as they become available.
Proven ability to work independently to coordinate and solve highly complex technical data transformation issues. Ability to effectively communicate with customers to clarify data format requirements and negotiate compromise.
Requires effective communication and presentation skills. Demonstrates the ability to work and design for multiple projects.
Maintains knowledge of current and upcoming technologies. Mentors junior developers, conducts code reviews and acts as a resource to others to resolve complex problems.
Works under minimal supervision with wide latitude for independent judgment.
Preferred
3 years of experience with data warehouse or analytics focused data environments, including star schemas, tabular models and business intelligence tools
Experience with Cloud EDW (Snowflake, Synapse, etc.)
3 years of demonstrated experience in the Healthcare industry, with preference for experience with Healthcare Payers.
Work-at-home requirements
Must have the ability to provide a non-cellular High Speed Internet Service such as Fiber, DSL, or cable Modems for a home office.
A minimum standard speed for optimal performance of 30x5 (30mpbs download x 5mpbs upload) is required.
Latency (ping) response time lower than 80 ms
Hotspots, satellite and wireless internet service is NOT allowed for this role.
A dedicated space lacking ongoing interruptions to protect member PHI / HIPAA information
How we value you
Competitive pay/salary ranges
Incentive plan
Health/Vision/Dental benefits effective day one
401(k) retirement plan: company match – dollar for dollar up to 4% employee contribution (pretax or Roth options) plus a 6% annual company contribution
Robust employee well-being program
Paid Time Off
Personal Community Enrichment Time
Company-provided Basic Life and AD&D
Company-provided Short-Term & Long-Term Disability
Tuition Assistance Program
Please note that the salary information is a general guideline only. GEHA considers factors such as (but not limited to) scope and responsibilities of the position, candidate’s work experience, education/training, key skills, internal peer equity, as well as, market and business considerations when extending an offer.
The annual base salary range for this position is $116,620 - $163,380 USD.
GEHA is an Equal Opportunity Employer, which means we will not discriminate against any individual based on sex, race, color, national origin, disability, religion, age, military status, genetic information, veteran status, pregnancy, marital status, gender identity, and sexual orientation, as well as all other characteristics and qualities protected by federal, state, or local law. GEHA will not discriminate against employees or applicants because they have inquired about, discussed, or disclosed their compensation or the compensation of another employee or applicant. We are committed to creating an inclusive environment for all employees. Our diversity drives innovation deepens connections and strengthens our organization.
GEHA is headquartered in Lee's Summit, Missouri, in the Kansas City area. We recognize the importance of balance and flexibility and offer hybrid and work-from-home options for many of our roles.
Show Less
Report",4.0,201 to 500 Employees,-1,Contract,-1,-1,Unknown / Non-Applicable
Sr Data Engineer,$112K - $152K (Glassdoor est.),Voloridge Investment Management4.7 ★,"Jupiter, FL","At Voloridge Investment Management our quantitative systems are deeply dependent on vast quantities of data. The Senior Data Engineer must understand the many different and evolving use cases for data at Voloridge and design systems that supply high-performance datasets for advanced analytics. In this role the Sr. Data Engineer / Architect will provide mentorship and impart experience to the data engineering team.
Summary of Job Functions
Collaborate effectively with Stakeholders, Project Managers, Software Engineers, Data Analysts, QA Analysts, DBAs, and Data Engineers
Build and maintain data pipelines based on functional and non-functional requirements
Proactively seek out information and overcome obstacles to deliver projects efficiently
Ensure that data pipelines incorporate best practices related to performance, scaling, extensibility, fault tolerance, instrumentation, and maintainability
Ensure that data pipelines are kept simple and not overly engineered
Produce and maintain design and operational documentation
Analyze complex data problems and engineer elegant solutions
Stay abreast of emerging technologies and make relevant recommendations
Upgrade existing data models and pipelines leveraging newer features and techniques
Work in a Kanban environment
Mentor less experienced data engineers
Participate in engineering standards and best practices evolution
Participate in an on-call rotation
Lead investigations to troubleshoot pipeline issues
Minimum Requirements
10+ years with hands-on data engineering and deep knowledge of data architecture fundamentals including:
Extensive experience building ETL/ELT pipelines from a variety of data sources
Broad experience with SQL Server 2019+, including advanced SQL Server features such as Table Partitioning, Columnstore
Deep knowledge and measurable experience in performance tuning TSQL, execution plan analysis blocking/deadlock analysis and index optimization
Extensive experience using SSMS to create and maintain SQL Server tables, views, functions, stored procedures, and user-defined table types
Comprehensive experience with data modeling indexes, Temporal tables, CLR, and Service Broker
Deep understanding of the development of data pipelines with either SSIS or Python and building data pipelines using multiple external data sources and transport mechanisms
Strong initiative, collaboration, accountability, impartiality, and communication
Strong analytical skills, a real passion for working with data and strong interest in solving data problems
Strong track record for judging core requirements and meeting deadlines
Experience managing master data
Experience writing C#, PowerShell, and Python
Experience with Git source control integration with SSMS
Experience working in a Kanban SDLC and a strong understanding of traditional Kanban SDLC workflows
Experience with deploying changes through segregated Development, QA, UAT and Production SDLC stages
Experience owning mission-critical processes
Bachelor’s degree in Computer Science, Information Systems, or related disciplines
Ability to work onsite in our Jupiter, FL office
Preferred Skills and Previous Experience
Python programming using libraries such as Pandas, Numpy, csv, Traceback, JSON, PyODBC, Math
Experience with source code branching and pull requests / code reviews
Experience with AWS
Experience working with trading / financial / investment / accounting data
Experience with tools such as Red Gate, Grafana, OpsGenie and JAMS
Experience with MPP databases such as Greenplum
MS/PhD in Computer Science, Information Systems, or related disciplines
Compensation and Benefits
Highly competitive base salary
Profit sharing bonus
Health, dental, vision, life, and disability insurance
401K
Additional Information
Voloridge Investment Management is an SEC registered investment advisor. A private investment company founded in 2009, our mission is to deliver superior risk-adjusted returns for qualified investors, using advanced proprietary modeling technology, conservative investment tactics and sophisticated risk management.
Voloridge Investment Management is an Equal Opportunity Employer. All qualified applicants are encouraged to apply and will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, protected veteran status, or any other legally protected characteristic or status.
Show Less
Report",4.7,51 to 200 Employees,2009,Company - Private,Investment & Asset Management,Financial Services,Unknown / Non-Applicable
ETL & Data Warehouse Manager / Architect (Remote),$94K - $128K (Glassdoor est.),Crum & Forster4.0 ★,"Morristown, NJ","Crum & Forster Company Overview:
Crum & Forster (C&F) Crum & Forster (C&F), with a proud history dating to 1822, provides specialty and standard commercial lines insurance products through our admitted and surplus lines insurance companies. C&F enjoys a financial strength rating of ""A"" (Excellent) by AM Best and is proud of our superior customer service platform. Our claims and risk engineering services are recognized as among the best in the industry.
Our most valuable asset is our people: more than 2000 employees in locations throughout the United States. The company is increasingly winning recognition as a great place to work, earning several workplace and wellness awards, including the October 2022 Great Place to Work® Award for our employee-first focus and our steadfast commitment to diversity, equity and Inclusion.
C&F is part of Fairfax Financial Holdings, a global, billion dollar organization. For more information about Crum & Forster, please visit our website: www.cfins.com.
Job Description:

C&F is looking for a passionate ETL & Data Warehouse Manager / Architect for our Snowflake implementation initiative, with significant experience in ETL solutions using SQL Server Integration Services and Snowflake. In this role, you will be responsible for designing and managing the development of robust ETL solutions for loading & extracting data from various source and target systems from our Snowflake Data warehouse. You will also be responsible for maintaining the Snowflake Data Warehouse schema design.
What you will do:

Collaborate with stakeholders and various IT groups to implement an overall data strategy that is in line with business objectives
Help the organization to bring our “one trusted data source” vision to life through a formal enterprise data lake house
Design build and maintain data models, data warehouses, data lakes, data marts and reporting/analytics solutions
Develop and maintain data integration and data transformation best practices and standards
Keep up-to-date with industry trends and advancements in ETL technologies and tools
Manage a team of ETL developers, providing guidance, support, and training as needed. This team will:
Identify and proactively resolve issues that could impact system performance, reliability, and usability
Develop and maintain ETL documentation, including technical specifications, data mappings, and data lineage
Perform data profiling and data quality analysis to ensure that ETL processes are accurate and reliable
Troubleshoot and resolve ETL issues and errors
What you will bring to C&F:

8+ years of experience in ETL development and data integration solutions using SSIS or any other ETL tool
8+ years of database development experience using Microsoft SQL Server, Oracle, and any other RDBMS
Strong knowledge of SQL/T-SQL/PL-SQL, Query Optimization, and Data management skills
Experience in Data warehouse development; Logical and Physical Database design & development
Experience with Snowflake data warehouse would be a big plus
Experience with BI tools such as SSRS/SSAS would be a plus
Experience with any cloud data warehouse would be plus
Knowledge of code versioning tools such as Git or stash would be a plus
Experience working in an agile environment would be a plus
Work experience related to the Insurance vertical would be a plus
Excellent critical thinking, analytical and problem-solving skills
Ability to think outside of the box and propose innovative solutions
Excellent written and oral communication skills
#LI-MS

# LI-REMOTE
What C&F will bring to you:
Competitive compensation package
Generous 401K employer match
Employee Stock Purchase plan with employer matching
Generous Paid Time Off
Excellent benefits that go beyond health, dental & vision. Our programs are focused on your whole family’s wellness, including your physical, mental and financial wellbeing
A core C&F tenet is owning your career development, so we provide a wealth of ways for you to keep learning, including tuition reimbursement, industry-related certifications and professional training to keep you progressing on your chosen path
A dynamic, ambitious, fun and exciting work environment
We believe you do well by doing good and want to encourage a spirit of social and community responsibility, matching donation program, volunteer opportunities, and an employee-driven corporate giving program that lets you participate and support your community

At C&F you will BELONG

If you require special accommodations, please let us know.We value inclusivity and diversity. We are committed to equal employment opportunity and welcome everyone regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity, or Veteran status. If you require special accommodations, please let us know
Apply Now: click Apply Now
Show Less
Report",4.0,1001 to 5000 Employees,1822,Subsidiary or Business Segment,Insurance Carriers,Insurance,Unknown / Non-Applicable
AWS Data Architect,$90.00 Per Hour (Employer est.),Blue Ocean Ventures3.5 ★,"Santa Monica, CA","Responsibilities / Qualifications:
· Candidate must have 10+ years of IT working experience with at least 5 years of experience on AWS Cloud environment is preferred.
· Working experience with Agile Methodology
· Experience working with source code management tools such as GitHub
Experience working with Jenkins or any CI/CD Pipelines using AWS Services
Job Type: Contract
Pay: From $90.00 per hour
Benefits:
401(k)
Dental insurance
Vision insurance
Schedule:
8 hour shift
Day shift
Ability to commute/relocate:
Santa Monica, CA 90401: Reliably commute or planning to relocate before starting work (Required)
Experience:
Data architect: 10 years (Preferred)
Work Location: In person
Speak with the employer
+91 7022159709
Show Less
Report",3.5,51 to 200 Employees,-1,Company - Private,HR Consulting,Human Resources & Staffing,Unknown / Non-Applicable
Principal data engineer,$118K - $171K (Glassdoor est.),bp4.1 ★,"Houston, TX","Location
United States of America - Texas - Houston
Travel required
No travel is expected with this role
Job category
Digital & technology
Relocation available
This role is not eligible for relocation
Job type
Professionals
Job code
RQ063058
Experience level
Senior

Job summary
Entity:
Innovation & Engineering

Job Family Group:
IT&S Group

Job Summary:
As a Principal Data Engineer, you will be part of bp’s Compute Platforms organisation, the group responsible for the computing platforms and services that underpin all bp’s computing services. The portfolio covers technologies that include on-premise data centres, cloud infrastructure and services, high-performance computing, databases, and supporting services.

Job Description:
Key Accountabilities:
Led a team of DevOps squads made up of software engineers, platform engineers, platform architects, and platform security engineers using agile development ceremonies including Kanban, refinement, and retrospectives, to deliver the Azure platform and resource provisioning services necessary for service and platform owners to deliver their agendas.
Build the platform strategy and product roadmap for Azure by working with partners internal and external to the team.
Develop a cloud alignment strategy for both AWS and Azure to provide a consistent customer experience.
Build relationships with external teams, including Digital Security and Architecture, to provide a balance of security and functionality in the Azure platform.
Provide a principle (architecture, design, and security) led service to allow the DevOps teams to be mostly autonomous squads to help deliver solutions rapidly.
Provide governance to enable prioritization of customer demand to ensure new and enhanced services are available for customer projects.
Provide guest platforms (DBaaS, CaaS, CPIN, WVD) the ability to deliver their services while minimizing their dependency on the Azure platform team.
Identify areas of continuous improvement to reduce the effort customers must put in to consume the Azure services (reduce customer friction).
Manage suppliers providing services for the Azure platform to ensure they provide people that are able to develop products/features following out team standards and principles.
Develop training programs with Microsoft to upskill bp staff and contractors as related to Azure capabilities.
Mentor and coach team members, while defining and promoting usage of standards, principles, and lessons learned
Essential Experience:
Developing and leading digital/technology strategies
Broad and strategic knowledge of the cloud technology landscape
Demonstrate strong product management and design thinking foresight skills
Strong facilitation and leadership skills: bringing multiple partners from architecture, digital security, and product/service owners together towards agreed outcomes.
Outstanding communication and relationship skills, ability to engage with a broad range of partners, capable of leading by influence.
Knowledge and understanding of modern development methodologies (agile using Kanban, DevOps, 2-pizza teams, agile ceremonies).
Knowledge and understanding of modern approaches to source-code management and control through tools (SonarCube, Azure DevOps, coding standards)
Bachelor's degree and/or MBA in relevant subject or equivalent preferred or equivalent experience.
Why join us

At bp, we support our people to learn and grow in a diverse and exciting environment. We believe that our team is strengthened by diversity. We are committed to fostering an inclusive environment in which everyone is respected and treated fairly.

There are many aspects of our employees’ lives that are important, so we offer benefits to enable your work to fit with your life. These benefits can include flexible working options, a generous paid parental leave policy, and excellent retirement benefits, among others!

We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation.

Travel Requirement
No travel is expected with this role

Relocation Assistance:
This role is not eligible for relocation

Remote Type:
This position is a hybrid of office/remote working

Skills:

Legal Disclaimer:
We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, sex, gender, gender expression, sexual orientation, age, marital status, neurodiversity/neurocognitive functioning, veteran status or disability status. Individuals with disabilities may request a reasonable accommodation related to bp’s recruiting process (e.g., accessing the job application, completing required assessments, participating in telephone screenings or interviews, etc.). If you would like to request an accommodation related to the recruitment process, please contact us to request accommodations.
If you are selected for a position and depending upon your role, your employment may be contingent upon adherence to local policy. This may include pre-placement drug screening, medical review of physical fitness for the role, and background checks.
To apply to this job, click Apply Now
Show Less
Report",4.1,10000+ Employees,1908,Company - Public,Energy & Utilities,"Energy, Mining & Utilities",$10+ billion (USD)
Sr. Data Architect,$108K - $145K (Glassdoor est.),American Honda Motor Co3.3 ★,"Marysville, OH","Sr. Data Architect
Location: Marysville, Ohio
Grade: IC1
Workstyle: Hybrid
What Makes a Honda, is Who makes a Honda
Honda has a clear vision for the future, and it’s a joyful one. We are looking for individuals with the skills, courage, persistence, and dreams that will help us reach our future-focused goals.

At our core is innovation. Honda is constantly innovating and developing solutions to drive our business with record success. We strive to be a company which serves as a source of “power” that supports people around the world who are trying to do things based on their own initiative and that helps people expand their own potential. To this end, Honda strives to realize “the joy and freedom of mobility” by developing new technologies and an innovative approach to achieve a “zero environmental footprint.”
We are looking for qualified individuals with diverse backgrounds, experiences, continuous improvement values, and a strong work ethic to join our team.
If your goals and values align with Honda’s, we want you to join our team to Bring the Future!
About this Position:
The Senior Data Architect is responsible for thought-leadership for innovation toward the next evolution of data technology products, agile approaches, cloud-based services, and advanced analytics. Build NA & global relationships and network to achieve trust and credibility, by discovering and meeting the needs of internal and external customers and vendors. As well as using their persuasion and influence to achieve maximum results with Enterprise IT goals.

Responsibilities include:

Develop and promote cloud data strategy, architecture, methodologies, and standards. Conduct innovation activities in data to sense study, test, and implement new technologies.
Work together with Unit and Dept. leadership to develop and deliver long-term strategic goal for data architecture; create, prioritize, and effectively deliver the company vision.
Delivers business value through high-performant and well-timed data pipeline orchestration, data governance, data quality broader data accessibility and governance policies & standards

Who we are seeking:
Required Work Experience:
10+ years of progressive experience in data management leading teams as a data or information architect.
10+ years of experience leading architecture teams in Data Analysis, Information Management and Business Intelligence
10+ years of advance knowledge of designing & working with multi-dimensional, mining transactional data and strategies that drive business
Hands-on experience with data architecting, data mining, large-scale data modeling
Required Education:
BS in computer science, information systems, or computer engineering
Additional Position Factors:
Workstyle: Hybrid
Travel: 5%
At Honda, you will play a key role in our journey to become a company that society wants to exist now, and in the future. Your endless curiosity will drive innovation and your courageous spirit will challenge the status quo. We believe having a workforce made up of diverse thinkers and innovators makes us a better Honda. Respect for each other and respect for diversity each and every day drives our associates to contribute at the highest level and work effectively in a team environment. We make the dream of mobility a reality with our innovative and high-quality products. Together, we Bring the Future to our customers, associates, and communities. We are Honda!
What differentiates Honda and make us an employer of choice?
Total Rewards:
Competitive Base Salary
Annual Bonus
Manager Lease Car Program (No Cost - Car, Maintenance, and Insurance included)
Industry leading Benefit Plans (Medical, Dental, Vision, Rx)
Paid time off, including vacation, paid holidays, sick time, personal days
401K Plan with company match + additional contribution
Relocation assistance (if eligible)
Career Growth:
Advancement opportunities
Career mobility
Education reimbursement for continued learning
Training and Development programs
Additional Offerings:
Wellbeing program
Community service and engagement programs
Product programs
Free drinks onsite
Honda is an equal opportunity employer and considers qualified applicants for employment without regard to race, color, creed, religion, national origin, sex, sexual orientation, gender identity and expression, age, disability, veteran status, or any other protected factor.
Apply Now: click Apply Now
Show Less
Report",3.3,10000+ Employees,1959,Subsidiary or Business Segment,Transportation Equipment Manufacturing,Manufacturing,$10+ billion (USD)
Data Solution Architect,$107K - $148K (Glassdoor est.),Steampunk4.5 ★,"McLean, VA","Overview:
In today’s rapidly evolving technology landscape, an organization’s data has never been a more important aspect in achieving mission and business goals. Our data exploitation experts work with our clients to support their mission and business goals by creating and executing a comprehensive data strategy using the best technology and techniques, given the challenge.

At Steampunk, our goal is to build and execute a data strategy for our clients to coordinate data collection and generation, to align the organization and its data assets in support of the mission, and ultimately to realize mission goals with the strongest effectiveness possible.

For our clients, data is a strategic asset. They are looking to become a facts-based, data-driven, customer-focused organization. To help realize this goal, they are leveraging visual analytics platforms to analyze, visualize, and share information. At Steampunk you will design and develop solutions to high-impact, complex data problems, working with the best and data practitioners around. Our data exploitation approach is tightly integrated with Human-Centered Design and DevSecOps.
Contributions:
We are looking for seasoned Data Solution Architect to work with our team and our clients to develop enterprise grade data platforms, services, pipelines, data models, visualizations, and more! The Data Solution Architect needs to be a technologist with excellent communication and customer service skills and a passion for data and problem solving. Data Solution Architect also be leading the team and providing necesary guidance while regularly interfacing with key customer stakeholders. This role spans the spectrum of data capabilities, from data vision and strategy all the way through data science.
Designing greenfield data solution stacks in the cloud or on premises, using the latest data services, products, technology, and industry best practices
Architecting migration of legacy data environments with performance and reliability
Data Architecture contributions include assessing and understanding data sources, data models and schemas, and data workflows
Data Engineering contributions include assessing, understanding, and designing ETL jobs, data pipelines, and workflows
BI and Data Visualization contributions include assessing, understanding, and designing reports, selecting BI tools, creating dynamic dashboards, and setting up data pipelines in support of dashboards and reports
Data Science contributions include assessing, understanding, and designing machine learning and AI applications, designing MLOps pipelines, and supporting data scientists
Addressing technical inquiries concerning customization, integration, enterprise architecture and general feature / functionality of data products
Experience in crafting data lakehouse solutions in the cloud (Preferably AWS. Alternatively, Azure, GCP). This includes relational databases, data warehouses, data lakes, and distributed data systems.
Key must have skill sets – broad understanding of data exploitation lifecycle and capabilities
Support an Agile software development lifecycle
You will contribute to the growth of our Data Exploitation Practice!
Qualifications:
US Citizen Only
Ability to hold a position of public trust with the US government.
5+ years industry experience coding commercial software and a passion for solving complex problems.
Experience in leading and managing a data solution team(s)
5+ years direct experience in Data Solutions with experience in tools such as:
Big data tools: Hadoop, Spark, Kafka, etc.
Relational SQL and NoSQL databases, such as Postgres, MySQL, MS SQL Server, Oracle, Mongo, etc.
Data pipeline and workflow management tools: Airflow, NiFi, etc.
AWS cloud services such as EC2, EMR, RDS, Redshift, Glue, SageMaker (or Azure and GCP equivalents)
Data streaming systems: Storm, Spark-Streaming, etc.
Data science tools/languages: R, R Studio, Python (data preparation and analysis libraries), Databricks, etc.
Search tools: Solr, Lucene, Elasticsearch
Object-oriented/scripting languages: Python, Java, C++, Scala, etc.
Advanced working SQL knowledge and experience working with relational databases, query authoring and optimization (SQL) as well as working familiarity with a variety of databases.
Experience with DBOps and MLOps frameworks and exposure/understanding of DevOps
Experience with message queuing, stream processing, and highly scalable ‘big data’ data stores.
Experience manipulating, processing, and extracting value from large, disconnected datasets.
Experience manipulating structured and unstructured data for analysis
Experience constructing complex queries to analyze results using databases or in a data processing development environment
Experience with data modeling tools and process
Experience architecting data systems (transactional and warehouses)
Experience aggregating results and/or compiling information for reporting from multiple datasets
Experience working in an Agile environment
Experience supporting project teams of developers and data scientists who build web-based interfaces, dashboards, reports, and analytics/machine learning models
About steampunk:
Steampunk is a Change Agent in the Federal contracting industry, bringing new thinking to clients in the Homeland, Federal Civilian, Health and DoD sectors. Through our Human-Centered delivery methodology, we are fundamentally changing the expectations our Federal clients have for true shared accountability in solving their toughest mission challenges. As an employee owned company, we focus on investing in our employees to enable them to do the greatest work of their careers – and rewarding them for outstanding contributions to our growth. If you want to learn more about our story, visit http://www.steampunk.com.

We are an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status, protected veteran status, or any other characteristic protected by law. Steampunk participates in the E-Verify program.
Show Less
Report",4.5,201 to 500 Employees,2003,Company - Private,Information Technology Support Services,Information Technology,Unknown / Non-Applicable
Sr Data Engineer/data architect,$70.00 - $90.00 Per Hour (Employer est.),Devcare Solutions3.6 ★,"Columbus, OH","Role : Data Architect / Bigdata Architect / Hadoop / senior data engineer/ senior Bigdata
skills: oracle, SQL, Hadoop, bigdata , cloud era, Hive, data migration etc.
8+ years Data analysis/architecture experience in Waterfall and Agile Methodology in various domains (prefer Healthcare) in a data warehouse environment.
Good knowledge of relational database, Hadoop big data platform and tools, data vault and dimensional model design.
Strong SQL experience (prefer Oracle, Hive and Impala) in creating DDL’s and DML’s in Oracle, Hive and Impala (minimum of 8 years’ experience).
Experience in analysis, design, development, support and enhancements in data warehouse environment with Cloudera Bigdata Technologies (with a minimum of 8-9 years’ experience in Hadoop, MapReduce, Sqoop, PySpark, Spark, HDFS, Hive, Impala, Stream Sets, Kudu, Oozie, Hue, Kafka, Yarn, Python, Flume, Zookeeper, Sentry, Cloudera Navigator) along with Informatica.
Experience (minimum of 8 years) in working with Sqoop scripts, PySpark programs, HDFS commands, HDFS file formats (Parquet, Avro, ORC etc.), Stream Sets pipelines, jobs scheduling, hive/impala queries, Unix commands, scripting and shell scripting etc.
Experience in migrating data from relational database (prefer Oracle) to big data – Hadoop platform is a plus.
Experience eliciting, analyzing and documenting functional and non-functional requirements.
Ability to document business, functional and non-functional requirements, meeting minutes, and key decisions/actions.
Experience in identifying data anomalies.
Experience building data sets and familiarity with PHI and PII data.
Ability to establish priorities & follow through on projects, paying close attention to detail with minimal supervision.
Effective communication, presentation, & organizational skills.
Good experience in working with Visio, Excel, PowerPoint, Word, etc.
Effective team player in a fast paced and quick delivery environment.
Required Education: BS/BA degree or combination of education & experience.
DESIRED Skill Sets:
Demonstrate effective leadership, analytical and problem-solving skills
Required excellent written and oral communication skills with technical and business teams.
Ability to work independently, as well as part of a team
Stay abreast of current technologies in area of IT assigned
Establish facts and draw valid conclusions
Recognize patterns and opportunities for improvement throughout the entire organization
Ability to discern critical from minor problems and innovate new solutions
Skill
Data analysis/architecture experience in Waterfall and Agile Methodology in various domains (prefer Healthcare) in a data warehouse environment.
Good knowledge of relational database, Hadoop big data platform and tools, data vault and dimensional model design.
Strong SQL experience (prefer Oracle, Hive and Impala) in creating DDL’s and DML’s in Oracle, Hive and Impala
analysis, design, development, support and enhancements in data warehouse environment with Cloudera Bigdata Technologies, along with Informatica
Experience in migrating data from relational database (prefer Oracle) to big data – Hadoop platform is a plus.
Job Type: Contract
Salary: $70.00 - $90.00 per hour
Benefits:
Dental insurance
Health insurance
Vision insurance
Schedule:
8 hour shift
Monday to Friday
Experience:
total: 10 years (Required)
oracle: 4 years (Required)
SQL: 3 years (Required)
cloud era: 3 years (Required)
hadoop / Bigdata: 3 years (Required)
data architect: 1 year (Required)
Data warehouse: 1 year (Required)
Willingness to travel:
100% (Required)
Work Location: On the road
Speak with the employer
+91 6148083833
Show Less
Report",3.6,51 to 200 Employees,2005,Company - Private,Information Technology Support Services,Information Technology,Unknown / Non-Applicable
AWS Data Architect IV,$98K - $142K (Glassdoor est.),Habemco3.5 ★,"Upper Lake, CA","Habemco is a shared services company wholly owned and operated by the Habematolel Pomo of Upper Lake, a federally recognized Native American tribe located in Northern California. Our talented team provides cross-functional support services to various tribal business and government entities. Habemco’s primary support services power the Tribe’s flagship online lending brand, Uprova, and any future brands, through product development, technology, and other support needed for growth. The Habemco team plays a critical role in ensuring a successful future for our customers, our employees, and the Tribe.
Headquartered in a beautiful, yet remote part of California, the Tribe recognizes that to compete in the highly competitive FinTech industry, the Tribe must access expertise throughout the nation. In addition to employees that work remotely, the Tribe has employees clustered at headquarters in Upper Lake, California, and a call center in Lenexa, Kansas.
Employees receive competitive pay and benefits, quarterly performance bonuses and 401(k) with a 4% match. Our team is ambitious, forward-thinking, passionate and moves fast! Are you ready to grow with us?

Purpose of the Position:
The AWS Data Architect IV will provide technology architectural assessments, strategies, and roadmaps for one or more projects & oversee the development and implementation of programs and provide technical leadership and support to the data development teams by identifying best-fit architectural solutions. To be successful in this role, you need deep expertise in design and architecture. You will partner closely with the business analyst, product owners, management, and stakeholders to align the architecture and recommend solutions that meet business and technology needs. All offers are contingent upon signing a confidentiality agreement and satisfactory completion of drug screening and background checks.
Essential Duties
Responsible for overall architecture and design of the solution delivered by the team.
Formulate target state architecture and roadmaps.
Lead a team and provide technical oversight, guidance, and review of the team's deliverables.
Data Modeling & Solution design for data solutions.
Embrace and incubate emerging technology and open-source products across all platforms.
Think outside the box and bring new ideas to the table to modernize the company's existing tech stacks and data platforms.
Advance the enterprise information data & integration architecture strategy.
Partner with architects, product owners, data professionals, and software & data engineers to drive the implementation of new applications.
Work within and across Agile teams to design, develop, test, implement and support technical solutions across full-stack development tools and technologies.
Lead efforts to deploy new and existing applications into AWS environments and provide operational support for the applications.
Conduct design and code reviews to ensure compliance with applicable standards.
Performs ad hoc duties and responsibilities as needed.
Stay up to date with technology, trends, and tools in Big Data.
Regular, reliable attendance during normal business hours.
In-person attendance and travel as requested.
Other duties as assigned.
Education and Experience
Required:
Bachelor's Degree Computer Science or other related technical discipline.
7+ years in IT and 5 years’ experience working as an AWS Data Architect.
5 years in Data warehouse, ETL, and BI projects.
5+ years of experience with Big Data, data streaming, & cloud-based platforms.
5+ years of experience with Data Lake Infrastructure, Data Warehousing, and Data Analytics tools.
Experience in AWS in developing solutions using microservices.
Hands-onexperience on AWS in developing solutions using microservices, AWS Lambda, API / Microservices (Code build, Code deploy and govern), API Gateway, and S3 Storage.
5+ years of experience in solution architecture, design detailing, and technology delivery with a particular focus on AWS platform services.
5+ years of experience in AWS platform services, such as: compute, containers, integration, internet of things, storage, web, and DevOps.
A minimum of two end-to-end implementations of Datawarehouse on Amazon cloud.
Expertise in AWS Platform as a Service (PAAS).
Strong track record of successfully architecting and deploying AWS solutions.
Exposure in defining solution architecture, design detailing, and technology delivery with a particular focus on AWS platform services, such as: compute, containers, integration, internet of things, storage, web, and DevOps.
Hands-on experience on AWS storage services like AmazonS3, Amazon Kinesis, Amazon Dynamo DB, Amazon RDS.
All offers are contingent upon signing a confidentiality agreement and satisfactory completion of drug screening and background checks.Employer observes federal standards for controlled substances.
Preferred:
Hands-on experience on AWS Event/ Data Processing services like AWS Lambda, Amazon Kinesis, Amazon EMR, Amazon Machine Learning.
Hands-on experience on AWS Data Analysis services like Amazon Redshift, Amazon Quick sight.
Experience/knowledge in AWS EKS, AWS Databases (RDS, Dynamo DB, DMS, Elastic Cache, etc.), AWS Faregate, SNS/SQS/Kinesis, Logic Apps, IoT, S3 Data Lake, Athena, and AWS Director services.
Skills and Ability
Advanced problem-solving skills and the ability to optimize data for the best possible outcome.
Ability to prioritize and manage multiple milestones and projects efficiently.
A willingness to dig deep, learn from others, share your own skills, and be part of a talented and dedicated team.
Superior attention to detail.
Highly adaptable, a driver of change, and capable of quickly rallying teams.
Effectively prioritizes and executes tasks in a highly productive yet autonomous environment.
Strong decision-making and problem-solving skills (i.e., design, debugging, and testing) and experience with software development projects.
Ability to present technical ideas in concise, user-friendly, or layman's language.
Strong interpersonal skills used in developing effective working relationships and listening skills.
Result-driven and solutions-oriented with the ability to develop and implement the resolution in time-sensitive situations.
Motivate and mentor team members to grow their skills and careers by creating a nurturing environment that encourages innovation and continual learning.
Ability to work in a fast-paced, time-sensitive, and confidential environment.
Excellent communication skills: utilizing the ability to communicate effectively both orally and in writing with professionalism, excellent grammar, respect and courteousness.
Possess a balance of assertiveness and diplomacy along with adaptability in order to communicate on all levels.
Physical Requirements
Prolonged periods in a stationary seated position, such as working on a computer.
Frequently move, transport, and manipulate computer equipment up to 15 pounds.
Verbal communication sufficient to exchange accurate ideas and information.
In-person attendance and travel as requested.
Show Less
Report",3.5,Unknown,-1,Unknown,Investment & Asset Management,Financial Services,Unknown / Non-Applicable
"Software Engineer, Data Products",$119K - $163K (Glassdoor est.),LaunchDarkly4.1 ★,"Oakland, CA","Please note, before progressing to our application, this position is based in the San Francisco Bay Area and not suitable for remote candidates.
About the Job:
We are looking for exceptional Software Engineers to make a profound impact on how data products will be integrated into companies' software in the future. We are integrating data into everything LaunchDarkly offers on top of our unrivaled feature management platform.
As a Data Products - Software Engineer, you will help us architect and write fast, reliable, and scalable data processing tools to process data from our thousands of customers and their hundreds of millions of users around the world. We're looking for someone who knows what it takes to deliver value to customers and takes pride in the quality of their work.
The primary technologies we use daily include Golang, Scala, Kinesis, and Flink. If working as a part of such a poly-functional team to bring to change how experimentation is done forever appeals to you then come join the Experimentation team at LaunchDarkly.
Responsibilities:
Build and expand our data platform and services
Help us identify the best technologies for our evolving data needs
Collaborate with product team to spec and deliver user-facing features
Monitor and improve data pipeline performance
Actively participate in code reviews
Improve engineering standards, tooling, and processes
Qualifications:
Proven experience and fluency in a JVM or functional language
Experience building data platforms (e.g. using Flink, Kafka, DataFlow, Hadoop, Spark)
Strong communication skills, a positive attitude, and empathy
You write code that can be easily understood by others, with an eye towards maintainability
You hold yourself and others to a high bar when working with production systems
You value high code quality, automated testing, and other engineering best practices
Pay:
Target pay range for a Level P3 in San Francisco/Bay Area: $144,000 - $169,000*
Restricted Stock Units (RSUs), health, vision, and dental insurance, and mental health benefits in addition to salary.
LaunchDarkly operates from a place of high trust and transparency; we are happy to state the pay range for our open roles to best align with your needs. Exact compensation may vary based on skills, experience, degree level, and location.
About LaunchDarkly:
LaunchDarkly is a Feature Management Platform that serves trillions of feature flags daily to help software teams build better software, faster. Feature flagging is an industry standard methodology of wrapping a new or risky section of code or infrastructure change with a flag. Each flag can easily be turned off independent of code deployment (aka ""dark launching""). LaunchDarkly has SDKs for all major web and mobile platforms. We are building a diverse team so that we can offer robust products and services. Our team culture is dynamic, friendly, and supportive. Our headquarters are in Oakland.
At LaunchDarkly, we believe in the power of teams. We're building a team that is humble, open, collaborative, respectful and kind. We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, gender identity, sexual orientation, age, marital status, veteran status, or disability status.
One of our company values is 'Widen the Circle'. Which means we seek out diversity of perspectives to get better results. We understand everyone has their own unique talents and experiences. We encourage you to apply to this role even if you don’t think you meet 100% of the qualifications outlined above. We can find out together if it's the right match for your skillset.
We've partnered with KeyValues to help demonstrate the amazing culture we've built here at LaunchDarkly, find more info at https://www.keyvalues.com/launchdarkly.
LaunchDarkly is also committed to giving back to our community and is a part of Pledge 1%, an organization that helps companies make this a priority. Through this initiative and its charitable arm, the LaunchDarkly Foundation, the company is committed to such causes as supporting education for the underserved, homelessness relief and moving towards having a net-zero carbon footprint. You can find more about the LaunchDarkly Foundation and the organizations we serve at https://launchdarkly.com/foundation/.
Do you need a disability accommodation?
Fill out this accommodations request form and someone from our People Operations team will contact you for assistance.
Show Less
Report",4.1,501 to 1000 Employees,2014,Company - Private,Enterprise Software & Network Solutions,Information Technology,$100 to $500 million (USD)
Azure - Senior Data Engineering Architect,$108K - $210K (Employer est.),Publicis Sapient3.8 ★,"Arlington, TX","Azure - Senior Data Engineering Architect
Full-time
Company Description
Publicis Sapient is a digital transformation partner helping established organizations get to their future, digitally-enabled state, both in the way they work and the way they serve their customers. We help unlock value through a start-up mindset and modern methods, fusing strategy, consulting and customer experience with agile engineering and problem-solving creativity. As digital pioneers with 20,000 people and 53 offices around the globe, our experience spanning technology, data sciences, consulting and customer obsession – combined with our culture of curiosity and relentlessness – enables us to accelerate our clients’ businesses through designing the products and services their customers truly value. Publicis Sapient is the digital business transformation hub of Publicis Groupe. For more information, visit publicissapient.com.
Job Description
Publicis Sapient is looking for a hands-on Senior Manager to join our team of bright thinkers and doers. You’ll use your problem-solving creativity to design, architect, and develop high-end technology solutions that solve our clients’ most complex and challenging problems across different industries. We are on a mission to transform the world, and you will be instrumental in shaping how we do it with your ideas, thoughts, and solutions.
Your impact:
Develop, design, and implement consumer data models based on business requirements and objectives.
Collaborate with various stakeholders, such as business analysts, architects, and developers, to understand data needs and convert these needs into effective data models.
Evaluate and optimize existing data models for improvement.
Ensure that data models adhere to industry best practices, standards, and guidelines.
Conduct data profiling and analysis to identify data quality issues and propose data cleansing and remediation strategies.
Collaborate with database administrators to optimize database performance and maintain data integrity.
Work closely with ETL developers to integrate data models into data integration processes.
Stay updated on the latest trends and technologies in data modeling, cloud computing, and database design.
Mentor, support and manage team members
Qualifications
Your Skills and Experience:
Demonstrable experience in enterprise level data platforms involving implementation of end-to-end data pipelines
Hands-on experience with at least one of the leading public cloud data platforms (Amazon Web Services, Azure or Google Cloud)
Experience with column-oriented database technologies (e.g., Big Query, Redshift, Vertica), NoSQL database technologies (e.g., DynamoDB, BigTable, Cosmos DB, etc.) and traditional database systems (e.g., SQL Server, Oracle, MySQL)
Experience in architecting data pipelines and solutions for both streaming and batch integrations using tools/frameworks like Glue ETL, Lambda, Google Cloud DataFlow, Azure Data Factory, Spark, Spark Streaming, etc.
Metadata definition and management via data catalogs, service catalogs, and stewardship tools such as OpenMetadata, DataHub, Alation, AWS Glue Catalog, Google Data Catalog.
Test plan creation and test programming using automated testing frameworks, data validation and quality frameworks, and data lineage frameworks
Data modeling, querying, and optimization for relational, NoSQL, timeseries, graph databases, data warehouses and data lakes
Data processing programming using SQL, DBT, Python, and similar tools
Logical programming in Python, Spark, PySpark, Java, Javascript, and/or Scala
Cloud-native data platform design with a focus on streaming and event-driven architectures
Participate in integrated validation and analysis sessions of components and subsystems on production servers
Data ingest, validation, and enrichment pipeline design and implementation
SDLC optimization across workstreams within a solution
Bachelor’s degree in Computer Science, Engineering, or related field
Additional Information
Pay Range:$108,000 -$210,000
Benefits of Working Here:
Flexible vacation policy; time is not limited, allocated, or accrued
16 paid holidays throughout the year
Generous parental leave and new parent transition program
Tuition reimbursement
Corporate gift matching program
As part of our dedication to an inclusive and diverse workforce, Publicis Sapient is committed to Equal Employment Opportunity without regard for race, color, national origin, ethnicity, gender, protected veteran status, disability, sexual orientation, gender identity, or religion. We are also committed to providing reasonable accommodations for qualified individuals with disabilities and disabled veterans in our job application procedures. If you need assistance or an accommodation due to a disability, you may contact us at [email protected] or you may call us at +1-617-621-0200.
Apply Now: click Apply Now
Show Less
Report",3.8,10000+ Employees,1990,Company - Public,Business Consulting,Management & Consulting,Unknown / Non-Applicable
"Engineering Director, Commercial Data Engineering",$170K - $255K (Employer est.),Amex4.2 ★,"Phoenix, AZ","You Lead the Way. We’ve Got Your Back.
With the right backing, people and businesses have the power to progress in incredible ways. When you join Team Amex, you become part of a global and diverse community of colleagues with an unwavering commitment to back our customers, communities and each other. Here, you’ll learn and grow as we help you create a career journey that’s unique and meaningful to you with benefits, programs, and flexibility that support you personally and professionally.
At American Express, you’ll be recognized for your contributions, leadership, and impact—every colleague has the opportunity to share in the company’s success. Together, we’ll win as a team, striving to uphold our company values and powerful backing promise to provide the world’s best customer experience every day. And we’ll do it with the utmost integrity, and in an environment where everyone is seen, heard and feels like they belong.
Join Team Amex and let's lead the way together.

As part of our diverse tech team, you can architect, code and ship software that makes us an essential part of our customers’ digital lives. Here, you can work alongside talented engineers in an open, supportive, inclusive environment where your voice is valued, and you make your own decisions on what tech to use to solve challenging problems. Amex offers a range of opportunities to work with the latest technologies and encourages you to back the broader engineering community through open source. And because we understand the importance of keeping your skills fresh and relevant, we give you dedicated time to invest in your professional development. Find your place in technology on #TeamAmex

How will you make an impact in this role?
We’re looking for an experienced data engineering leader to join our Commercial Data Engineering organization. We build data-centric solutions to support the Global Commercial Services product suite including B2B payments, large corporate clients, and our small and medium enterprise ecosystem. You’ll lead your team and partner cross functionally to create innovative, scalable, resilient data systems that enable us to unlock the value of our data for all of our products.
Cultivate an environment of continuous improvement through technical guidance, coaching, mentoring, and feedback.
Lead one or more data engineering teams that iterate on our large-scale distributed, high-performance data platform.
Establish and maintain strong relationships with key stakeholders and cross functional partners to deliver collaboratively.
Perform hands-on architecture, design, development, and testing.
Drive high-level & detailed technical designs and conduct designs & code reviews as needed.
Implement process improvements to streamline areas for your team such as hiring, onboarding, software delivery, and internal/external communication.
Recruit and retain engineering talent.

Minimum Qualifications
Excellent written and verbal communication skills.
Expertise with a major cloud vendor (AWS/GCP).
Expertise with spark, python, SQL.
Experience leading high-performing data engineering teams focused on iterative delivery.
Experience partnering cross functionally and being a hands-on leader to drive successful execution.
Experience with CI/CD and strong understanding of implementing iterative software delivery practices.
Preferred Qualifications
Experience building unified data driven solutions with a data-lakehouse architecture.
Experience building event driven data streaming solutions
Salary Range: $170,000.00 to $255,000.00 annually + bonus + equity (if applicable) + benefits
The above represents the expected salary range for this job requisition. Ultimately, in determining your pay, we'll consider your location, experience, and other job-related factors.
We back our colleagues and their loved ones with benefits and programs that support their holistic well-being. That means we prioritize their physical, financial, and mental health through each stage of life. Benefits include:
Competitive base salaries
Bonus incentives
6% Company Match on retirement savings plan
Free financial coaching and financial well-being support
Comprehensive medical, dental, vision, life insurance, and disability benefits
Flexible work arrangements and schedules with hybrid and virtual options with Amex Flex
20+ weeks paid parental leave for all parents, regardless of gender, offered for pregnancy, adoption or surrogacy
Free access to global on-site wellness centers staffed with nurses and doctors (depending on location)
Free and confidential counseling support through our Healthy Minds program
Career development and training opportunities
For a full list of Team Amex benefits, visit our Colleague Benefits Site.
At American Express, you’ll be recognized for your contributions, leadership, and impact—every colleague has the opportunity to share in the company’s success. Together, we’ll win as a team, striving to uphold our company values and powerful backing promise to provide the world’s best customer experience every day. And we’ll do it with the utmost integrity, and in an environment where everyone is seen, heard and feels like they belong.
American Express is an equal opportunity employer and makes employment decisions without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, veteran status, disability status, age, or any other status protected by law.
We back our colleagues with the support they need to thrive, professionally and personally. That's why we have Amex Flex, our enterprise working model that provides greater flexibility to colleagues while ensuring we preserve the important aspects of our unique in-person culture. Depending on role and business needs, colleagues will either work onsite, in a hybrid model (combination of in-office and virtual days) or fully virtually.
US Job Seekers/Employees - Click here to view the “Know Your Rights” poster and supplement and the Pay Transparency Policy Statement.
If the links do not work, please copy and paste the following URLs in a new browser window: https://www.dol.gov/agencies/ofccp/posters to access the three posters.
Start your job application: click Apply Now
Show Less
Report",4.2,10000+ Employees,1850,Company - Public,Financial Transaction Processing,Financial Services,$10+ billion (USD)
Data Engineer,$70.00 Per Hour (Employer est.),Tellus solutions3.7 ★,"Sunnyvale, CA","Job Description:
The role will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams.
The ideal candidate is an experienced data pipeline builder and data wrangler who enjoy optimizing data systems and building them from the ground up.
The Data Engineer will support our software developers, database architects, and data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple teams, systems and products.
The right candidate will be excited by the prospect of optimizing or even re-designing our data architecture to support our next generation of products and data initiatives.
Responsibilities:
Create and maintain optimal data pipeline architecture for data intensive applications.
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using Azure SQL, Cosmo DB, Databricks and other legacy databases.
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.
Keep our data separated and secure across national boundaries through multiple data centers and Azure regions.
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
Work with data and analytics experts to strive for greater functionality in our data systems.
Qualifications for Data Engineer
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Extensive Experience on Databricks on Azure Cloud platform, deep understanding on Delta lake, Lake House Architecture.
Programming experience on Python, Shell scripting, PySpark, and other data programming language.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with Data Visualization Dashboard, Metrics and etc.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
Skills:
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Working knowledge of message queuing, stream processing, and highly scalable 'big data' data stores.
Familiar with Deployment tool like Docker and building CI/CD pipelines.
Experience supporting and working with cross-functional teams in a dynamic environment.
8+ years' experience in software development, Data engineering, and
Bachelor's degree in computer science, Statistics, Informatics, Information Systems or another quantitative field. Postgraduate/master's degree is preferred.
Experience in Machine Learning and Data Modeling is a plus.
Job Type: Contract
Salary: Up to $70.00 per hour
Benefits:
401(k)
Dental insurance
Health insurance
Schedule:
8 hour shift
Day shift
Application Question(s):
Only US Citizen and Green Card Holder
Experience:
Python, Shell scripting, PySpark: 5 years (Required)
Azure SQL: 5 years (Required)
Work Location: On the road
Show Less
Report",3.7,51 to 200 Employees,2006,Company - Private,Information Technology Support Services,Information Technology,$5 to $25 million (USD)
Senior Data Engineer,$100K - $179K (Employer est.),RVO Health4.0 ★,"Minneapolis, MN","AT A GLANCE
RVO Health is looking for a talented Senior Data Engineer to join our team! As a Senior Data Engineer at RVO Health, you will have the chance to build technology that drives real improvements to consumer health outcomes and has the potential to have widespread impact across the healthcare industry. You will design, develop, test, and maintain big data pipelines for ingestion, segmentation, and reporting to drive our vision!
What You'll Do:
Provide technology ownership for data solutions for projects that the team has been tasked with.
Work with a cross functional team of business analysts, architects, engineers, data analysts and data scientists to formulate both business and technical requirements.
Design and build data pipelines from various data sources to a target data warehouse using batch data load strategies utilizing cutting edge cloud technologies.
Conceptualizing and generating infrastructure that allows data to be accessed and analyzed effectively.
Documenting database designs that include data models, metadata, ETL specifications and process flows for business data project integrations.
Perform periodic code reviews and test plans to ensure data quality and integrity.
Provide input into strategies as they drive the team forward with delivery of business value and technical acumen.
Execute on proof of concepts, where appropriate, to help improve our technical processes.
What We're Looking For:
5+ years of Data Engineering experience
4+ years of experience working on Spark (RDDs / Data Frames / Dataset API) using Scala/Python to build and maintain complex ETL pipelines.
4+ years of experience in the big data space
Experience in translating business requirements into technical data solutions on a large scale.
2+ years of experience working on AWS (Kinesis / Kafka / S3 / RedShift) Or Azure.
Able to research and troubleshoot potential issues presented by stakeholders within the data ecosystem.
Experience with GitHub and CI/CD processes
Experience with Compute technologies like EMR and Databricks
Experience working with job orchestration (eg., Airflow / AWS Step Function)
Experience with Data Modeling, Data warehousing
Working with Kubernetes is a plus
Strong analytical and interpersonal skills.
Enthusiastic, highly motivated and ability to learn quickly.
Able to work through ambiguity in a fast-paced, dynamically changing business environment.
Ability to manage multiple tasks at the same time with minimal supervision.
This position may occasionally require travel for training and other work-related duties.
""Pursuant to various state Fair Pay Acts, below is a summary of compensation elements for this role at the company. The following benefits are provided by RVO Health, subject to eligibility requirements.""
Starting Salary: $100,000 - $178,500*
Note actual salary is based on geographic location, qualifications and experience
Health Insurance Coverage (medical, dental, and vision)
Life Insurance
Short and Long-Term Disability Insurance
Flexible Spending Accounts
Paid Time Off
Holiday Pay
401(k) with match
Employee Assistance Program
Paid Parental Bonding Benefit Program
Who We Are:
Founded in 2022, RVO Health is a new healthcare platform of digital media brands, services and technologies focused on building relationships with people throughout their health & wellness journey. We meet people where they are in their personal health journeys and connect them with both the information and the care they need. RVO Health was created by joining teams from both Red Ventures and UnitedHealth Group's Optum Health. Together we're focused on delivering on our vision of a stronger and healthier world.
RVO Health is comprised of Healthline Media (Healthline, Medical News Today, Psych Central, Greatist and Bezzy), Healthgrades, FindCare and PlateJoy; Optum Perks, Optum Store and the virtual coaching platforms Real Appeal, Wellness Coaching, and QuitForLife.
We offer competitive salaries and a comprehensive benefits program for full-time employees, including medical, dental and vision coverage, paid time off, life insurance, disability coverage, employee assistance program, 401(k) plan and a paid parental leave program.
RVO Health is an equal opportunity employer that does not discriminate against any employee or applicant because of race, creed, color, religion, gender, sexual orientation, gender identity/expression, national origin, disability, age, genetic information, veteran status, marital status, pregnancy or any other basis protected by law. Employment at RVO Health is based solely on a person's merit and qualifications.
We are committed to providing equal employment opportunities to qualified individuals with disabilities. This includes providing reasonable accommodation where appropriate. Should you require a reasonable accommodation to apply or participate in the job application or interview process, please contact accommodations@rvohealth.com.
We do not provide visa sponsorship at this time.
RVO Health Privacy Policy: https://rvohealth.com/legal/privacy
Show Less
Report",4.0,1001 to 5000 Employees,2022,Company - Private,Hospitals & Health Clinics,Healthcare,Unknown / Non-Applicable
Data Architect (Azure),$140K - $160K (Employer est.),LTI - Larsen & Toubro Infotech3.8 ★,"Charlotte, NC","Role: Azure Data Architect.
Location: Charlotte, NC (Onsite or Hybrid Model (3 days onsite/week)
Duration: FTE.
Responsibilities:
You are an expert in Azure Data Analytics having thorough understanding of Azure Data Platform tools
Expertise and hands-on experience on Azure Platform among: Data Factory, Azure Spark
Collaborate with project stakeholders like database administrators, technical architects, , business analysts, big data admins, security experts, information modelling experts to determine project needs and plan development and implementation strategies.
To define, review, and explain Data Architecture requirements & design to all the project stakeholders
Lead the migration of data from legacy systems to newly developed solution.
To create strategies and design solutions for wide variety use cases like Data Migration (end to end ETL process), database optimization, data architectural solutions for Analytics and Big Data Projects
To design, develop and troubleshoot highly complex technical problems in OLAP/OLTP/DW, Analytics, Big Data environments and provide solutions for Enterprise level Applications utilizing Azure Data Platform
To implement data quality processes for use with MDM, BI solutions, data warehouses, EAI solutions, etc.
Work on streamlining data flows and data models consistently
Have a keen focus on improving and tuning data quality, accessibility, performance and security needs
Skills Required
Bachelor/ master’s degree in computer science engineering,
Self-driven, and able to think holistically of the product roadmap
Performing reviews of data Architecture and Designs
Research new technologies and data modelling methods
Creative in solving complex business problems
Hands-on experience in business analysis, pre-sales, solution proposals, development
Excellent written & verbal communication
Job Type: Full-time
Salary: $140,000.00 - $160,000.00 per year
Benefits:
401(k)
401(k) matching
Dental insurance
Health insurance
Paid time off
Vision insurance
Schedule:
Monday to Friday
Ability to commute/relocate:
Charlotte, NC 28202: Reliably commute or planning to relocate before starting work (Required)
Experience:
Data Architect: 10 years (Required)
Azure: 8 years (Required)
Azure data factory: 5 years (Required)
Azure DataBricks: 5 years (Required)
Data modeling: 8 years (Required)
Adobe Spark: 5 years (Required)
Data Migration: 4 years (Required)
OLAP: 6 years (Required)
Work Location: In person
Show Less
Report",3.8,10000+ Employees,1997,Company - Private,Information Technology Support Services,Information Technology,Unknown / Non-Applicable
Data Engineer,$110K (Employer est.),Capitol Federal2.9 ★,"Topeka, KS","Job Description:
Pay: up to $110,000 Annually
Job Type: Full Time
The Data Engineer assists in setting overall development roadmap and standards for the Bank and helps evaluate and architect the use of data solutions, using industry best practices. This position works as part of a collaborative team to design, code, and implement data solutions to support internal business requirements or external customers and vendors. An innovative mindset and an ability to translate complex business scenarios into a technical solution is required. This position performs a variety of tasks under general supervision. The position reports directly to an IT manager and requires regular, predictable and timely attendance at work to meet department workload demands.
Paid time off and holiday available on your first day! Benefits available to anyone working 20 hours or more per week!
CapFed® is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees.
Job Type: Full-time
Work Location: In person
Show Less
Report",2.9,501 to 1000 Employees,1893,Company - Public,Banking & Lending,Financial Services,$100 to $500 million (USD)
Sr. Data Architect,-1,Planet Fitness3.4 ★,Remote,"About Us:
Founded in 1992 in Dover, NH, Planet Fitness is one of the largest and fastest-growing franchisors and operators of fitness centers in the United States by number of members and locations. We have over 2,400+ stores in 50 states, the District of Columbia, Puerto Rico, Canada, Panama, Mexico, and Australia. More than 90% of Planet Fitness stores are owned and operated by independent business men and women.

At Planet Fitness, our unique mission has always been to enhance people’s lives by providing a high-quality fitness experience in a welcoming, non-intimidating environment. And we’re proud of the amazing Planet Fitness team that supports our clubs and team members. They are comprised of dynamic, dedicated, and talented individuals who represent our values of integrity, transparency, passion, respect, and excellence (while having fun!) in everything they do.

Joining the PF family means being part of a company that cares about bettering the health and wellbeing of our communities. It means being a part of a supportive, engaging workforce with an inclusive culture that values diversity and creates an environment where everyone can feel they belong. It means encouraging professional growth and development. It means making true, lasting connections with your co-workers with celebrations, team building activities and engaging corporate events! It means creating a positive impact in our local communities through our Judgement Free Generation® philanthropic initiative. It means being part of a brand that you can be proud of!

For the past 30 years, we’ve helped millions of people in their fitness journey and revolutionized the industry along the way. And we’re just getting started!
Overview:
The Sr. Data Architect will be responsible for creating and maintaining a scalable enterprise data architecture at Planet Fitness. In this role, you will facilitate the development of data modeling standards, guidelines, and techniques. You will collaborate across the data engineering, business intelligence engineering, and data governance teams to ensure data architectures are consistent and adhere to defined policies and standards. And as our Sr. Data Architect, you will also collaborate with the broader technology organization to implement data management best practices and improve data quality at the source of truth/system of record.

For team collaboration purposes, the ideal candidate currently resides in the CST or EST zones.
Responsibilities:
Create and maintain data architecture designs that support business and technical requirements for high-quality, performant data solutions.
Implement data modeling standards and ensure adherence within data management solutions.
Research and recommend tools and services to improve data management processes and support architectural standards and patterns.
Participate in data solution prototyping initiatives.
Create and maintain documentation related to data architecture standards, protocols, and frameworks.
Implement culture of continuous improvement of data architecture approaches to align to best practices and data management technology evolution.
Foster environment of continuous learning, maintain current knowledge of emerging technologies and industry trends, and present ideas for innovation.
Perform analytical exploration and examination of data from multiple data sources.
Participate in enforcing data quality and governance best practices in the data platform.
Work with a multi-disciplinary team consisting of data analysts, data engineers, developers and data consumers in an agile, fast-paced environment.
Work with and support a team that is globally located.
Participate in review processes that involve architecture, design and quality assurance to preemptively identify conflicts and ensure consistency of implementation.
Ensure strict adherence to documentation best practices and change control processes.
Perform other duties as assigned.
Qualifications:
Bachelor’s degree in Computer Science, Information Technology, Data Analytics, Information Systems or a related field
10+ years of direct experience in Big Data, Data Warehousing, Data Analytics, and/or Information Management related projects
6+ years of direct experience in cloud data solution architectures, design and development including ETL, data warehousing, data lakes, and big data
5+ years of experience using SQL including development of stored procedures, functions, triggers and views
5+ years of direct experience with one or more database/data warehouse technologies (e.g., Oracle, MSSQL, MySQL, PostgreSQL, Hadoop, Teradata, Redshift, Snowflake)
5+ years of direct experience working in a cloud environment such as AWS, Azure or GCP
Excellent critical thinking and problem-solving skills
Must be self-sufficient and proactive
Deep understanding of agile development methods including: core values, guiding principles, and key agile practices
A strong understanding of data mining, predictive modeling, and statistical analysis
Experience working in retail business (preferred)
Experience working in a franchised business (preferred)
Extremely detail-oriented, efficient, and organized with an exceptional ability to establish and balance multiple priorities and objectives
Excellent presentation and communication skills along with the ability to communicate effectively across all levels of the organization
Able to establish and maintain effective, collaborative work relationships with diverse individuals, internally and externally
Creative, progressive, thought leadership with the ability to influence at all levels of the organization
Dedicated learner with a natural curiosity for consistent growth
Exhibits comfort, ease, and flexibility working in an extremely fast-paced ever-changing, deadline-driven environment
Cooperative team player with an upbeat, positive, “can-do” attitude!
Perks:
Remote work allowed
Volunteer days off
Competitive salaries and comprehensive benefits package, including medical, pharmacy, dental and vision benefits
Generous vacation/holiday pay
401(k) Retirement
Employee Stock Purchase Program
Childcare reimbursement
Pet care reimbursement
Learning and development programs
Discount programs, including vacations, theme parks, shopping, meal delivery services & much more
Free Black Card membership and fun exercise incentives
Company-sponsored social events
Apply Now: click Apply Now
Show Less
Report",3.4,201 to 500 Employees,1992,Company - Public,Beauty & Wellness,Personal Consumer Services,$5 to $25 million (USD)
"Data Architect, IT",$83K - $129K (Glassdoor est.),UofL Health3.4 ★,"Louisville, KY","Overview:
We are Hiring for our Information Technology team.
Shift Options: Full Time & Days

About Us
UofL Health is a fully integrated regional academic health system with seven hospitals, four medical centers, nearly 200 physician practice locations, more than 700 providers, the Frazier Rehabilitation Institute and the Brown Cancer Center.
With more than 12,000 team members—physicians, surgeons, nurses, pharmacists and other highly skilled health care professionals—UofL Health is focused on one mission: delivering patient-centered care to each and every patient each and every day.

Our Mission
As an academic health care system, we will transform the health of the communities we serve through compassionate, innovative, patient-centered care.

Job Summary
The Data Architect supports the design, development and implementation of all data initiatives at ULH. Leads the enterprise information management strategy fostering IT – Business collaboration in understanding of enterprise data, binding disparate, heterogenous data sources together in a framework for access and sharing of data, developing data trust across the organization and instituting best practices and standards in data use.

Leads the implementation, enhancement and on-going support of enterprise data platform utilizing data modeling concepts for model extension and ETL programs to transform and ingest data.
Supports the data through its life cycle utilizing data governance principles that ensure data quality, integrity, stewardship, security, literacy and adoption.
Develops and enforces implementation of standards and best practices involved in data modeling (conceptual/logical/physical models), data architecture design patterns (EDW/data marts/data lakes) and ETL.
Conducts research and makes recommendations on products, tools, services, protocols and standards that will support ULH’s data management strategy.
Works in concert with BI Developers and business teams to understand business requirements and translating those requirements into developing value-add BI/Analytics solutions.
Designs and maintains a curriculum for coaching and training current and prospective end users to better understand how these tools can enhance business decision making capabilities.
Provides Level 1, 2 and 3 support for day-to-day production issues maintaining documentation in the appropriate tracking systems while adhering to prescribed escalation & change control procedures. Includes on call rotation.
Adheres to all Security Standards as set forth by the organization and National guidelines.
Additional tasks/responsibilities as defined.
Responsibilities:
Works closely with Analytics leadership team, business teams and IT infrastructure teams to design, implement and support the goals and objectives of the organization set by the leadership.
Leads the implementation, enhancement and on-going support of enterprise data platform utilizing data modeling concepts for model extension and ETL programs to transform and ingest data.
Conducts research and makes recommendations on products, tools, services, protocols and standards that will support ULH’s data management and BI strategies.
Supports the data through its life cycle utilizing data governance principles that ensure data quality, integrity, stewardship, security, literacy and adoption.
Proactively communicate and collaborate with internal and external customers to analyze information needs and functional requirements and delivery.
Performs Tier 1, 2 and 3 Application/Systems support.
Maintains relationship with vendors of hospital applications to understand current and future features and functionality and product life cycle.
Qualifications:
Education / Accreditation / Licensure (required & preferred):
Bachelor’s Degree in Business, Information Science or Computer Science required. Master’s Degree highly preferred

Experience (required and preferred):
7+ years of experience in supporting/developing/extending data warehouse/data mart solutions required.
5+ years of experience with data modeling concepts translating business requirements into conceptual, logical and physical models required.
5+ years of experience in ETL development preferably with SSIS required.
Expert knowledge of data governance practices and data life cycle management highly desired.
Experience in Agile development methodology for analytics projects required.
Experience and ability in working directly with vendors, customers and other IT teams.
Apply Now: click Apply Now
Show Less
Report",3.4,1001 to 5000 Employees,-1,Hospital,Health Care Services & Hospitals,Healthcare,$100 to $500 million (USD)
AWS Data Architect,$90.00 Per Hour (Employer est.),Blue Ocean Ventures3.5 ★,"Santa Monica, CA","Responsibilities / Qualifications:
· Candidate must have 10+ years of IT working experience with at least 5 years of experience on AWS Cloud environment is preferred.
· Working experience with Agile Methodology
· Experience working with source code management tools such as GitHub
Experience working with Jenkins or any CI/CD Pipelines using AWS Services
Job Type: Contract
Pay: From $90.00 per hour
Benefits:
401(k)
Dental insurance
Vision insurance
Schedule:
8 hour shift
Day shift
Ability to commute/relocate:
Santa Monica, CA 90401: Reliably commute or planning to relocate before starting work (Required)
Experience:
Data architect: 10 years (Preferred)
Work Location: In person
Speak with the employer
+91 7022159709
Show Less
Report",3.5,51 to 200 Employees,-1,Company - Private,HR Consulting,Human Resources & Staffing,Unknown / Non-Applicable
Senior Azure Data Architect,-1,Lighthouse MTG LLC,Rhode Island,"Azure Data Architect
Description:
Spyglass MTG (Microsoft Technology Group) is a Microsoft Gold Certified Partner. We hire people who are professional consultants in addition to being highly competent performers in their specific discipline. As a Consultant at Spyglass MTG you will be working on projects to develop Microsoft technology focused solutions for a variety of clients in industries such as Financial Services, Healthcare, Life Sciences, Manufacturing and Higher Education. Our office is in Lincoln, RI, however our clients are typically located in the Greater Boston and New England area. You will be working in a team environment that consists of Spyglass and Client members.
As an Azure Data Architect, you will join our increasingly growing and exciting Azure Data and Analytics practice. You will be required to apply enterprise principles, standards and practices serving as the conduit for influencing our clients Enterprise Data Architecture’s direction while optimizing solutions for them. You will evaluate business needs and objectives, current and future state and transform into Azure data solutions that meet performance, scalability, reliability, and security needs. You must also provide technical guidance and oversight to development team, mentor those in less senior positions and ensure a consistent state of excellence during and post-delivery of the solution. You will be integral to the design, development, and delivery of all modern data solutions on Azure for our clients.
Candidate Expectations:
Architect, Design and deploy architecture to support data transformation, data structures, metadata, dependency, and workload management.
Experience deploying modern data solutions leveraging components like Azure functions, Azure Data Factory, Data Flows, Azure Data Lake, Azure SQL, Azure Synapse, Streaming Analytics and more.
Provide oversight and guidance to data, BI and ML engineering teams. It is expected that you provide direct experience within these core areas.
Experience with one or more languages: Python & Pyspark, T-SQL, SparkR & R, Scala.
Experience with code deployment in Azure Databricks environment.
Familiarity with DevOps tools like Azure DevOps, Jenkins, Maven etc.
Experience working with Azure data platforms, integration techniques & self-service data preparation.
Assist business users on functional and data requirements to enhance data models and pipelines.
Experience in requirements analysis, design, and prototyping.
Basic Qualifications:
8+ years of relevant professional technology experience
5+ years of experience in a programming language like SQL, Python or Scala
5+ years of working experience with SQL Server, data warehousing and data analytics projects
5+ years of experience data engineering in cloud and on-prem environments
MUST HAVE Experience deploying Azure data solution with Azure Data Factory, Azure Synapse, Data Lake or other Azure data service.
MUST HAVE Experience architecting and Azure data solution with Azure Data Factory, Azure Synapse, Data Lake or other Azure data service.
MUST HAVE Experience data engineering Azure Data Factory or Azure Synapse
Experience building scalable data platforms.
Experience with Azure solutions and infrastructure
Minimum of a Bachelor’s degree in Computer Science, Computer Engineering, Software Design, Software Engineering, or a related field, or equivalent alternative education, skills, and/or practical experience
Preferred Qualifications:
MS Certified: Data Engineering Associate
MS Certified: Azure Solutions Architect Expert
3+ years of experience with Azure SQL, Azure Synapse, SQL DW or other Cloud Data Services.
2+ years of experience with version control and DevOps or DataOps.
5+ years programming with SQL, Python, Scala or R.
5+ years developing, deploying, and testing data pipelines in Azure or other cloud provider.
5+ years of data engineering with Hadoop, Spark, Databricks, SSIS or other data integration tool.
Master’s degree in Computer Science, Computer Engineering, Software Design, Software Engineering, or a related field, or equivalent alternative education, skills, and/or practical experience.
Benefits:
Medical, Vision and Dental Plans
Life and Disability Insurance
Open PTO Policy
Holiday PTO
Paid training certification
Bonus plan
401k
Flexible working arrangements
& more
All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, transgender status, national origin, citizenship, age, disability or protected veteran status.
Show Less
Report",-1,Unknown,-1,Company - Public,-1,-1,Unknown / Non-Applicable
"Senior Solution Architect, Data & Analytics - Remote",$128K - $200K (Employer est.),EPAM Systems4.1 ★,Remote,"Are you an influential Architecture leader with a passion for leading strategic initiatives that make a huge impact? We are hiring a Senior Data Solution Architect, who will work alongside a dynamic team to identify complex business problems and create solution-oriented strategies for some of the most recognized brands. Apply now to connect with a recruiter about this influential role at EPAM!

Req.#180339287

RESPONSIBILITIES
Provide support in the solution decision making process as a trusted technical advisor
Design, implement, and deploy data platforms at scale in public and private cloud enviroments
Guide clients on establishing a data practice on an enterprise level by improving their data strategy, data governance, data architecture and data quality management
Drive and execute the technical stream of data strategy engagements by conducting customer workshops, discovery sessions solution and presentations
Educate clients on modern technologies, architectures and approaches for data & analytics by explaining their value for business
Define business and development processes as well as platform + tool usage for data acquisition, storage, transformation, and analysis
Communicate different solution and technology options, while articulating short and long-term consequences & their impact on business
Develop roadmaps and implementation strategy around data & analytics initiatives
Review and audit existing solutions, designs and system architectures while creating architecture documentation & presentations
Implement scalable data platform architecture
Discuss proposed solution to multiple level of stakeholders from C-level to engineering teams

REQUIREMENTS
Extensive experience within Solution Architecture with a strong background in data & analytics
Highly Skilled with designing, developing and maintaining enterprise scale data platforms
History working with with big data technologies and frameworks such as Databricks, Snowflake, Apache Spark, Kafka, Apache Flink, AWS Glue + Redshift, GCP Dataflow + BigQuery, Azure Data Factory + Synapse
Expert within Big Data solutions developed in large cloud computing infrastructures such as Amazon Web Services, Azure Cloud, or Google Cloud
Hands on experience with client-driven large-scale implementation projects
Background in programming and scripting languages such as Java, Python, or Scala
Strong understanding of Data Science and Analytics experience such as Machine Learning, Deep Learning, Recommendation Engines & Search Personalizations
Comfortable leading technical agile teams with common SCRUM & SDLC practices
Solid knowledge of design patterns, refactoring concepts, unit tests and CI/CD
Practical expertise in performance tuning &optimization
Solid troubleshooting & problems analysis skills
Ability to travel up to 20%

BENEFITS
Medical, Dental and Vision Insurance (Subsidized)
Health Savings Account
Flexible Spending Accounts (Healthcare, Dependent Care, Commuter)
Short-Term and Long-Term Disability (Company Provided)
Life and AD&D Insurance (Company Provided)
Employee Assistance Program
Unlimited access to LinkedIn learning solutions
Matched 401(k) Retirement Savings Plan
Paid Time Off – the employee will be eligible to accrue 15-25 paid days, depending on specific level and tenure with EPAM (accrual eligibility may change over time)
Paid Holidays - nine (9) total per year
Legal Plan and Identity Theft Protection
Accident Insurance
Employee Discounts
Pet Insurance
Employee Stock Purchase Program
If otherwise eligible, participation in the discretionary annual bonus program
If otherwise eligible and hired into a qualifying level, participation in the discretionary Long-Term Incentive (LTI) Program

ABOUT EPAM
EPAM is a leading global provider of digital platform engineering and development services. We are committed to having a positive impact on our customers, our employees, and our communities. We embrace a dynamic and inclusive culture. Here you will collaborate with multi-national teams, contribute to a myriad of innovative projects that deliver the most creative and cutting-edge solutions, and have an opportunity to continuously learn and grow. No matter where you are located, you will join a dedicated, creative, and diverse community that will help you discover your fullest potential

ADDITIONAL
This posting includes a good faith range of the salary EPAM would reasonably expect to pay the selected candidate. The range provided reflects base salary only. Individual compensation offers within the range are based on a variety of factors, including, but not limited to: geographic location, experience, credentials, education, training; the demand for the role; and overall business and labor market considerations. Most candidates are hired at a salary within the range disclosed. Salary range: $128k - $200k In addition, the details highlighted in this job posting above are a general description of all other expected benefits and compensation for the position
Start your job application: click Apply Now
Show Less
Report",4.1,10000+ Employees,1993,Company - Public,Information Technology Support Services,Information Technology,$1 to $5 billion (USD)
Sr. Data Engineer - Remote,-1,Chamberlain Group3.7 ★,Illinois,"Chamberlain Group is a global leader in access solutions with top brands, such as LiftMaster and Chamberlain, found in millions of homes, businesses, and communities worldwide.
As a leader in the Smart Home industry, we boast one of the largest IoT install bases, with innovative products consisting of cameras, locks, card readers, garage door openers, gates and more, all powered by our myQ digital ecosystem.
This role is responsible for providing technical expertise and leadership to design and deliver end-to-end data engineering solutions to support advanced analytics capabilities and drive innovation and decision-making
across Chamberlain.
Essential Duties and Responsibilities
Build and maintain real-time and batch data pipelines across the advanced analytics platform.
Design, develop and orchestrate highly robust and scalable ETL pipelines.
Design and implement Dimensional and NoSQL data modelling as per the business requirements.
Develop highly optimal codebase and perform Spark optimizations for Big Data use cases.
Design, develop and deploy optimal monitoring and testing strategy for the data products.
Collaborate with stakeholders and advanced analytics business partners to understand business needs and translate requirements into scalable data engineering solutions.
Collaborate with data scientists to prepare data for model development and production.
Collaborate with data visualization and reporting application developers to ensure the sustainability of production applications and reports.
Collaborate with data architects on the enhancement of Chamberlain’s enterprise data architecture and platforms.
Provide leadership to third-party contractors.
Comply with health and safety guidelines and rules.
Protect CGI’s reputation by keeping information confidential.
Maintain professional and technical knowledge by attending educational workshops, professional publications, establishing personal networks, and participating in professional societies.
Minimum Qualifications
Education/Certifications:
Bachelor’s degree in computer science or related quantitative field of study
Experience:
4+ years of professional experience
Knowledge, Skills, and Abilities:
Natural sense of urgency, teamwork, and collaboration reflected in daily work ethic.
Proficient in Spark or Databricks, Cloud Data Engineering Services preferably Azure, Streaming frameworks like Event Hubs or Kafka.
Proficient in Microsoft Office.
Familiarity with modern Machine Learning Operationalization techniques.
Agile methodologies.
Familiarity with Data visualization tools, such as Qlik or Power BI.
Preferred Qualifications
Education/Certifications:
Master’s degree in computer science or related quantitative field of study
Experience:
4+ years of professional experience
2+ years of professional experience delivering engineering for advanced analytics or data science solutions
Knowledge, Skills, and Abilities:
Agile methodologies
Experience with IoT Data Architecture.
Machine Learning Operationalization (MLOps) proficiency.
REST API design and development.
Proficiency with streaming design patterns.

The pay range for this position is $103,300.00 to $177.475.00; base pay offered may vary depending on a number of factors including, but not limited to, the position offered, location, education, training, and/or experience. In addition to base pay, also offered is a comprehensive benefits package and 401k contribution (all benefits are subject to eligibility requirements).
This position is eligible for participation in a short-term incentive plan subject to the terms of the applicable plans and policies.
#LI-Remote
We're an organization who values its human capital and provides support to assist its employees succeed.

Chamberlain Group is proud to be an Equal Opportunity Employer. You will be considered for this position based upon your experience and education, without regard to race, color, religion, sex, national origin, age, sexual orientation, ancestry; marital, disabled or veteran status. We are committed to creating and maintaining a workforce environment that is free from any form of discriminations or harassment.

Persons with disabilities who anticipate needing accommodations for any part of the application process may contact, in confidence
Recruiting@Chamberlain.com
.

NOTE: Staffing agencies, headhunters, recruiters, and/or placement agencies, please do not contact our hiring managers via email or phone or other methods.
To apply to this job, click Apply Now
Show Less
Report",3.7,1001 to 5000 Employees,1900,Company - Private,Consumer Product Manufacturing,Manufacturing,$500 million to $1 billion (USD)
Data & Analytics Engineer,$80K - $107K (Glassdoor est.),Robert W. Baird4.3 ★,"Louisville, KY","As we continue to grow and add top talent to the Baird family of technical associates, we are looking for a Data & Analytics Engineer for our growing data team. This is a key role on our IT Data Team requiring a broad range of skills and the ability to step into different roles depending on the size and scope of the business need. The self-motivated candidate will have proven experience architecting successful data solutions on key projects in a collaborative environment. Success will come from being able to prioritize, deliver value incrementally, problem solve, and manage changing priorities. You will work closely with our business partners and interface with both technical and non-technical colleagues.
This position is hybrid, working a combination of remote and in-office in our new collaborative work space. We offer a collaborative culture with a continuous learning, agile/lean environment and adding value to the Baird business. Learn more about Baird IT here.

As a Data & Analytics Engineer, you will:
Data Architecture
Specialize in data modeling, both 3NF and dimensional, with experience in conceptual, logical, physical, and industry data modeling. Strong knowledge and experience with data architecture methodologies.
Apply the appropriate level of modeling theory, pattern recognition, and abstractions to architect and design a pragmatic solution that functionally meets the business and technical requirements.
Partner with internal business units to define information requirements and translate them into appropriate data solutions.
Collaborate with IT and business partners to lead data discovery, profiling, analysis, and quality assessments in order to obtain clear information requirements.
Develop and validate source to target mappings and transformation logic required to support business needs. Understand the importance of capturing data lineage.
Architect, implement and verify end-to-end data solutions.
Develop test plans needed to ensure a quality deliverable. Participate in validation testing, coordinate user acceptance testing and training to ensure the final implementation enables the user to solve their business problem.
General Data Management
Play a critical role in architecting our data and analytics solution landscape
Demonstrate competence, experience, knowledge, understanding, and advocacy of data management concepts, data warehousing, BI, and analytics.
Demonstrate ability to perform appropriate level of strategic thinking by viewing initiatives both within the immediate project context as well as the overall architectural vision.
Participate and/or Lead in data architectural design and strategy discussions.
Data Delivery
Work with the business users to conduct data discovery engagements and can quickly identify, and prototype, a solution that brings together multiple data sources into one coherent concept and understanding. (data blending)
Leverage existing tools to create data visualizations and mentors the business to be self-sufficient.
Collaborate – build relationships!
Identify and communicate project risks and impediments and proactively work with other members of the Analytics team to complete high-value deliverables as identified by business partners and team leadership.
Partner with Analytics team members to translate business and functional requirements into technical designs
Strive to understand the data consumption needs of the business community, as well as the problems faced by business users involving the access and use of data
Help Analytics teams develop solutions that enable businesses to capitalize on business insights and drive toward gaining a competitive advantage
What makes this opportunity great:
Information technology is a core part of Baird’s business strategy and plays a critical role in the growth and transformation of the firm.
On Computerworld’s ‘Best Company to Work For’ list for five consecutive years with a collaborative culture that values diverse backgrounds and perspectives while emphasizing teamwork and a strong sense of partnership.
Support and flexibility to grow and be your best at work, at home, and in the community.
What we look for:
Minimum of 3-5 years of experience in Data Solution delivery in a complex environment working collaboratively in a team setting
Proficient in Data Solution tools and concepts such as:
Business Intelligence tools: Microsoft tools (SQL Server Management Studio, SSRS, SSAS, Power Pivot, Power Query, PowerBI), Alteryx
Database: SQL Server
Data Query tools: SQL, T-SQL
Data Management and Quality: data mapping, data profiling, metadata repository, relational data modeling, master data management
Data Modeling: ER/Studio Data Architect, 3NF and dimensional modeling
Data Warehousing concepts: Inmon, Kimball, Data Lake
Data Integration concepts and strategies: EII, ETL, EL-T and EAI
#LI-SB1
Commitment to Inclusion & Diversity
Baird is committed to inclusion & diversity for our clients, our associates and the communities where we live and work. This commitment stems from our culture of integrity, genuine concern for others and respect for the individual. We view inclusion & diversity as an ongoing journey – one of shared responsibility, continuous improvement and a focus on progress. We invite you to join us as we work together to foster an environment where diversity unites rather than divides us.
Start your job application: click Apply Now
Show Less
Report",4.3,1001 to 5000 Employees,1919,Company - Private,Investment & Asset Management,Financial Services,$1 to $5 billion (USD)
Data Modeler/Architect,-1,Agama Solutions3.9 ★,United States,"Bachelor’s degree in Computer Science, Information Systems , or other related field or equivalent work experience • Typically has 5+ years of IT experience with at least 3 years of data management, metadata and data quality experiences • Expertise with data quality tools for data profiling, cleansing and standardization • May require experience in implementing solutions and processes for master data and hierarchy synchronizations • Knowledge of logical data architecture

Responsibilities:
• Provides support for metadata management system development, implementation and maintenance • Works with the IT teams to understand data requirements • Collects, analyzes and summarizes data to support business decisions • Provides data that is congruent, reliable, and easily accessible by the user • Utilizes tools to monitor and mass update data changes • Translates business requirements into conceptual, logical and physical data model • Develops and maintains the logical and physical data models • Uses technology to extract and analyze raw data • Develops and maintains technical documentation regarding data • Makes recommendations for process improvements in order to support data integrity efforts • Analyzes program needs and translates them into data warehousing and data mart requirements • Designs, develops and deploys query parameters, layout, filters, and analytics for program information solutions • Recognizes and resolves conflicts between models, ensuring that data models are consistent with the enterprise model (e.g., entity names, relationships and definitions) • Communicates data integrity accuracy to the business, and escalates / communicates issues when necessary • Provides guidance on complex issues to other team members • Supports the development of automated solutions which enhance the quality of enterprise data • Performs regular data audits • Builds data migration and single source strategies • Participates in establishment of governance for metadata management across the enterprise • Ensures integration of project logical data model into enterprise conceptual data model • Works in partnership with data architects to design a common customer view of information • Oversees the design and implementation of data cleansing procedures • Works with project teams to understand the business environment in order to manage enterprise-wide information/data support systems • Researches internal and external data sources for new data and improved sources of data feeds Complexity • Works on multiple projects/issues/enhancements as a team leader • Works on complex enterprise-wide projects/issues/enhancements • Designs logical enterprise-wide data models • Provides support for master data management, logical data, quality system development, implementation and maintenance
Show Less
Report",3.9,51 to 200 Employees,-1,Contract,Computer Hardware Development,Information Technology,$5 to $25 million (USD)
Senior Data Architect,$106K - $201K (Employer est.),PSRTEK4.5 ★,Remote,"Role: Data Architect
Remote can be consider
Expert level knowledge in two or more of the following subject areas specialisms, so that you can lead data technology architecture from a position of technical authority:
Data Engineering patterns and practices for efficient & optimized utilization from raw data
Data Warehousing, semantic layer definitions and scaled data consumption patterns.
Distributed compute and processing data in parallel.
Robust enterprise grade data integration, ingestion, management & pipelines.
Data streaming and associated ”Lambda” style data architectures.
Operationalization of Data Science outcomes, including continuous model qualification.
Experience of 2 or more of the following core Azure data components, or very strong adjacent experience from other platforms. o Azure Storage (Data Lake Store, Blob Storage, etc.
Data Bricks / PYSpark / Azure Data Lake Analytics
Azure DW/Synapse
Azure Functions, Event Hub and other adjacent data relevant components.
IaC / Automated delivery technology such as Azure DevOps, Terraform, Ansible, etc.
Azure Kubernetes Service or other Containerized delivery technology.
Experience delivering specialized & detailed reference architectures as content
Experience with data modelling and distributed data architecture concepts, fluency with agile and DevOps methodology and automaton practices
Superb problem solving and outstanding communication skills with the ability to describe complex & abstract technical concepts to peers and engineers.
12+ years’ total experience with at least 5 years of senior architecture leadership roles
Job Types: Full-time, Contract
Salary: $105,900.45 - $201,312.11 per year
Experience:
APPTUS: 4 years (Preferred)
Work Location: Remote
Speak with the employer
+91 609-934-3291
Show Less
Report",4.5,Unknown,-1,Company - Private,Information Technology Support Services,Information Technology,Unknown / Non-Applicable
GCP Data Architect,-1,Rinf4.4 ★,Remote,"Job Information
Competence
Development
Level of Experience
Senior; Expert
Industry
Banking
Remote Job
Job Description
This is a remote position.
Rinf.tech is a technology consulting and software services company. Founded in 2006 in Romania, we have grown into a global organization with 600+ engineers and 8 Delivery Centers in Europe and North America (Romania, Bulgaria, Ukraine, Turkiye, and Mexico).
We offer custom software solutions and support for our worldwide partners through three main Business Units: Business Applications, R&D Embedded, Robotics, and Automotive.
At Rinf.tech, you’ll come across friendly people and a genuine way of thinking. RINFers are eager to learn from each other, explore and reinvent the world of technology. We have an inspiring place to share ideas and build amazing products together: www.rinf.tech.
What you will be working on
Contribute to the Design and implementation of scalable and secure GCP solutions based on business requirements, industry best practices, and security standards.
Design the integration of GCP services, including Compute Engine, Cloud Storage, Cloud Networking, BigQuery, and Dataflow, to ensure optimal performance and availability.
Monitor and troubleshoot product and services to proactively identify and resolve any performance, security, or operational issues.
Collaborate with cross-functional teams, including IT, data engineers, and developers, to ensure seamless integration of GCP services into our applications and infrastructure.
Provide technical guidance and support to team members, stakeholders, and customers on GCP-related matters.
Stay up-to-date with the latest trends and developments in GCP technologies and provide recommendations on adopting new features and services to enhance our cloud infrastructure.
Develop and maintain documentation, including technical designs, configuration guides, and operational procedures for GCP services.
Implement and enforce security best practices and ensure compliance with regulatory requirements.
What you offer us
Strong experience in designing and managing Google Cloud Platform (GCP) services, including Compute Engine, Cloud Storage, Cloud Networking, BigQuery, and Dataflow.
In-depth knowledge of GCP technologies, architectures, and best practices.
Familiarity with GCP security features, including Identity and Access Management (IAM), Cloud Identity-Aware Proxy (IAP), and VPC Service Controls.
Strong troubleshooting and problem-solving skills with the ability to analyze complex technical issues and provide timely resolutions.
Excellent communication and collaboration skills with the ability to work effectively in cross-functional teams.
Realization skills with the ability to take on a challenge and make it happen.
Strong analytical skills and the ability to take decisions based on data and facts.
Solid communication and collaborative skills to interact with different stakeholders.
Understand the need to comply with regulations and policies, but dare to debate alternatives.
What we offer you
Flexible working environment
Learning budget and platforms
Wide variety of projects you could be part of
Medical subscription
HR representative to guide you in your professional career development
Flexible benefits platform
Bookster
Our recruitment process
HR Discussion
Technical interview
Offer
Meet us!
If you are still unsure, we are inviting you to come by anytime for a tour of our office without any commitment.
All applications are strictly confidential. We will not disclose any private information without having your approval.
Show Less
Report",4.4,201 to 500 Employees,2006,Company - Private,Information Technology Support Services,Information Technology,$5 to $25 million (USD)
Senior Data Architect (Remote),$150K - $200K (Employer est.),KBX3.8 ★,"Wichita, KS","Your Job
KBX Technology Solutions, LLC, a provider of transportation technology to industry leaders, is seeking a highly skilled Data Architect to join our dynamic team. You will be responsible for designing and implementing scalable, secure, and efficient data architectures that leverage cloud-native technologies and principles. You will play a critical role in defining data strategies, ensuring data integrity, and enabling advanced analytics and insights in our cloud-native environment.
Our Team
This role will be part of our Platform Architecture team. The Platform is the core foundation that all of products are built. Software, Cloud, and Data architects are part of one team that develop the strategy and guidelines for all of core capabilities and products.
What You Will Do

Design and Develop Data Architecture: Collaborate with cross-functional teams to design and develop scalable and robust data architectures that align with cloud-native principles. Evaluate and select appropriate technologies, tools, and frameworks to support data storage, processing, integration, and analytics.
Cloud-Native Data Solutions: Architect, implement, and optimize data solutions leveraging cloud-native technologies such as Kubernetes, Kafka, microservices, containers, and managed data services. Ensure that data solutions are highly available, scalable, and cost-effective in a cloud environment.
Data Modeling and Governance: Define and enforce data modeling and governance best practices. Develop data models, data dictionaries, data catalog, and data integration patterns to ensure consistency, standardization, and quality of data across the organization. Establish data governance frameworks, policies, and procedures to promote data integrity and security.
Data Integration and ETL: Design and oversee implementation of data integration processes, including Extract, Transform, Load (ETL) workflows, APIs, data pipelines, and data streaming. Collaborate with data engineers and developers to ensure seamless and efficient data integration between various systems and applications.
Contribute & Share Knowledge: Participate in various transformation initiatives across KBX requiring data-centric architecture and enablement guidance and contribute to the data management & enablement community within Koch companies to drive strategy development, modeling, and knowledge systems for leveraging data.

Who You Are (Basic Qualifications)
Experience translating business strategy into value creation through data by creating roadmaps and the data strategy while collaborating and implementing with cross functional teams.
Experience in integration of complex, cross-corporate processes, and information strategies, and/or designing strategic metrics and scorecards.
Experience in Information Technology systems and ability to understand how data interacts with the enterprise digital foundation.
Experience in data lake and data warehouse technologies
Strong knowledge of cloud platforms such as AWS, Azure, or Google Cloud Platform (GCP).
Proficiency in data modeling, data integration, and data governance concepts and best practices.
Proficiency in SQL and NoSQL databases

What Will Put You Ahead
Experience in machine learning model development, training, and lifecycle management
Familiarity with data integration tools and ETL processes.
Experience with cloud-native data technologies, such as Kubernetes, Kafka, microservices, containers, and managed data services.
Solid understanding of data security, privacy, and compliance requirements.
Strong analytical and critical thinking skills.
Excellent communication and collaboration abilities.
Experience working within large organizations, and the ability to develop strong relationships required.
Experience with business intelligence and data analytics
For this role, we anticipate paying $150,000 - $200,000 per year. This role is eligible for variable pay, issued as a monetary bonus or in another form.
At Koch companies, we are entrepreneurs. This means we openly challenge the status quo, find new ways to create value and get rewarded for our individual contributions. Any compensation range provided for a role is an estimate determined by available market data. The actual amount may be higher or lower than the range provided considering each candidate's knowledge, skills, abilities, and geographic location. If you have questions, please speak to your recruiter about the flexibility and detail of our compensation philosophy.
Hiring Philosophy
All Koch companies value diversity of thought, perspectives, aptitudes, experiences, and backgrounds. We are Military Ready and Second Chance employers. Learn more about our hiring philosophy here.
Who We Are
As a Koch company, KBX provides the global transportation, logistics and technology solutions that help our customers deliver life's essentials to people all over the world. We develop and deploy cutting-edge technologies to deliver better solutions for increasingly complex supply chains. Our team of tenacious problem-solvers are driven to create real, long-term value for our customers.
At Koch, employees are empowered to do what they do best to make life better. Learn how our business philosophy helps employees unleash their potential while creating value for themselves and the company.
Our Benefits
Our goal is for each employee, and their families, to live fulfilling and healthy lives. We provide essential resources and support to build and maintain physical, financial, and emotional strength focusing on overall wellbeing so you can focus on what matters most. Our benefits plan includes medical, dental, vision, flexible spending and health savings accounts, life insurance, ADD, disability, retirement, paid vacation/time off, educational assistance, and may also include infertility assistance, paid parental leave and adoption assistance. Specific eligibility criteria is set by the applicable Summary Plan Description, policy or guideline and benefits may vary by geographic region. If you have questions on what benefits apply to you, please speak to your recruiter.
Equal Opportunities
Equal Opportunity Employer, including disability and protected veteran status. Except where prohibited by state law, all offers of employment are conditioned upon successfully passing a drug test. This employer uses E-Verify. Please visit the following website for additional information: http://www.kochcareers.com/doc/Everify.pdf
To apply to this job, click Apply Now
Show Less
Report",3.8,10000+ Employees,1940,Company - Private,Energy & Utilities,"Energy, Mining & Utilities",$10+ billion (USD)
Sr Data Engineer,$112K - $152K (Glassdoor est.),Voloridge Investment Management4.7 ★,"Jupiter, FL","At Voloridge Investment Management our quantitative systems are deeply dependent on vast quantities of data. The Senior Data Engineer must understand the many different and evolving use cases for data at Voloridge and design systems that supply high-performance datasets for advanced analytics. In this role the Sr. Data Engineer / Architect will provide mentorship and impart experience to the data engineering team.
Summary of Job Functions
Collaborate effectively with Stakeholders, Project Managers, Software Engineers, Data Analysts, QA Analysts, DBAs, and Data Engineers
Build and maintain data pipelines based on functional and non-functional requirements
Proactively seek out information and overcome obstacles to deliver projects efficiently
Ensure that data pipelines incorporate best practices related to performance, scaling, extensibility, fault tolerance, instrumentation, and maintainability
Ensure that data pipelines are kept simple and not overly engineered
Produce and maintain design and operational documentation
Analyze complex data problems and engineer elegant solutions
Stay abreast of emerging technologies and make relevant recommendations
Upgrade existing data models and pipelines leveraging newer features and techniques
Work in a Kanban environment
Mentor less experienced data engineers
Participate in engineering standards and best practices evolution
Participate in an on-call rotation
Lead investigations to troubleshoot pipeline issues
Minimum Requirements
10+ years with hands-on data engineering and deep knowledge of data architecture fundamentals including:
Extensive experience building ETL/ELT pipelines from a variety of data sources
Broad experience with SQL Server 2019+, including advanced SQL Server features such as Table Partitioning, Columnstore
Deep knowledge and measurable experience in performance tuning TSQL, execution plan analysis blocking/deadlock analysis and index optimization
Extensive experience using SSMS to create and maintain SQL Server tables, views, functions, stored procedures, and user-defined table types
Comprehensive experience with data modeling indexes, Temporal tables, CLR, and Service Broker
Deep understanding of the development of data pipelines with either SSIS or Python and building data pipelines using multiple external data sources and transport mechanisms
Strong initiative, collaboration, accountability, impartiality, and communication
Strong analytical skills, a real passion for working with data and strong interest in solving data problems
Strong track record for judging core requirements and meeting deadlines
Experience managing master data
Experience writing C#, PowerShell, and Python
Experience with Git source control integration with SSMS
Experience working in a Kanban SDLC and a strong understanding of traditional Kanban SDLC workflows
Experience with deploying changes through segregated Development, QA, UAT and Production SDLC stages
Experience owning mission-critical processes
Bachelor’s degree in Computer Science, Information Systems, or related disciplines
Ability to work onsite in our Jupiter, FL office
Preferred Skills and Previous Experience
Python programming using libraries such as Pandas, Numpy, csv, Traceback, JSON, PyODBC, Math
Experience with source code branching and pull requests / code reviews
Experience with AWS
Experience working with trading / financial / investment / accounting data
Experience with tools such as Red Gate, Grafana, OpsGenie and JAMS
Experience with MPP databases such as Greenplum
MS/PhD in Computer Science, Information Systems, or related disciplines
Compensation and Benefits
Highly competitive base salary
Profit sharing bonus
Health, dental, vision, life, and disability insurance
401K
Additional Information
Voloridge Investment Management is an SEC registered investment advisor. A private investment company founded in 2009, our mission is to deliver superior risk-adjusted returns for qualified investors, using advanced proprietary modeling technology, conservative investment tactics and sophisticated risk management.
Voloridge Investment Management is an Equal Opportunity Employer. All qualified applicants are encouraged to apply and will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, protected veteran status, or any other legally protected characteristic or status.
Show Less
Report",4.7,51 to 200 Employees,2009,Company - Private,Investment & Asset Management,Financial Services,Unknown / Non-Applicable
Senior Principal Big Data Architect,$220K - $352K (Employer est.),Zillow3.9 ★,Remote,"About the team
Are you looking for an opportunity to help millions of customers navigate one of the biggest life decisions they'll ever make? Zillow's mission is to give people the power to unlock life's next chapter. We work with Designers, Engineers, Data Scientists, and Researchers to solve complex engineering problems and build products that transform the real estate industry. Our Product Teams are tasked with finding solutions to bridge the gap between you and your next address by delivering end-to-end experiences for customers actively shopping, renting, touring, or financing their home. Our Teams are also working to solve difficult problems for real estate agents in the field by providing industry leading platforms and tooling.

We maintain our competitive edge by making data driven decisions that we evolve through rapid testing and iteration to ensure we are launching enjoyable experiences to the world’s largest online real estate marketplace. We are not done yet. Our goal is to achieve Zillow 2.0, which will deliver seamlessly comprehensive solutions for buyers, sellers, and agents transacting with all the services Zillow provides. And, we need your help to do it!
About the role
As a Senior Principal Data Architect you will lead data architecture practice and represent Data Engineering at the enterprise level. The Data Engineering (DE) team is building the new generation of a Data Platform to enable implementation of Data Mesh principles and drastically improve time to value for all engineers who work with data. This work requires proven expertise in big data combined with a never ending ability to learn and evolve your thinking.

You will facilitate cross-team collaboration for defining and building enterprise data management architecture from principals to tools, oversee cross-functional adoption of new architecture, and enable a new level of engineering efficiency when working with data.

You will get to:
Defining enterprise data architecture for data platform
Working with Platform team on building platform functionality and with data engineers on adoption of platform functionality
Influencing and educating whole team on topics of modern data architecture
Shape data lakehouse data models and bring it to performant physical models specifically tailored to chosen storage format and data tech stack
Advance best DE architecture practices with focus on performance, scalability, security, enabling future capabilities and resilience. Drive and communicate architecture decisions across the Zillow Data Ecosystem.
Create cohesive architecture practices across DE producing standard methodologies and reference architecture that the team can leverage.
Create consensus and alignment on technology choices, data formats and data flows and provide guidance to teams on new technologies and future technical investments.
Create alignment with product teams on technical vision and long term product vision.
Represent the DE architecture in the Enterprise Architecture Group
This role has been categorized as a Remote position. “Remote” employees do not have a permanent corporate office workplace and, instead, work from a physical location of their choice which must be identified to the Company. Employees may live in any of the 50 US States, with limited exceptions. In certain cases, an employee in a remote-designated job may need to live in a specific region or time zone to support customers or clients as part of their role.
In California, Colorado, Connecticut, Nevada, New York City and Washington the standard base pay range for this role is $220,200.00 - $351,800.00 Annually. This base pay range is specific to California, Colorado, Connecticut, Nevada, New York City and Washington and may not be applicable to other locations.
In addition to a competitive base salary this position is also eligible for equity awards based on factors such as experience, performance and location. Actual amounts will vary depending on experience, performance and location.
Who you are
You have built data platforms and solutions, accumulated enough experience to know how to solve non-trivial challenges for a non-trivial business and how to shape enterprise data systems into a cohesive enterprise data management platform.
You can demonstrate successful projects related to data systems at medium and large size companies in leading architecture roles
Experience mentoring engineers and oversee project execution and delivery for adhering to blueprints and architecture principles.
You are designing enterprise systems and processes that span org structures and levels, inspire with your strong and robust vision and technical leadership
Previous experience leading technical organizations through change in leading data management practices to next level and enabling business to get data-rooted results
You are a master of concepts, but you think in code. There is a wide array of proven tools in your toolbox - Spark, advanced Python, unlimited SQL, deep knowledge of data streaming, intimate understanding of data structures. You are native to cloud thinker, ready to demonstrate your ideas with prototypes and partner with data engineers on complex implementations, helping guide work and showcase architecture principles
Ability to explain advanced concepts in simple to understand manner
Strong partnership with Zillow Enterprise Architecture (ZGEA) group advocating for data management
Able to balance multiple contending priorities in a fast-paced environment

Get to know us
Zillow is reimagining real estate to make home a reality for more and more people.
As the most-visited real estate website in the United States, Zillow® and its affiliates help movers find and win their home through digital solutions, first class partners, and easier buying, selling, financing and renting experiences. Millions of people visit Zillow Group sites every month to start their home search, and now they can rely on Zillow to help make it easier to move. The work we do helps people get home and no matter what job you're in, you will play a critical role in making home a reality for more and more people.
Our efforts to streamline the real estate transaction are supported by a deep-rooted culture of innovation, our passion to redefine the employee experience, a fundamental commitment to Equity and Belonging, and world-class benefits. These benefits include comprehensive medical, dental, vision, life, and disability coverages as well as parental leave, family benefits, retirement contributions, and paid time off. We’re also setting the standard for work experiences of the future, where our employees are supported in doing their best work and living a flexible, well-balanced life. But don’t just take our word for it. Read recent reviews on Glassdoor and recent recognition from multiple organizations, including: the 100 Best Companies to Work For, Glassdoor Employees’ Choice Award, Bloomberg Gender-Equality Index, Human Rights Campaign (HRC) Corporate Equity Index, and TIME 100 Most Influential Companies list.
Zillow Group is an equal opportunity employer committed to fostering an inclusive, innovative environment with the best employees. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. If you have a disability or special need that requires accommodation, please contact us at RecruitingAccessibility@zillowgroup.com.
Applicants who receive job offers from Zillow Group will be asked to sign a Proprietary Rights Agreement which includes confidentiality, intellectual property assignment, customer and employee non-solicitation, and non-competition provisions. If you are contacted for a role at Zillow Group and wish to review a copy of the Proprietary Rights Agreement prior to receiving an offer, you may request a copy from your Recruiter.
Start your job application: click Apply Now
Show Less
Report",3.9,5001 to 10000 Employees,2005,Company - Public,Internet & Web Services,Information Technology,$1 to $5 billion (USD)
Senior-Software Engineer,$117K - $231K (Employer est.),AT&T3.7 ★,"Middletown, NJ","Join AT&T and reimagine the communications and technologies that connect the world. We’re committed to those who seek to discover the undiscoverable and dare to disrupt the norm. Bring your bold ideas and fearless risk-taking to redefine connectivity and transform how the world shares stories and experiences that matter. When you step into a career with AT&T, you won’t just imagine the future – you’ll create it.

As a Senior Software Engineer, you’ll be responsible for the overall delivery process of a software application or service, including design, development, testing, deployment, production application support (e.g., troubleshooting) and maintenance with a focus on automation.

Key Responsibilities:
Collaborate to gather and review software requirements and user stories, provide estimates, create software design specifications, and collaborate with engineers and architects to assess and test hardware and software interactions.
Execute a specific development methodology through application of various programming languages.
Create and execute automated test plans and strategies utilizing business requirements and collaborate with engineers and architects, clients, etc. to validate test environments, test data and test results, design and implement code fixes, validate outcomes against expected results and produce associated reporting.
In addition to Unit Test, responsibilities may include dynamic application security testing, interface testing, integration testing, end-to-end testing and/or user acceptance testing.
Supports applications and solves configuration and environment issues.

Our Senior Software Engineers earn between $116,600 – $231,100 annually. Not to mention all the other amazing rewards that working at AT&T offers. Individual starting salary within this range may depend on geography, experience, expertise, and education/training.

Joining our team comes with amazing perks and benefits:
Medical/Dental/Vision coverage
401(k) plan
Tuition reimbursement program
Paid Time Off and Holidays (based on date of hire, at least 23 days of vacation each year and 9 company-designated holidays)
Paid Parental Leave
Paid Caregiver Leave
Additional sick leave beyond what state and local law require may be available but is unprotected
Adoption Reimbursement
Disability Benefits (short term and long term)
Life and Accidental Death Insurance
Supplemental benefit programs: critical illness/accident hospital indemnity/group legal
Employee Assistance Programs (EAP)
Extensive employee wellness programs
Employee discounts up to 50% off on eligible AT&T mobility plans and accessories, AT&T internet (and fiber where available) and AT&T phone

A career with us, a global leader in communications and technology, comes with big rewards. As part of our team, you’ll lead transformation surrounded by trailblazing industry leaders like you. You’ll be empowered to go above and beyond – making a difference through company-sponsored initiatives or connecting and networking through one of our many employee groups. And regardless of where you’re at in your career trajectory, you’ll be rewarded by the impact that comes with making a difference in the lives of millions. With AT&T, you’ll be a part of something greater, do incredible things and be rewarded with a chance to change the world!

Required Qualifications
5 - 8 years’ experience
Experience with ATCS conferencing services, Java Development, Azure
Experience on ATCS Conference platform applications, dealing with Call Flows, Customer Provisioning and related Billing
Front-end and backend conferencing platform applications on Azure, as well as on-prem infrastructure
Experience helping to solve configuration and environment issues in non-production as well as production

Desired Qualifications
Bachelor of Science degree in Computer Engineering, Computer Science, Applied Science, Electrical Engineering, or Math, Developer nanodegree
Experience working in a scaled agile development environment
To apply to this job, click Apply Now
Show Less
Report",3.7,10000+ Employees,1876,Company - Public,Telecommunications Services,Telecommunications,$10+ billion (USD)
ETL & Data Warehouse Manager / Architect (Remote),$94K - $128K (Glassdoor est.),Crum & Forster4.0 ★,"Morristown, NJ","Crum & Forster Company Overview:
Crum & Forster (C&F) Crum & Forster (C&F), with a proud history dating to 1822, provides specialty and standard commercial lines insurance products through our admitted and surplus lines insurance companies. C&F enjoys a financial strength rating of ""A"" (Excellent) by AM Best and is proud of our superior customer service platform. Our claims and risk engineering services are recognized as among the best in the industry.
Our most valuable asset is our people: more than 2000 employees in locations throughout the United States. The company is increasingly winning recognition as a great place to work, earning several workplace and wellness awards, including the October 2022 Great Place to Work® Award for our employee-first focus and our steadfast commitment to diversity, equity and Inclusion.
C&F is part of Fairfax Financial Holdings, a global, billion dollar organization. For more information about Crum & Forster, please visit our website: www.cfins.com.
Job Description:

C&F is looking for a passionate ETL & Data Warehouse Manager / Architect for our Snowflake implementation initiative, with significant experience in ETL solutions using SQL Server Integration Services and Snowflake. In this role, you will be responsible for designing and managing the development of robust ETL solutions for loading & extracting data from various source and target systems from our Snowflake Data warehouse. You will also be responsible for maintaining the Snowflake Data Warehouse schema design.
What you will do:

Collaborate with stakeholders and various IT groups to implement an overall data strategy that is in line with business objectives
Help the organization to bring our “one trusted data source” vision to life through a formal enterprise data lake house
Design build and maintain data models, data warehouses, data lakes, data marts and reporting/analytics solutions
Develop and maintain data integration and data transformation best practices and standards
Keep up-to-date with industry trends and advancements in ETL technologies and tools
Manage a team of ETL developers, providing guidance, support, and training as needed. This team will:
Identify and proactively resolve issues that could impact system performance, reliability, and usability
Develop and maintain ETL documentation, including technical specifications, data mappings, and data lineage
Perform data profiling and data quality analysis to ensure that ETL processes are accurate and reliable
Troubleshoot and resolve ETL issues and errors
What you will bring to C&F:

8+ years of experience in ETL development and data integration solutions using SSIS or any other ETL tool
8+ years of database development experience using Microsoft SQL Server, Oracle, and any other RDBMS
Strong knowledge of SQL/T-SQL/PL-SQL, Query Optimization, and Data management skills
Experience in Data warehouse development; Logical and Physical Database design & development
Experience with Snowflake data warehouse would be a big plus
Experience with BI tools such as SSRS/SSAS would be a plus
Experience with any cloud data warehouse would be plus
Knowledge of code versioning tools such as Git or stash would be a plus
Experience working in an agile environment would be a plus
Work experience related to the Insurance vertical would be a plus
Excellent critical thinking, analytical and problem-solving skills
Ability to think outside of the box and propose innovative solutions
Excellent written and oral communication skills
#LI-MS

# LI-REMOTE
What C&F will bring to you:
Competitive compensation package
Generous 401K employer match
Employee Stock Purchase plan with employer matching
Generous Paid Time Off
Excellent benefits that go beyond health, dental & vision. Our programs are focused on your whole family’s wellness, including your physical, mental and financial wellbeing
A core C&F tenet is owning your career development, so we provide a wealth of ways for you to keep learning, including tuition reimbursement, industry-related certifications and professional training to keep you progressing on your chosen path
A dynamic, ambitious, fun and exciting work environment
We believe you do well by doing good and want to encourage a spirit of social and community responsibility, matching donation program, volunteer opportunities, and an employee-driven corporate giving program that lets you participate and support your community

At C&F you will BELONG

If you require special accommodations, please let us know.We value inclusivity and diversity. We are committed to equal employment opportunity and welcome everyone regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity, or Veteran status. If you require special accommodations, please let us know
Apply Now: click Apply Now
Show Less
Report",4.0,1001 to 5000 Employees,1822,Subsidiary or Business Segment,Insurance Carriers,Insurance,Unknown / Non-Applicable
Data Warehouse Programmer,$75K - $160K (Employer est.),Bethesda Game Studios3.4 ★,"Rockville, MD","Overview
Join Constellation!
Come join Bethesda Game Studios, the award-winning development team behind Starfield, The Elder Scrolls and Fallout. Bethesda Game Studios strives to offer its employees a well-balanced home and work life by providing competitive salaries, a generous benefits program, and offices located in some of North America’s best cities.
With a goal of creating a culture as fun and diverse as our games and our players, we welcome applicants with unique skillsets, experience levels and backgrounds. If you are passionate about making a meaningful contribution to some of the most significant games in the industry we’d love to hear from you!
Responsibilities
Your Daily Life at Bethesda Game Studios
As Data Warehouse Programmer, you will...
Work with other data programmers and game analysts to build new and extend existing data structures to support game analytics
Develop, maintain, and support ETL processes for loading data from multiple data sources into a Redshift data warehouse
Maintain and develop all physical data models for EDW.
Maintain large, multi-terabyte data warehouse which includes performance tuning and data retention/purge processes
Research and troubleshoot data quality issues, providing fixes and proposing both short- and long-term solutions
Prepare designs for database systems and recommend improvements for performance.
Maintain and develop various database scripts and tools to facilitate automation process
Provide support to all data warehouse initiatives.
Evaluate all proposals requests and assist to improve structure of data warehouse
Qualifications
What Makes you S.P.E.C.I.A.L.
You have 3+ years of experience in a data warehousing, data engineering, or data architect role
You have strong experience with AWS Redshift or similar databases
You have experience working with other AWS data technologies such as S3, Redshift Spectrum, Athena, Data Pipeline, Glue, EMR, RDS, and Kinesis
You have excellent SQL skills
You have data modeling experience for both transactional and data warehousing environments including familiarity with Kimball dimensional and 3NF modeling standards
You have strong interpersonal skills and problem-solving ability
Salary Range
Data Warehouse Programmer - The typical base pay range for this position at the start of employment is expected to be between $75,000 - $160,000 per year.

ZeniMax has different base pay ranges for different work locations within the United States, which allows us to pay employees competitively and consistently in different geographic markets. The range above reflects the potential base pay across the U.S. for this role; the applicable base pay range will depend on what ultimately is determined to be the candidate’s primary work location. Individual base pay depends on various factors, in addition to primary work location, such as complexity and responsibility of role, job duties/requirements, and relevant experience and skills. Base pay ranges are reviewed and typically updated each year. Offers are made within the base pay range applicable at the time.
At ZeniMax certain roles are eligible for additional rewards, such as merit increases and discretionary bonuses. These awards are allocated based on individual performance and are not guaranteed. Benefits/perks listed here may vary depending on the nature of employment with ZeniMax and the country work location. U.S.-based employees have access to healthcare benefits, a 401(k) plan and company match, short-term and long-term disability coverage, basic life insurance, wellbeing benefits, paid vacation time, paid sick and mental health time, and several paid holidays, among others.
We embrace diversity, equity, and inclusion in everything we do – from recruiting for our studios, publishing and operations to fostering safe and respectful workplaces that encourage collaboration. Our culture is based on principles of respect, inclusion, and fair treatment and we welcome anyone into our family without regard to race, religion, gender identity, sexual orientation, or age.
Our diversity fuels our innovation and inspires us to create game worlds that bring us closer to the global community of players we serve.
Show Less
Report",3.4,51 to 200 Employees,-1,Subsidiary or Business Segment,Video Game Publishing,Media & Communication,$5 to $25 million (USD)
GCP Data Modeler/ Architect,$70.00 Per Hour (Employer est.),Infinity Quest4.0 ★,"Dublin, OH","Qualifications & Experience
Required
· Must have designed, developed, and supported a complex software solution.
· Proficient in SQL.
· Good Understanding in dimensional/multidimensional data modeling.
· Experience with graph, transactional, and operational data modeling is a plus.
· Familiarity with all stages of the product development cycle. Experience maintaining engineering best practices, including defect tracking, design reviews, and appropriate testing.
· Hold strong organizational and problem-solving skills.
· Take a pragmatic, product-oriented approach.
· Possess the ability to work cross-functionally with minimal supervision.
Preferred
· B.S. in Computer Science, Electrical Engineering, Mathematics, Statistics, Physics, or similar quantitative fields/work experience.
· Experience with cloud environments
· 7+ years of experience in data modeling.
· 3-7+ years of experience in at least one scripting language (Python, Perl, JavaScript, Shell)
· 2+ years of experience working on streaming data applications
· 3+ years of experience with Agile engineering practices
· 3+ years of experience developing Java-based software solutions, scripting and OOP languages
· 3+ years of experience with UNIX/Linux, including basic commands and shell scripting
· 2+ years of experience with GCP
· 1+ years in the healthcare industry and knowledge of their business practices.
Job Type: Contract
Salary: From $70.00 per hour
Schedule:
8 hour shift
Experience:
Data modeling: 1 year (Required)
Python: 1 year (Required)
DVT: 1 year (Required)
Data Validation Tool: 1 year (Required)
Terraform: 1 year (Required)
BigQuery: 1 year (Required)
Work Location: On the road
Show Less
Report",4.0,201 to 500 Employees,2006,Company - Private,Information Technology Support Services,Information Technology,Unknown / Non-Applicable
IT Software Engineer - Remote,$91K - $134K (Employer est.),Mayo Clinic3.9 ★,"Rochester, MN","Why Mayo Clinic

Mayo Clinic has been ranked the #1 hospital in the nation by U.S. News & World Report, as well as #1 in more specialties than any other care provider. As we work together to put the needs of the patient first, we are also dedicated to our employees, investing in competitive compensation and comprehensive benefit plans – to take care of you and your family, now and in the future. And with continuing education and advancement opportunities at every turn, you can build a long, successful career with Mayo Clinic. You’ll thrive in an environment that supports innovation, is committed to ending racism and supporting diversity, equity and inclusion, and provides the resources you need to succeed.


Responsibilities
Mayo Clinic is seeking a Software Engineer to design and build back-end services that support our portfolio of data-centric clinical and analytic applications. These applications leverage cloud computing, big data, mobile, data science, data warehousing, machine learning using state of the art software development applications and frameworks. Our Software Engineers ensures that these cloud-based micro-services adhere to uptime and accuracy targets, are resilient, and scale as data volumes and traffic increase. They work closely with the data engineering, platform, and solutions teams to develop applications as required to benefit our practice and patients.
Works closely with the Product Owners, Product Managers, Architects to translate requirements into code. Developing services around data warehousing, big data, cloud computing, business intelligence, analytics and machine learning. Participate in DevOps, Agile, continuous development and integration frameworks. Programming in high-level languages such as Go, Python, Java etc. Work on deployment automation/configuration management with tools including but not limited to ADO, Puppet, Chef or Ansible or Azure Pipelines, CloudFormation, Terraform following a DevOps model. Ensure all appropriate documentation of processes and source code is created and maintained. Communicate effectively with peers, leaders, and customers throughout the organization. Participate in expert level troubleshooting and resolve problems through root cause analysis, data and system investigation. Continues to build knowledge of the organization, processes and customers. Performs a range of mainly straightforward assignments. Uses prescribed guidelines or policies to analyze and resolve problems. Receives a moderate level of guidance and direction.

Qualifications
Bachelor's Degree in Computer Science/Engineering or related field; Or an Associates’ degree in Computer Science/Engineering or related field with an additional 2 years of experience as described below.
Have working knowledge and experience of Software Engineering with a minimum of internships and a minimum of 1 yr. of experience, or 2yrs of experience coding applications or services in a high-level language (C, C++, Golang, Java, C# etc.).
Demonstrated problem solving and time management skills.
Possesses strong technical aptitude for designing and implementing software solutions.
Experience with modern application development frameworks
Knowledge of professional software engineering practices & best practices for the full software development life cycle, including coding standards, code reviews, source control management, build processes, testing, and operations.
Deep hands-on technical expertise, excellent verbal and written communication skills.
Experience with Agile software development techniques.
Preferred qualifications:
Ability to use a wide variety of open-source technologies and cloud-based services.
Experience with Google and Azure cloud environments
Experience in databases, analytics, big data systems or business intelligence products
Experience with building high-performance, highly available and scalable distributed systems.
Experience developing software for healthcare related industries.
Authorization to work and remain in the United States, without necessity for Mayo Clinic sponsorship now, or in the future (for example, be a U.S. Citizen, national, or permanent resident, refugee, or asylee). Also, Mayo Clinic does not participate in the F-1 STEM OPT extension program.

Exemption Status

Exempt

Compensation Detail

$90,937.60 - $133,681.60 / year

Benefits Eligible

Yes

Schedule

Full Time

Hours/Pay Period

80

Schedule Details

Monday - Friday

Weekend Schedule

N/A

International Assignment

No

Site Description
Just as our reputation has spread beyond our Minnesota roots, so have our locations. Today, our employees are located at our three major campuses in Phoenix/Scottsdale, Arizona, Jacksonville, Florida, Rochester, Minnesota, and at Mayo Clinic Health System campuses throughout Midwestern communities, and at our international locations. Each Mayo Clinic location is a special place where our employees thrive in both their work and personal lives. Learn more about what each unique Mayo Clinic campus has to offer, and where your best fit is.

Affirmative Action and Equal Opportunity Employer

As an Affirmative Action and Equal Opportunity Employer Mayo Clinic is committed to creating an inclusive environment that values the diversity of its employees and does not discriminate against any employee or candidate. Women, minorities, veterans, people from the LGBTQ communities and people with disabilities are strongly encouraged to apply to join our teams. Reasonable accommodations to access job openings or to apply for a job are available.


Recruiter

Miranda Grabner

Department Title

Information Technology
Show Less
Report",3.9,10000+ Employees,-1,Nonprofit Organization,Health Care Services & Hospitals,Healthcare,$10+ billion (USD)
Azure Data Architect,$150K - $180K (Employer est.),Hitachi Vantara Corporation3.3 ★,Remote,"Position Overview:
We are looking for a highly skilled Azure Data Architect to join our team. As an Azure Data Architect, you will be responsible for designing and implementing scalable and efficient data architecture solutions on the Azure cloud platform. Your primary focus will be on creating robust data models, optimizing data storage and retrieval, and ensuring the overall integrity and security of data. You will collaborate with cross-functional teams to understand business requirements and translate them into effective data architecture solutions that support data-driven decision-making.

Responsibilities:
Design and implement end-to-end data architecture solutions on the Azure cloud platform.
Collaborate with business stakeholders, data engineers, and data scientists to understand data requirements and design scalable and flexible data models.
Develop data ingestion strategies and frameworks to efficiently capture and integrate data from various sources into Azure data services.
Define data storage and retrieval mechanisms, including data partitioning, indexing, and compression, to optimize performance and cost efficiency.
Implement data governance and data management practices to ensure data quality, consistency, and compliance with relevant regulations.
Create and maintain data pipelines and ETL/ELT processes to transform, cleanse, and integrate data across different data sources.
Collaborate with security and compliance teams to establish and enforce data security measures, including data encryption, access controls, and data masking.
Perform data profiling, analysis, and troubleshooting to identify and resolve data-related issues.
Stay up to date with the latest advancements in Azure data services and recommend innovative solutions to enhance data architecture capabilities.
Provide technical guidance and mentorship to junior team members and promote best practices in data architecture design and implementation.

Qualifications:
Bachelor's or Master's degree in Computer Science, Engineering, or a related field.
Extensive experience designing and implementing data architecture solutions on the Azure cloud platform.
Strong proficiency in Azure data services such as Azure SQL Database, Azure Synapse Analytics, Azure Data Lake Storage, Azure Databricks, and Azure Cosmos DB.
Deep understanding of data modeling principles and experience with relational, dimensional, and NoSQL data modeling techniques.
Solid knowledge of ETL/ELT processes, data integration patterns, and data warehouse concepts.
Familiarity with big data processing frameworks like Apache Spark or Hadoop.
Proficiency in SQL and programming languages such as Python or Scala.
Experience with data governance, data security, and compliance practices in Azure.
Strong problem-solving and analytical skills with the ability to troubleshoot and resolve complex data-related issues.
Excellent communication and collaboration skills to work effectively with stakeholders at all levels.
Ability to manage multiple projects and priorities in a fast-paced and dynamic environment.

Preferred Qualifications:
Relevant certifications in Azure or data architecture.
Experience with streaming data processing using technologies like Apache Kafka or Azure Event Hubs.
Knowledge of machine learning and AI technologies and their integration with data architecture.
Understanding of data visualization and reporting tools.
Familiarity with DevOps practices and CI/CD pipelines in the context of data architecture.
As required by the equal pay and transparency acts, the expected base salary for this position is $150k-$180k + Bonus+ Benefits
The expected pay is determined based on a variety of factors including, but not limited to, depth of experience in the practice area. Employees are eligible to participate in Hitachi Vantara's bonus/variable/commission pay programs, where applicable, and are subject to the program's conditions and restrictions.
Our Company
Hitachi Vantara is part of the Global Hitachi family. We balance innovation with an open, friendly culture and the backing of a long-established parent company, known for its ethical reputation. We guide customers from what's now to what's next by unlocking the value of their data and applications to solve their digital challenges, achieving outcomes that benefit both business and society.
Our people are our biggest asset, they drive our innovation advantage and we strive to offer a flexible and collaborative workplace where they can thrive. Diversity of thought is welcomed and our employee base is represented by several active Employee Resource Group communities. We offer industry leading benefits packages (flexible working, generous pension and private healthcare) and promote a creative and inclusive culture. If driving real change gives you a sense of pride and you are passionate about powering social good, we'd love to hear from you.
Our Values
We strive to create an inclusive environment for all and are open to considering home working, compressed/flexible hours and flexible arrangements. Get in touch with us to explore how we might be able to accommodate your specific needs.
We are proud to say we are an equal opportunity employer and welcome all applicants for employment without attention to race, colour, religion, sex, sexual orientation, gender identity, national origin, veteran or disability status. With Japanese roots going back over 100 years, our culture is founded on the values of our parent company expressed as the Hitachi Spirit:
Wa – Harmony, Trust, Respect
Makoto – Sincerity, Fairness, Honesty, Integrity
Kaitakusha-Seishin – Pioneering Spirit, Challenge
#LI-MS2
Start your job application: click Apply Now
Show Less
Report",3.3,10000+ Employees,1989,Subsidiary or Business Segment,Information Technology Support Services,Information Technology,Unknown / Non-Applicable
Principal Data Architect,$125K - $164K (Glassdoor est.),T. Rowe Price3.8 ★,"Owings Mills, MD","There is a place for you at T. Rowe Price to grow, contribute, learn, and make a difference. We are a premier asset manager focused on delivering global investment management excellence and retirement services that investors can rely on today and in the future. The work we do matters. We invite you to explore the opportunity to join us and grow your career with us.
A career at T. Rowe Price says you want to contribute and make a difference at a leading global investment management firm where success results from the dedication our associates have in building success for our clients. We are a growing organization of associates from diverse backgrounds, experiences, and perspectives.
We take a long-term view on associates and their careers. Our associates do phenomenal work with purpose, and as a result, we provide growth opportunities through in-person and online training, management development programs, and career development on the job.
If you are seeking a meaningful work experience along with a workplace culture that thrives on teamwork, we invite you to explore the opportunity to join us.
The Team
The Data Architecture team is one of the six verticals within the newly established Chief Data Office (CDO), part of T. Rowe Price’s Chief Operating Office (COO). The team is responsible for designing and governing the firm’s data architecture framework, principles, and standards working closely with partners in Data Governance, Solution Architecture, and the business to ensure strategic alignment and appropriate risk management.
The Role
T. Rowe Price is seeking a Principal Data Architect who can accelerate the development and execution of the data architecture strategy. As part of the Chief Data Office, the Principal Data Architect has opportunities to collaborate with leaders in the Chief Data Office in enhancing the firm’s data strategy and implement ground-breaking capabilities and transformative customer experiences.
Impact
In this role, you will be responsible for understanding and advocating data architecture principles and articulating value proposition of data architecture to our business and technology partners. You will also develop architectural data strategy for across domains and developing/implementing the mechanisms necessary to ensure that the strategy is realized. Ensuring decisions around data architecture are made and deviations from standards are accurately identified, addressed, and communicated will be essential as will be raising risks and issues as necessary. You will design reference architecture and develop reference implementations to enable business units to accelerate the development of their data capabilities and ensure adoption of shared data services.
Do you thrive at solving unusual problems that have a broad impact on the business or an organizational function? If so, we encourage you to apply.
Key Accountabilities
Building data architecture disciplinary strategies within the Chief Data Office to be utilized across the enterprise.
Developing and continuously improving the data principles, data standards and data practices.
Advocating the data principles and articulating value proposition of data architecture and data technologies to business and technology partners.
Developing and enhancing reference architecture and reusable implementations based on the data architecture principles and standards.
Ensuring our firm's projects engage data architecture early and often on architecturally significant projects.
Serving as an expert who advises on the best courses of action in area of data spanning across the data lifecycle.
Ensuring that Architects follow all aspects of the Enterprise Architecture standards, practices and processes from initiation to closure.
Owning a domain in data technology to craft, validate and monitor technology standards, standard methodologies, and technical biases.
Facilitating the lifecycle management and reporting of the technology products in the data technology domain and impact to data environment.
Taking product ownership of enterprise data tools and platforms and ensure delivery and adoption.
Providing mentorship to the Senior Architects in the early planning stage around the different solution patterns that may be appropriate for this specific solution.
Ensuring that standards set by Data, Security, Infrastructure, Platform and other architecture domains are followed when crafting solutions.
Representing our architecture and strategy at internal and external forums.
Staying abreast of industry trends; you are active in staying knowledgeable to help us take advantage of new technologies.
Operating as a hands-on architecture practitioner, delivers within a team as an individual architect.
Decomposing the most complex problems into discrete work units.
Balancing strategic and pragmatic concerns when solving complex or multifaceted problems.
Making sound and objective decisions with limited facts or resources.
Displaying understanding of theoretical concepts.
Identifying non-obvious relationships and anomalies often overlooked by others.
Identifying and evaluating options and selecting the most effective solution.
Holding associates and teams accountable for adhering to practices and policies.
Leading a matrix team on a specific data projects.
Experience & Qualifications
Business Knowledge
You demonstrate deep knowledge of products/flows within the businesses you support.
Your decisions show a focus on current and future business priorities, together with fiscal responsibility.
You are skilled at making decisions that are cognizant of the firm’s broader business strategy.
You articulate broader business concerns and/or regulatory landscape, including key risks and controls (e.g., GDPR, MIFID, SOX).
You set the expectations for development practices and ensures they are known and adhered to within the area.
You can articulate business needs and translate them into technology solutions.
You can engage in identifying architectural weaknesses and recommend appropriate solutions.
Requirements
A Bachelors or Masters Degree in a technology area of study; preferably in Computer Science, MIS or Analytics
Experience in Asset Management and/or financial services preferred
15+ years equivalent work experience
10+ years of experience in Data Analysis, Data Architecture and/or Data Lake/Warehousing; preferably in a shared or enterprise data environment
10+ years direct experience in Data Modeling and Data Solution Development. Excellent knowledge of metadata management, data modeling, and related tools required.
10+ years of hands-on relational, dimensional, and/or analytic experience (using RDBMS, dimensional, NoSQL data platform technologies, and ELT/ETL and data ingestion protocols).
Expertise in methodologies and practices in data management, data quality and data operation
Deep experience in logical, physical and semantic data modeling
SQL Query development skills for analyzing and profiling data
Expertise in data modeling principles/methods including conceptual, logical & physical Data Models, knowledge of modern techniques such as data vault or graph data models is a plus
You are an authority in the data architecture discipline or domain within our firm and potentially across the industry
Your designs and architectures show consideration for the operational aspects of a system, long-term supportability, maintenance, etc. Extends the half-life of software.
Demonstrates mastery of architectural processes
You innovate and leads explorations into new areas and new technologies within the company but also with other industry leaders
Capable of leading large software development projects in terms of team size, technical complexity, and/or organizational complexity
Able to produce results through individuals and teams where there is no direct management oversight of resources
Able to overcome differences of opinion and drive team alignment around a specific goal or solution
Ability to clearly communicate complex technical ideas, regardless of the technical capacity of the audience
Strong inter-personal skills and ability to work as part of a team
Ability to quickly learn and adapt modeling methods from case studies or other proven approaches
Have product management and delivery experience is a plus
FINRA Requirements
FINRA licenses are not required and will not be supported for this role.
Work Flexibility
This role is eligible for remote work up to three days a week.
-
Commitment to Diversity, Equity, and Inclusion:
We strive for equity, equality, and opportunity for all associates. When we embrace the power of diversity and create an environment where people can bring their authentic and best selves to work, our firm is stronger, and we create greater value for our clients. Our commitment and inclusive programming aim to lift the experience for each associate and builds allies for our global associate community. We know that a sense of belonging is key not only to your success at the firm, but also to your ability to bring your best each day.
Benefits: We invest in our people through a wide range of programs and benefits, including:
Competitive pay and bonuses as well as a generous retirement plan and employee stock purchase plan with matching contributions
Flexible and remote work opportunities
Health care benefits (medical, dental, vision)
Tuition assistance
Wellness programs (fitness reimbursement, Employee Assistance Program)
Our policies may change as our working lives evolve. Yet, our commitment to supporting our associates’ well-being and addressing the needs of our clients, business, and communities is unwavering.
T. Rowe Price is an equal opportunity employer and values diversity of thought, gender, and race. We believe our continued success depends upon the equal treatment of all associates and applicants for employment without discrimination on the basis of race, religion, creed, color, national origin, sex, gender, age, mental or physical disability, marital status, sexual orientation, gender identity or expression, citizenship status, military or veteran status, pregnancy, or any other classification protected by country, federal, state, or local law.
Start your job application: click Apply Now
Show Less
Report",3.8,5001 to 10000 Employees,1937,Company - Public,Investment & Asset Management,Financial Services,$1 to $5 billion (USD)
Data Architect,$90K - $100K (Employer est.),Shvender LLC,Remote,-1,3.8,-1,-1,-1,-1,-1,-1
Data Engineer,$70.00 Per Hour (Employer est.),Tellus solutions3.7 ★,"Sunnyvale, CA","Job Description:
The role will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams.
The ideal candidate is an experienced data pipeline builder and data wrangler who enjoy optimizing data systems and building them from the ground up.
The Data Engineer will support our software developers, database architects, and data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple teams, systems and products.
The right candidate will be excited by the prospect of optimizing or even re-designing our data architecture to support our next generation of products and data initiatives.
Responsibilities:
Create and maintain optimal data pipeline architecture for data intensive applications.
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using Azure SQL, Cosmo DB, Databricks and other legacy databases.
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.
Keep our data separated and secure across national boundaries through multiple data centers and Azure regions.
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
Work with data and analytics experts to strive for greater functionality in our data systems.
Qualifications for Data Engineer
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Extensive Experience on Databricks on Azure Cloud platform, deep understanding on Delta lake, Lake House Architecture.
Programming experience on Python, Shell scripting, PySpark, and other data programming language.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with Data Visualization Dashboard, Metrics and etc.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
Skills:
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Working knowledge of message queuing, stream processing, and highly scalable 'big data' data stores.
Familiar with Deployment tool like Docker and building CI/CD pipelines.
Experience supporting and working with cross-functional teams in a dynamic environment.
8+ years' experience in software development, Data engineering, and
Bachelor's degree in computer science, Statistics, Informatics, Information Systems or another quantitative field. Postgraduate/master's degree is preferred.
Experience in Machine Learning and Data Modeling is a plus.
Job Type: Contract
Salary: Up to $70.00 per hour
Benefits:
401(k)
Dental insurance
Health insurance
Schedule:
8 hour shift
Day shift
Application Question(s):
Only US Citizen and Green Card Holder
Experience:
Python, Shell scripting, PySpark: 5 years (Required)
Azure SQL: 5 years (Required)
Work Location: On the road
Show Less
Report",3.7,51 to 200 Employees,2006,Company - Private,Information Technology Support Services,Information Technology,$5 to $25 million (USD)
"Software Engineer, Data Products",$119K - $163K (Glassdoor est.),LaunchDarkly4.1 ★,"Oakland, CA","Please note, before progressing to our application, this position is based in the San Francisco Bay Area and not suitable for remote candidates.
About the Job:
We are looking for exceptional Software Engineers to make a profound impact on how data products will be integrated into companies' software in the future. We are integrating data into everything LaunchDarkly offers on top of our unrivaled feature management platform.
As a Data Products - Software Engineer, you will help us architect and write fast, reliable, and scalable data processing tools to process data from our thousands of customers and their hundreds of millions of users around the world. We're looking for someone who knows what it takes to deliver value to customers and takes pride in the quality of their work.
The primary technologies we use daily include Golang, Scala, Kinesis, and Flink. If working as a part of such a poly-functional team to bring to change how experimentation is done forever appeals to you then come join the Experimentation team at LaunchDarkly.
Responsibilities:
Build and expand our data platform and services
Help us identify the best technologies for our evolving data needs
Collaborate with product team to spec and deliver user-facing features
Monitor and improve data pipeline performance
Actively participate in code reviews
Improve engineering standards, tooling, and processes
Qualifications:
Proven experience and fluency in a JVM or functional language
Experience building data platforms (e.g. using Flink, Kafka, DataFlow, Hadoop, Spark)
Strong communication skills, a positive attitude, and empathy
You write code that can be easily understood by others, with an eye towards maintainability
You hold yourself and others to a high bar when working with production systems
You value high code quality, automated testing, and other engineering best practices
Pay:
Target pay range for a Level P3 in San Francisco/Bay Area: $144,000 - $169,000*
Restricted Stock Units (RSUs), health, vision, and dental insurance, and mental health benefits in addition to salary.
LaunchDarkly operates from a place of high trust and transparency; we are happy to state the pay range for our open roles to best align with your needs. Exact compensation may vary based on skills, experience, degree level, and location.
About LaunchDarkly:
LaunchDarkly is a Feature Management Platform that serves trillions of feature flags daily to help software teams build better software, faster. Feature flagging is an industry standard methodology of wrapping a new or risky section of code or infrastructure change with a flag. Each flag can easily be turned off independent of code deployment (aka ""dark launching""). LaunchDarkly has SDKs for all major web and mobile platforms. We are building a diverse team so that we can offer robust products and services. Our team culture is dynamic, friendly, and supportive. Our headquarters are in Oakland.
At LaunchDarkly, we believe in the power of teams. We're building a team that is humble, open, collaborative, respectful and kind. We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, gender identity, sexual orientation, age, marital status, veteran status, or disability status.
One of our company values is 'Widen the Circle'. Which means we seek out diversity of perspectives to get better results. We understand everyone has their own unique talents and experiences. We encourage you to apply to this role even if you don’t think you meet 100% of the qualifications outlined above. We can find out together if it's the right match for your skillset.
We've partnered with KeyValues to help demonstrate the amazing culture we've built here at LaunchDarkly, find more info at https://www.keyvalues.com/launchdarkly.
LaunchDarkly is also committed to giving back to our community and is a part of Pledge 1%, an organization that helps companies make this a priority. Through this initiative and its charitable arm, the LaunchDarkly Foundation, the company is committed to such causes as supporting education for the underserved, homelessness relief and moving towards having a net-zero carbon footprint. You can find more about the LaunchDarkly Foundation and the organizations we serve at https://launchdarkly.com/foundation/.
Do you need a disability accommodation?
Fill out this accommodations request form and someone from our People Operations team will contact you for assistance.
Show Less
Report",4.1,501 to 1000 Employees,2014,Company - Private,Enterprise Software & Network Solutions,Information Technology,$100 to $500 million (USD)
Data Architect (Azure),$140K - $160K (Employer est.),LTI - Larsen & Toubro Infotech3.8 ★,"Charlotte, NC","Role: Azure Data Architect.
Location: Charlotte, NC (Onsite or Hybrid Model (3 days onsite/week)
Duration: FTE.
Responsibilities:
You are an expert in Azure Data Analytics having thorough understanding of Azure Data Platform tools
Expertise and hands-on experience on Azure Platform among: Data Factory, Azure Spark
Collaborate with project stakeholders like database administrators, technical architects, , business analysts, big data admins, security experts, information modelling experts to determine project needs and plan development and implementation strategies.
To define, review, and explain Data Architecture requirements & design to all the project stakeholders
Lead the migration of data from legacy systems to newly developed solution.
To create strategies and design solutions for wide variety use cases like Data Migration (end to end ETL process), database optimization, data architectural solutions for Analytics and Big Data Projects
To design, develop and troubleshoot highly complex technical problems in OLAP/OLTP/DW, Analytics, Big Data environments and provide solutions for Enterprise level Applications utilizing Azure Data Platform
To implement data quality processes for use with MDM, BI solutions, data warehouses, EAI solutions, etc.
Work on streamlining data flows and data models consistently
Have a keen focus on improving and tuning data quality, accessibility, performance and security needs
Skills Required
Bachelor/ master’s degree in computer science engineering,
Self-driven, and able to think holistically of the product roadmap
Performing reviews of data Architecture and Designs
Research new technologies and data modelling methods
Creative in solving complex business problems
Hands-on experience in business analysis, pre-sales, solution proposals, development
Excellent written & verbal communication
Job Type: Full-time
Salary: $140,000.00 - $160,000.00 per year
Benefits:
401(k)
401(k) matching
Dental insurance
Health insurance
Paid time off
Vision insurance
Schedule:
Monday to Friday
Ability to commute/relocate:
Charlotte, NC 28202: Reliably commute or planning to relocate before starting work (Required)
Experience:
Data Architect: 10 years (Required)
Azure: 8 years (Required)
Azure data factory: 5 years (Required)
Azure DataBricks: 5 years (Required)
Data modeling: 8 years (Required)
Adobe Spark: 5 years (Required)
Data Migration: 4 years (Required)
OLAP: 6 years (Required)
Work Location: In person
Show Less
Report",3.8,10000+ Employees,1997,Company - Private,Information Technology Support Services,Information Technology,Unknown / Non-Applicable
Data Engineer,$110K (Employer est.),Capitol Federal2.9 ★,"Topeka, KS","Job Description:
Pay: up to $110,000 Annually
Job Type: Full Time
The Data Engineer assists in setting overall development roadmap and standards for the Bank and helps evaluate and architect the use of data solutions, using industry best practices. This position works as part of a collaborative team to design, code, and implement data solutions to support internal business requirements or external customers and vendors. An innovative mindset and an ability to translate complex business scenarios into a technical solution is required. This position performs a variety of tasks under general supervision. The position reports directly to an IT manager and requires regular, predictable and timely attendance at work to meet department workload demands.
Paid time off and holiday available on your first day! Benefits available to anyone working 20 hours or more per week!
CapFed® is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees.
Job Type: Full-time
Work Location: In person
Show Less
Report",2.9,501 to 1000 Employees,1893,Company - Public,Banking & Lending,Financial Services,$100 to $500 million (USD)
"Senior Solution Architect, Data & Analytics - Remote",$128K - $200K (Employer est.),EPAM Systems4.1 ★,Remote,"Are you an influential Architecture leader with a passion for leading strategic initiatives that make a huge impact? We are hiring a Senior Data Solution Architect, who will work alongside a dynamic team to identify complex business problems and create solution-oriented strategies for some of the most recognized brands. Apply now to connect with a recruiter about this influential role at EPAM!

Req.#180339287

RESPONSIBILITIES
Provide support in the solution decision making process as a trusted technical advisor
Design, implement, and deploy data platforms at scale in public and private cloud enviroments
Guide clients on establishing a data practice on an enterprise level by improving their data strategy, data governance, data architecture and data quality management
Drive and execute the technical stream of data strategy engagements by conducting customer workshops, discovery sessions solution and presentations
Educate clients on modern technologies, architectures and approaches for data & analytics by explaining their value for business
Define business and development processes as well as platform + tool usage for data acquisition, storage, transformation, and analysis
Communicate different solution and technology options, while articulating short and long-term consequences & their impact on business
Develop roadmaps and implementation strategy around data & analytics initiatives
Review and audit existing solutions, designs and system architectures while creating architecture documentation & presentations
Implement scalable data platform architecture
Discuss proposed solution to multiple level of stakeholders from C-level to engineering teams

REQUIREMENTS
Extensive experience within Solution Architecture with a strong background in data & analytics
Highly Skilled with designing, developing and maintaining enterprise scale data platforms
History working with with big data technologies and frameworks such as Databricks, Snowflake, Apache Spark, Kafka, Apache Flink, AWS Glue + Redshift, GCP Dataflow + BigQuery, Azure Data Factory + Synapse
Expert within Big Data solutions developed in large cloud computing infrastructures such as Amazon Web Services, Azure Cloud, or Google Cloud
Hands on experience with client-driven large-scale implementation projects
Background in programming and scripting languages such as Java, Python, or Scala
Strong understanding of Data Science and Analytics experience such as Machine Learning, Deep Learning, Recommendation Engines & Search Personalizations
Comfortable leading technical agile teams with common SCRUM & SDLC practices
Solid knowledge of design patterns, refactoring concepts, unit tests and CI/CD
Practical expertise in performance tuning &optimization
Solid troubleshooting & problems analysis skills
Ability to travel up to 20%

BENEFITS
Medical, Dental and Vision Insurance (Subsidized)
Health Savings Account
Flexible Spending Accounts (Healthcare, Dependent Care, Commuter)
Short-Term and Long-Term Disability (Company Provided)
Life and AD&D Insurance (Company Provided)
Employee Assistance Program
Unlimited access to LinkedIn learning solutions
Matched 401(k) Retirement Savings Plan
Paid Time Off – the employee will be eligible to accrue 15-25 paid days, depending on specific level and tenure with EPAM (accrual eligibility may change over time)
Paid Holidays - nine (9) total per year
Legal Plan and Identity Theft Protection
Accident Insurance
Employee Discounts
Pet Insurance
Employee Stock Purchase Program
If otherwise eligible, participation in the discretionary annual bonus program
If otherwise eligible and hired into a qualifying level, participation in the discretionary Long-Term Incentive (LTI) Program

ABOUT EPAM
EPAM is a leading global provider of digital platform engineering and development services. We are committed to having a positive impact on our customers, our employees, and our communities. We embrace a dynamic and inclusive culture. Here you will collaborate with multi-national teams, contribute to a myriad of innovative projects that deliver the most creative and cutting-edge solutions, and have an opportunity to continuously learn and grow. No matter where you are located, you will join a dedicated, creative, and diverse community that will help you discover your fullest potential

ADDITIONAL
This posting includes a good faith range of the salary EPAM would reasonably expect to pay the selected candidate. The range provided reflects base salary only. Individual compensation offers within the range are based on a variety of factors, including, but not limited to: geographic location, experience, credentials, education, training; the demand for the role; and overall business and labor market considerations. Most candidates are hired at a salary within the range disclosed. Salary range: $128k - $200k In addition, the details highlighted in this job posting above are a general description of all other expected benefits and compensation for the position
To apply to this job, click Apply Now
Show Less
Report",4.1,10000+ Employees,1993,Company - Public,Information Technology Support Services,Information Technology,$1 to $5 billion (USD)
Azure - Senior Data Engineering Architect,$108K - $210K (Employer est.),Publicis Sapient3.8 ★,"Arlington, TX","Azure - Senior Data Engineering Architect
Full-time
Company Description
Publicis Sapient is a digital transformation partner helping established organizations get to their future, digitally-enabled state, both in the way they work and the way they serve their customers. We help unlock value through a start-up mindset and modern methods, fusing strategy, consulting and customer experience with agile engineering and problem-solving creativity. As digital pioneers with 20,000 people and 53 offices around the globe, our experience spanning technology, data sciences, consulting and customer obsession – combined with our culture of curiosity and relentlessness – enables us to accelerate our clients’ businesses through designing the products and services their customers truly value. Publicis Sapient is the digital business transformation hub of Publicis Groupe. For more information, visit publicissapient.com.
Job Description
Publicis Sapient is looking for a hands-on Senior Manager to join our team of bright thinkers and doers. You’ll use your problem-solving creativity to design, architect, and develop high-end technology solutions that solve our clients’ most complex and challenging problems across different industries. We are on a mission to transform the world, and you will be instrumental in shaping how we do it with your ideas, thoughts, and solutions.
Your impact:
Develop, design, and implement consumer data models based on business requirements and objectives.
Collaborate with various stakeholders, such as business analysts, architects, and developers, to understand data needs and convert these needs into effective data models.
Evaluate and optimize existing data models for improvement.
Ensure that data models adhere to industry best practices, standards, and guidelines.
Conduct data profiling and analysis to identify data quality issues and propose data cleansing and remediation strategies.
Collaborate with database administrators to optimize database performance and maintain data integrity.
Work closely with ETL developers to integrate data models into data integration processes.
Stay updated on the latest trends and technologies in data modeling, cloud computing, and database design.
Mentor, support and manage team members
Qualifications
Your Skills and Experience:
Demonstrable experience in enterprise level data platforms involving implementation of end-to-end data pipelines
Hands-on experience with at least one of the leading public cloud data platforms (Amazon Web Services, Azure or Google Cloud)
Experience with column-oriented database technologies (e.g., Big Query, Redshift, Vertica), NoSQL database technologies (e.g., DynamoDB, BigTable, Cosmos DB, etc.) and traditional database systems (e.g., SQL Server, Oracle, MySQL)
Experience in architecting data pipelines and solutions for both streaming and batch integrations using tools/frameworks like Glue ETL, Lambda, Google Cloud DataFlow, Azure Data Factory, Spark, Spark Streaming, etc.
Metadata definition and management via data catalogs, service catalogs, and stewardship tools such as OpenMetadata, DataHub, Alation, AWS Glue Catalog, Google Data Catalog.
Test plan creation and test programming using automated testing frameworks, data validation and quality frameworks, and data lineage frameworks
Data modeling, querying, and optimization for relational, NoSQL, timeseries, graph databases, data warehouses and data lakes
Data processing programming using SQL, DBT, Python, and similar tools
Logical programming in Python, Spark, PySpark, Java, Javascript, and/or Scala
Cloud-native data platform design with a focus on streaming and event-driven architectures
Participate in integrated validation and analysis sessions of components and subsystems on production servers
Data ingest, validation, and enrichment pipeline design and implementation
SDLC optimization across workstreams within a solution
Bachelor’s degree in Computer Science, Engineering, or related field
Additional Information
Pay Range:$108,000 -$210,000
Benefits of Working Here:
Flexible vacation policy; time is not limited, allocated, or accrued
16 paid holidays throughout the year
Generous parental leave and new parent transition program
Tuition reimbursement
Corporate gift matching program
As part of our dedication to an inclusive and diverse workforce, Publicis Sapient is committed to Equal Employment Opportunity without regard for race, color, national origin, ethnicity, gender, protected veteran status, disability, sexual orientation, gender identity, or religion. We are also committed to providing reasonable accommodations for qualified individuals with disabilities and disabled veterans in our job application procedures. If you need assistance or an accommodation due to a disability, you may contact us at [email protected] or you may call us at +1-617-621-0200.
Apply Now: click Apply Now
Show Less
Report",3.8,10000+ Employees,1990,Company - Public,Business Consulting,Management & Consulting,Unknown / Non-Applicable
"Engineering Director, Commercial Data Engineering",$170K - $255K (Employer est.),Amex4.2 ★,"Phoenix, AZ","You Lead the Way. We’ve Got Your Back.
With the right backing, people and businesses have the power to progress in incredible ways. When you join Team Amex, you become part of a global and diverse community of colleagues with an unwavering commitment to back our customers, communities and each other. Here, you’ll learn and grow as we help you create a career journey that’s unique and meaningful to you with benefits, programs, and flexibility that support you personally and professionally.
At American Express, you’ll be recognized for your contributions, leadership, and impact—every colleague has the opportunity to share in the company’s success. Together, we’ll win as a team, striving to uphold our company values and powerful backing promise to provide the world’s best customer experience every day. And we’ll do it with the utmost integrity, and in an environment where everyone is seen, heard and feels like they belong.
Join Team Amex and let's lead the way together.

As part of our diverse tech team, you can architect, code and ship software that makes us an essential part of our customers’ digital lives. Here, you can work alongside talented engineers in an open, supportive, inclusive environment where your voice is valued, and you make your own decisions on what tech to use to solve challenging problems. Amex offers a range of opportunities to work with the latest technologies and encourages you to back the broader engineering community through open source. And because we understand the importance of keeping your skills fresh and relevant, we give you dedicated time to invest in your professional development. Find your place in technology on #TeamAmex

How will you make an impact in this role?
We’re looking for an experienced data engineering leader to join our Commercial Data Engineering organization. We build data-centric solutions to support the Global Commercial Services product suite including B2B payments, large corporate clients, and our small and medium enterprise ecosystem. You’ll lead your team and partner cross functionally to create innovative, scalable, resilient data systems that enable us to unlock the value of our data for all of our products.
Cultivate an environment of continuous improvement through technical guidance, coaching, mentoring, and feedback.
Lead one or more data engineering teams that iterate on our large-scale distributed, high-performance data platform.
Establish and maintain strong relationships with key stakeholders and cross functional partners to deliver collaboratively.
Perform hands-on architecture, design, development, and testing.
Drive high-level & detailed technical designs and conduct designs & code reviews as needed.
Implement process improvements to streamline areas for your team such as hiring, onboarding, software delivery, and internal/external communication.
Recruit and retain engineering talent.

Minimum Qualifications
Excellent written and verbal communication skills.
Expertise with a major cloud vendor (AWS/GCP).
Expertise with spark, python, SQL.
Experience leading high-performing data engineering teams focused on iterative delivery.
Experience partnering cross functionally and being a hands-on leader to drive successful execution.
Experience with CI/CD and strong understanding of implementing iterative software delivery practices.
Preferred Qualifications
Experience building unified data driven solutions with a data-lakehouse architecture.
Experience building event driven data streaming solutions
Salary Range: $170,000.00 to $255,000.00 annually + bonus + equity (if applicable) + benefits
The above represents the expected salary range for this job requisition. Ultimately, in determining your pay, we'll consider your location, experience, and other job-related factors.
We back our colleagues and their loved ones with benefits and programs that support their holistic well-being. That means we prioritize their physical, financial, and mental health through each stage of life. Benefits include:
Competitive base salaries
Bonus incentives
6% Company Match on retirement savings plan
Free financial coaching and financial well-being support
Comprehensive medical, dental, vision, life insurance, and disability benefits
Flexible work arrangements and schedules with hybrid and virtual options with Amex Flex
20+ weeks paid parental leave for all parents, regardless of gender, offered for pregnancy, adoption or surrogacy
Free access to global on-site wellness centers staffed with nurses and doctors (depending on location)
Free and confidential counseling support through our Healthy Minds program
Career development and training opportunities
For a full list of Team Amex benefits, visit our Colleague Benefits Site.
At American Express, you’ll be recognized for your contributions, leadership, and impact—every colleague has the opportunity to share in the company’s success. Together, we’ll win as a team, striving to uphold our company values and powerful backing promise to provide the world’s best customer experience every day. And we’ll do it with the utmost integrity, and in an environment where everyone is seen, heard and feels like they belong.
American Express is an equal opportunity employer and makes employment decisions without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, veteran status, disability status, age, or any other status protected by law.
We back our colleagues with the support they need to thrive, professionally and personally. That's why we have Amex Flex, our enterprise working model that provides greater flexibility to colleagues while ensuring we preserve the important aspects of our unique in-person culture. Depending on role and business needs, colleagues will either work onsite, in a hybrid model (combination of in-office and virtual days) or fully virtually.
US Job Seekers/Employees - Click here to view the “Know Your Rights” poster and supplement and the Pay Transparency Policy Statement.
If the links do not work, please copy and paste the following URLs in a new browser window: https://www.dol.gov/agencies/ofccp/posters to access the three posters.
To apply to this job, click Apply Now
Show Less
Report",4.2,10000+ Employees,1850,Company - Public,Financial Transaction Processing,Financial Services,$10+ billion (USD)
AWS Data Architect IV,$98K - $142K (Glassdoor est.),Habemco3.5 ★,"Upper Lake, CA","Habemco is a shared services company wholly owned and operated by the Habematolel Pomo of Upper Lake, a federally recognized Native American tribe located in Northern California. Our talented team provides cross-functional support services to various tribal business and government entities. Habemco’s primary support services power the Tribe’s flagship online lending brand, Uprova, and any future brands, through product development, technology, and other support needed for growth. The Habemco team plays a critical role in ensuring a successful future for our customers, our employees, and the Tribe.
Headquartered in a beautiful, yet remote part of California, the Tribe recognizes that to compete in the highly competitive FinTech industry, the Tribe must access expertise throughout the nation. In addition to employees that work remotely, the Tribe has employees clustered at headquarters in Upper Lake, California, and a call center in Lenexa, Kansas.
Employees receive competitive pay and benefits, quarterly performance bonuses and 401(k) with a 4% match. Our team is ambitious, forward-thinking, passionate and moves fast! Are you ready to grow with us?

Purpose of the Position:
The AWS Data Architect IV will provide technology architectural assessments, strategies, and roadmaps for one or more projects & oversee the development and implementation of programs and provide technical leadership and support to the data development teams by identifying best-fit architectural solutions. To be successful in this role, you need deep expertise in design and architecture. You will partner closely with the business analyst, product owners, management, and stakeholders to align the architecture and recommend solutions that meet business and technology needs. All offers are contingent upon signing a confidentiality agreement and satisfactory completion of drug screening and background checks.
Essential Duties
Responsible for overall architecture and design of the solution delivered by the team.
Formulate target state architecture and roadmaps.
Lead a team and provide technical oversight, guidance, and review of the team's deliverables.
Data Modeling & Solution design for data solutions.
Embrace and incubate emerging technology and open-source products across all platforms.
Think outside the box and bring new ideas to the table to modernize the company's existing tech stacks and data platforms.
Advance the enterprise information data & integration architecture strategy.
Partner with architects, product owners, data professionals, and software & data engineers to drive the implementation of new applications.
Work within and across Agile teams to design, develop, test, implement and support technical solutions across full-stack development tools and technologies.
Lead efforts to deploy new and existing applications into AWS environments and provide operational support for the applications.
Conduct design and code reviews to ensure compliance with applicable standards.
Performs ad hoc duties and responsibilities as needed.
Stay up to date with technology, trends, and tools in Big Data.
Regular, reliable attendance during normal business hours.
In-person attendance and travel as requested.
Other duties as assigned.
Education and Experience
Required:
Bachelor's Degree Computer Science or other related technical discipline.
7+ years in IT and 5 years’ experience working as an AWS Data Architect.
5 years in Data warehouse, ETL, and BI projects.
5+ years of experience with Big Data, data streaming, & cloud-based platforms.
5+ years of experience with Data Lake Infrastructure, Data Warehousing, and Data Analytics tools.
Experience in AWS in developing solutions using microservices.
Hands-onexperience on AWS in developing solutions using microservices, AWS Lambda, API / Microservices (Code build, Code deploy and govern), API Gateway, and S3 Storage.
5+ years of experience in solution architecture, design detailing, and technology delivery with a particular focus on AWS platform services.
5+ years of experience in AWS platform services, such as: compute, containers, integration, internet of things, storage, web, and DevOps.
A minimum of two end-to-end implementations of Datawarehouse on Amazon cloud.
Expertise in AWS Platform as a Service (PAAS).
Strong track record of successfully architecting and deploying AWS solutions.
Exposure in defining solution architecture, design detailing, and technology delivery with a particular focus on AWS platform services, such as: compute, containers, integration, internet of things, storage, web, and DevOps.
Hands-on experience on AWS storage services like AmazonS3, Amazon Kinesis, Amazon Dynamo DB, Amazon RDS.
All offers are contingent upon signing a confidentiality agreement and satisfactory completion of drug screening and background checks.Employer observes federal standards for controlled substances.
Preferred:
Hands-on experience on AWS Event/ Data Processing services like AWS Lambda, Amazon Kinesis, Amazon EMR, Amazon Machine Learning.
Hands-on experience on AWS Data Analysis services like Amazon Redshift, Amazon Quick sight.
Experience/knowledge in AWS EKS, AWS Databases (RDS, Dynamo DB, DMS, Elastic Cache, etc.), AWS Faregate, SNS/SQS/Kinesis, Logic Apps, IoT, S3 Data Lake, Athena, and AWS Director services.
Skills and Ability
Advanced problem-solving skills and the ability to optimize data for the best possible outcome.
Ability to prioritize and manage multiple milestones and projects efficiently.
A willingness to dig deep, learn from others, share your own skills, and be part of a talented and dedicated team.
Superior attention to detail.
Highly adaptable, a driver of change, and capable of quickly rallying teams.
Effectively prioritizes and executes tasks in a highly productive yet autonomous environment.
Strong decision-making and problem-solving skills (i.e., design, debugging, and testing) and experience with software development projects.
Ability to present technical ideas in concise, user-friendly, or layman's language.
Strong interpersonal skills used in developing effective working relationships and listening skills.
Result-driven and solutions-oriented with the ability to develop and implement the resolution in time-sensitive situations.
Motivate and mentor team members to grow their skills and careers by creating a nurturing environment that encourages innovation and continual learning.
Ability to work in a fast-paced, time-sensitive, and confidential environment.
Excellent communication skills: utilizing the ability to communicate effectively both orally and in writing with professionalism, excellent grammar, respect and courteousness.
Possess a balance of assertiveness and diplomacy along with adaptability in order to communicate on all levels.
Physical Requirements
Prolonged periods in a stationary seated position, such as working on a computer.
Frequently move, transport, and manipulate computer equipment up to 15 pounds.
Verbal communication sufficient to exchange accurate ideas and information.
In-person attendance and travel as requested.
Show Less
Report",3.5,Unknown,-1,Unknown,Investment & Asset Management,Financial Services,Unknown / Non-Applicable
ETL & Data Warehouse Manager / Architect (Remote),$94K - $128K (Glassdoor est.),Crum & Forster4.0 ★,"Morristown, NJ","Crum & Forster Company Overview:
Crum & Forster (C&F) Crum & Forster (C&F), with a proud history dating to 1822, provides specialty and standard commercial lines insurance products through our admitted and surplus lines insurance companies. C&F enjoys a financial strength rating of ""A"" (Excellent) by AM Best and is proud of our superior customer service platform. Our claims and risk engineering services are recognized as among the best in the industry.
Our most valuable asset is our people: more than 2000 employees in locations throughout the United States. The company is increasingly winning recognition as a great place to work, earning several workplace and wellness awards, including the October 2022 Great Place to Work® Award for our employee-first focus and our steadfast commitment to diversity, equity and Inclusion.
C&F is part of Fairfax Financial Holdings, a global, billion dollar organization. For more information about Crum & Forster, please visit our website: www.cfins.com.
Job Description:

C&F is looking for a passionate ETL & Data Warehouse Manager / Architect for our Snowflake implementation initiative, with significant experience in ETL solutions using SQL Server Integration Services and Snowflake. In this role, you will be responsible for designing and managing the development of robust ETL solutions for loading & extracting data from various source and target systems from our Snowflake Data warehouse. You will also be responsible for maintaining the Snowflake Data Warehouse schema design.
What you will do:

Collaborate with stakeholders and various IT groups to implement an overall data strategy that is in line with business objectives
Help the organization to bring our “one trusted data source” vision to life through a formal enterprise data lake house
Design build and maintain data models, data warehouses, data lakes, data marts and reporting/analytics solutions
Develop and maintain data integration and data transformation best practices and standards
Keep up-to-date with industry trends and advancements in ETL technologies and tools
Manage a team of ETL developers, providing guidance, support, and training as needed. This team will:
Identify and proactively resolve issues that could impact system performance, reliability, and usability
Develop and maintain ETL documentation, including technical specifications, data mappings, and data lineage
Perform data profiling and data quality analysis to ensure that ETL processes are accurate and reliable
Troubleshoot and resolve ETL issues and errors
What you will bring to C&F:

8+ years of experience in ETL development and data integration solutions using SSIS or any other ETL tool
8+ years of database development experience using Microsoft SQL Server, Oracle, and any other RDBMS
Strong knowledge of SQL/T-SQL/PL-SQL, Query Optimization, and Data management skills
Experience in Data warehouse development; Logical and Physical Database design & development
Experience with Snowflake data warehouse would be a big plus
Experience with BI tools such as SSRS/SSAS would be a plus
Experience with any cloud data warehouse would be plus
Knowledge of code versioning tools such as Git or stash would be a plus
Experience working in an agile environment would be a plus
Work experience related to the Insurance vertical would be a plus
Excellent critical thinking, analytical and problem-solving skills
Ability to think outside of the box and propose innovative solutions
Excellent written and oral communication skills
#LI-MS

# LI-REMOTE
What C&F will bring to you:
Competitive compensation package
Generous 401K employer match
Employee Stock Purchase plan with employer matching
Generous Paid Time Off
Excellent benefits that go beyond health, dental & vision. Our programs are focused on your whole family’s wellness, including your physical, mental and financial wellbeing
A core C&F tenet is owning your career development, so we provide a wealth of ways for you to keep learning, including tuition reimbursement, industry-related certifications and professional training to keep you progressing on your chosen path
A dynamic, ambitious, fun and exciting work environment
We believe you do well by doing good and want to encourage a spirit of social and community responsibility, matching donation program, volunteer opportunities, and an employee-driven corporate giving program that lets you participate and support your community

At C&F you will BELONG

If you require special accommodations, please let us know.We value inclusivity and diversity. We are committed to equal employment opportunity and welcome everyone regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity, or Veteran status. If you require special accommodations, please let us know
Apply Now: click Apply Now
Show Less
Report",4.0,1001 to 5000 Employees,1822,Subsidiary or Business Segment,Insurance Carriers,Insurance,Unknown / Non-Applicable
Big Data Architect,$93K - $166K (Employer est.),PSRTEK4.5 ★,"Denver, CO","Role: Data Architect
Location: Denver CO, (Day 1 Onsite)
Job Description
Big Data Architect experienced to Manage the Data with core foundational Data Architecture knowledge (12 to 15+yrs)
Data Archival, taxonomy, classification, Tagging,
Business Cataloging
Access control to Data
Data Governance
Data Management
Data Archival
Build Business glossary
Build Metadata
AWS Technologies skills or any cloud technologies a plus
Job Type: Contract
Salary: $92,559.20 - $165,638.64 per year
Ability to commute/relocate:
Denver, CO 80014: Reliably commute or planning to relocate before starting work (Required)
Experience:
Big Data: 10 years (Preferred)
Work Location: In person
Speak with the employer
+91 609-934-3291
Show Less
Report",4.5,Unknown,-1,Company - Private,Information Technology Support Services,Information Technology,Unknown / Non-Applicable
Senior Principal Big Data Architect,$220K - $352K (Employer est.),Zillow3.9 ★,Remote,"About the team
Are you looking for an opportunity to help millions of customers navigate one of the biggest life decisions they'll ever make? Zillow's mission is to give people the power to unlock life's next chapter. We work with Designers, Engineers, Data Scientists, and Researchers to solve complex engineering problems and build products that transform the real estate industry. Our Product Teams are tasked with finding solutions to bridge the gap between you and your next address by delivering end-to-end experiences for customers actively shopping, renting, touring, or financing their home. Our Teams are also working to solve difficult problems for real estate agents in the field by providing industry leading platforms and tooling.

We maintain our competitive edge by making data driven decisions that we evolve through rapid testing and iteration to ensure we are launching enjoyable experiences to the world’s largest online real estate marketplace. We are not done yet. Our goal is to achieve Zillow 2.0, which will deliver seamlessly comprehensive solutions for buyers, sellers, and agents transacting with all the services Zillow provides. And, we need your help to do it!
About the role
As a Senior Principal Data Architect you will lead data architecture practice and represent Data Engineering at the enterprise level. The Data Engineering (DE) team is building the new generation of a Data Platform to enable implementation of Data Mesh principles and drastically improve time to value for all engineers who work with data. This work requires proven expertise in big data combined with a never ending ability to learn and evolve your thinking.

You will facilitate cross-team collaboration for defining and building enterprise data management architecture from principals to tools, oversee cross-functional adoption of new architecture, and enable a new level of engineering efficiency when working with data.

You will get to:
Defining enterprise data architecture for data platform
Working with Platform team on building platform functionality and with data engineers on adoption of platform functionality
Influencing and educating whole team on topics of modern data architecture
Shape data lakehouse data models and bring it to performant physical models specifically tailored to chosen storage format and data tech stack
Advance best DE architecture practices with focus on performance, scalability, security, enabling future capabilities and resilience. Drive and communicate architecture decisions across the Zillow Data Ecosystem.
Create cohesive architecture practices across DE producing standard methodologies and reference architecture that the team can leverage.
Create consensus and alignment on technology choices, data formats and data flows and provide guidance to teams on new technologies and future technical investments.
Create alignment with product teams on technical vision and long term product vision.
Represent the DE architecture in the Enterprise Architecture Group
This role has been categorized as a Remote position. “Remote” employees do not have a permanent corporate office workplace and, instead, work from a physical location of their choice which must be identified to the Company. Employees may live in any of the 50 US States, with limited exceptions. In certain cases, an employee in a remote-designated job may need to live in a specific region or time zone to support customers or clients as part of their role.
In California, Colorado, Connecticut, Nevada, New York City and Washington the standard base pay range for this role is $220,200.00 - $351,800.00 Annually. This base pay range is specific to California, Colorado, Connecticut, Nevada, New York City and Washington and may not be applicable to other locations.
In addition to a competitive base salary this position is also eligible for equity awards based on factors such as experience, performance and location. Actual amounts will vary depending on experience, performance and location.
Who you are
You have built data platforms and solutions, accumulated enough experience to know how to solve non-trivial challenges for a non-trivial business and how to shape enterprise data systems into a cohesive enterprise data management platform.
You can demonstrate successful projects related to data systems at medium and large size companies in leading architecture roles
Experience mentoring engineers and oversee project execution and delivery for adhering to blueprints and architecture principles.
You are designing enterprise systems and processes that span org structures and levels, inspire with your strong and robust vision and technical leadership
Previous experience leading technical organizations through change in leading data management practices to next level and enabling business to get data-rooted results
You are a master of concepts, but you think in code. There is a wide array of proven tools in your toolbox - Spark, advanced Python, unlimited SQL, deep knowledge of data streaming, intimate understanding of data structures. You are native to cloud thinker, ready to demonstrate your ideas with prototypes and partner with data engineers on complex implementations, helping guide work and showcase architecture principles
Ability to explain advanced concepts in simple to understand manner
Strong partnership with Zillow Enterprise Architecture (ZGEA) group advocating for data management
Able to balance multiple contending priorities in a fast-paced environment

Get to know us
Zillow is reimagining real estate to make home a reality for more and more people.
As the most-visited real estate website in the United States, Zillow® and its affiliates help movers find and win their home through digital solutions, first class partners, and easier buying, selling, financing and renting experiences. Millions of people visit Zillow Group sites every month to start their home search, and now they can rely on Zillow to help make it easier to move. The work we do helps people get home and no matter what job you're in, you will play a critical role in making home a reality for more and more people.
Our efforts to streamline the real estate transaction are supported by a deep-rooted culture of innovation, our passion to redefine the employee experience, a fundamental commitment to Equity and Belonging, and world-class benefits. These benefits include comprehensive medical, dental, vision, life, and disability coverages as well as parental leave, family benefits, retirement contributions, and paid time off. We’re also setting the standard for work experiences of the future, where our employees are supported in doing their best work and living a flexible, well-balanced life. But don’t just take our word for it. Read recent reviews on Glassdoor and recent recognition from multiple organizations, including: the 100 Best Companies to Work For, Glassdoor Employees’ Choice Award, Bloomberg Gender-Equality Index, Human Rights Campaign (HRC) Corporate Equity Index, and TIME 100 Most Influential Companies list.
Zillow Group is an equal opportunity employer committed to fostering an inclusive, innovative environment with the best employees. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. If you have a disability or special need that requires accommodation, please contact us at RecruitingAccessibility@zillowgroup.com.
Applicants who receive job offers from Zillow Group will be asked to sign a Proprietary Rights Agreement which includes confidentiality, intellectual property assignment, customer and employee non-solicitation, and non-competition provisions. If you are contacted for a role at Zillow Group and wish to review a copy of the Proprietary Rights Agreement prior to receiving an offer, you may request a copy from your Recruiter.
Start your job application: click Apply Now
Show Less
Report",3.9,5001 to 10000 Employees,2005,Company - Public,Internet & Web Services,Information Technology,$1 to $5 billion (USD)
Principal data engineer,$118K - $171K (Glassdoor est.),bp4.1 ★,"Houston, TX","Location
United States of America - Texas - Houston
Travel required
No travel is expected with this role
Job category
Digital & technology
Relocation available
This role is not eligible for relocation
Job type
Professionals
Job code
RQ063058
Experience level
Senior

Job summary
Entity:
Innovation & Engineering

Job Family Group:
IT&S Group

Job Summary:
As a Principal Data Engineer, you will be part of bp’s Compute Platforms organisation, the group responsible for the computing platforms and services that underpin all bp’s computing services. The portfolio covers technologies that include on-premise data centres, cloud infrastructure and services, high-performance computing, databases, and supporting services.

Job Description:
Key Accountabilities:
Led a team of DevOps squads made up of software engineers, platform engineers, platform architects, and platform security engineers using agile development ceremonies including Kanban, refinement, and retrospectives, to deliver the Azure platform and resource provisioning services necessary for service and platform owners to deliver their agendas.
Build the platform strategy and product roadmap for Azure by working with partners internal and external to the team.
Develop a cloud alignment strategy for both AWS and Azure to provide a consistent customer experience.
Build relationships with external teams, including Digital Security and Architecture, to provide a balance of security and functionality in the Azure platform.
Provide a principle (architecture, design, and security) led service to allow the DevOps teams to be mostly autonomous squads to help deliver solutions rapidly.
Provide governance to enable prioritization of customer demand to ensure new and enhanced services are available for customer projects.
Provide guest platforms (DBaaS, CaaS, CPIN, WVD) the ability to deliver their services while minimizing their dependency on the Azure platform team.
Identify areas of continuous improvement to reduce the effort customers must put in to consume the Azure services (reduce customer friction).
Manage suppliers providing services for the Azure platform to ensure they provide people that are able to develop products/features following out team standards and principles.
Develop training programs with Microsoft to upskill bp staff and contractors as related to Azure capabilities.
Mentor and coach team members, while defining and promoting usage of standards, principles, and lessons learned
Essential Experience:
Developing and leading digital/technology strategies
Broad and strategic knowledge of the cloud technology landscape
Demonstrate strong product management and design thinking foresight skills
Strong facilitation and leadership skills: bringing multiple partners from architecture, digital security, and product/service owners together towards agreed outcomes.
Outstanding communication and relationship skills, ability to engage with a broad range of partners, capable of leading by influence.
Knowledge and understanding of modern development methodologies (agile using Kanban, DevOps, 2-pizza teams, agile ceremonies).
Knowledge and understanding of modern approaches to source-code management and control through tools (SonarCube, Azure DevOps, coding standards)
Bachelor's degree and/or MBA in relevant subject or equivalent preferred or equivalent experience.
Why join us

At bp, we support our people to learn and grow in a diverse and exciting environment. We believe that our team is strengthened by diversity. We are committed to fostering an inclusive environment in which everyone is respected and treated fairly.

There are many aspects of our employees’ lives that are important, so we offer benefits to enable your work to fit with your life. These benefits can include flexible working options, a generous paid parental leave policy, and excellent retirement benefits, among others!

We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation.

Travel Requirement
No travel is expected with this role

Relocation Assistance:
This role is not eligible for relocation

Remote Type:
This position is a hybrid of office/remote working

Skills:

Legal Disclaimer:
We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, sex, gender, gender expression, sexual orientation, age, marital status, neurodiversity/neurocognitive functioning, veteran status or disability status. Individuals with disabilities may request a reasonable accommodation related to bp’s recruiting process (e.g., accessing the job application, completing required assessments, participating in telephone screenings or interviews, etc.). If you would like to request an accommodation related to the recruitment process, please contact us to request accommodations.
If you are selected for a position and depending upon your role, your employment may be contingent upon adherence to local policy. This may include pre-placement drug screening, medical review of physical fitness for the role, and background checks.
Apply Now: click Apply Now
Show Less
Report",4.1,10000+ Employees,1908,Company - Public,Energy & Utilities,"Energy, Mining & Utilities",$10+ billion (USD)
Data Warehouse Programmer,$75K - $160K (Employer est.),Bethesda Game Studios3.4 ★,"Rockville, MD","Overview
Join Constellation!
Come join Bethesda Game Studios, the award-winning development team behind Starfield, The Elder Scrolls and Fallout. Bethesda Game Studios strives to offer its employees a well-balanced home and work life by providing competitive salaries, a generous benefits program, and offices located in some of North America’s best cities.
With a goal of creating a culture as fun and diverse as our games and our players, we welcome applicants with unique skillsets, experience levels and backgrounds. If you are passionate about making a meaningful contribution to some of the most significant games in the industry we’d love to hear from you!
Responsibilities
Your Daily Life at Bethesda Game Studios
As Data Warehouse Programmer, you will...
Work with other data programmers and game analysts to build new and extend existing data structures to support game analytics
Develop, maintain, and support ETL processes for loading data from multiple data sources into a Redshift data warehouse
Maintain and develop all physical data models for EDW.
Maintain large, multi-terabyte data warehouse which includes performance tuning and data retention/purge processes
Research and troubleshoot data quality issues, providing fixes and proposing both short- and long-term solutions
Prepare designs for database systems and recommend improvements for performance.
Maintain and develop various database scripts and tools to facilitate automation process
Provide support to all data warehouse initiatives.
Evaluate all proposals requests and assist to improve structure of data warehouse
Qualifications
What Makes you S.P.E.C.I.A.L.
You have 3+ years of experience in a data warehousing, data engineering, or data architect role
You have strong experience with AWS Redshift or similar databases
You have experience working with other AWS data technologies such as S3, Redshift Spectrum, Athena, Data Pipeline, Glue, EMR, RDS, and Kinesis
You have excellent SQL skills
You have data modeling experience for both transactional and data warehousing environments including familiarity with Kimball dimensional and 3NF modeling standards
You have strong interpersonal skills and problem-solving ability
Salary Range
Data Warehouse Programmer - The typical base pay range for this position at the start of employment is expected to be between $75,000 - $160,000 per year.

ZeniMax has different base pay ranges for different work locations within the United States, which allows us to pay employees competitively and consistently in different geographic markets. The range above reflects the potential base pay across the U.S. for this role; the applicable base pay range will depend on what ultimately is determined to be the candidate’s primary work location. Individual base pay depends on various factors, in addition to primary work location, such as complexity and responsibility of role, job duties/requirements, and relevant experience and skills. Base pay ranges are reviewed and typically updated each year. Offers are made within the base pay range applicable at the time.
At ZeniMax certain roles are eligible for additional rewards, such as merit increases and discretionary bonuses. These awards are allocated based on individual performance and are not guaranteed. Benefits/perks listed here may vary depending on the nature of employment with ZeniMax and the country work location. U.S.-based employees have access to healthcare benefits, a 401(k) plan and company match, short-term and long-term disability coverage, basic life insurance, wellbeing benefits, paid vacation time, paid sick and mental health time, and several paid holidays, among others.
We embrace diversity, equity, and inclusion in everything we do – from recruiting for our studios, publishing and operations to fostering safe and respectful workplaces that encourage collaboration. Our culture is based on principles of respect, inclusion, and fair treatment and we welcome anyone into our family without regard to race, religion, gender identity, sexual orientation, or age.
Our diversity fuels our innovation and inspires us to create game worlds that bring us closer to the global community of players we serve.
Show Less
Report",3.4,51 to 200 Employees,-1,Subsidiary or Business Segment,Video Game Publishing,Media & Communication,$5 to $25 million (USD)
"Solutions Architect, Cisco FSO (Remote)",$64K - $100K (Glassdoor est.),Presidio4.0 ★,"Raleigh, NC","SEIZE THE OPPORTUNITY TO BE A PART OF SOMETHING GREAT!
Presidio is on the leading edge of a technology-driven movement to transform the way business is done, for our customers and our customers' customers. Joining Presidio means immersing yourself in a culture of self-starters, collaborators and innovators who make real, lasting change in the marketplace via cutting-edge technology and business solutions. At Presidio, we know that it’s our people that make the connections happen.
WHY YOU SHOULD JOIN US? You will set your career on track for outstanding achievement with a company that knows no limits. Presidio is a leading a global digital services and solutions provider focused on Digital Infrastructure, Business Analytics, Cloud, Security & Emerging solutions.

THE ROLE: Internal Job Title

Job Summary:
As a Solutions Architect (SA) and a member of the Pre-Sales Engineering Team, the candidate will be responsible for working with Presidio account managers and customers to collect requirements and build solutions tailored around the Cisco Full Stack Observability (FSO) portfolio products. This position will be remote, as the role will support Presidio accounts across the entire country.

A successful Solutions Architect should be able to present and explain the various use cases for the Cisco FSO stack to customers, guide them through requirements gathering, and formulate a solution consisting of one or more offerings. SAs are responsible for creating scopes of work and task lists for various types of projects in support of these solutions.
Travel Requirements: In this role you will be expected to travel up to 20%. It will be based in any location in the United States (Remote)

Job Responsibilities:
Meet with Presidio’s customers, collecting requirements for observability solutions
Present and explain technologies to customers, guide them through requirements gathering and formulate a solution consisting of software, licensing, and engineering services
Develop engineering solutions for sale to Presidio customers.
Work with Account Manager/Sales Team to develop customer relationships and solutions to assist in the sales process
Create high level solutions designs/architecture and present to customers
Creative customer-facing presentations
Create Bills of Materials & Configurations for solutions
Develop Professional Services Pricing
Write Statements of Work and Proposals
Create scope of work and task lists for various types of projects in support of these solutions.
Mentor deployment engineers and provide technical leadership around the FSO stack
Required Skills:
Demonstrated passion for technology, solution design, and self-study
Comfortable leading group presentations, solution demonstrations, and whiteboard sessions
Strong sales acumen and technical expertise
Candidates must have strong written and verbal communication skills
Candidates should have a depth of knowledge and experience with design, implementation and support of at least 3 of the following:
Complex campus and data center routing and switching solutions
Cisco Wireless
Firewall, SASE, and malware (Palo Alto, Cisco and/or Fortinet)
SD-WAN
Cisco Meraki portfolio
Cloud networking (AWS/Azure/GCP)
Education and Experience:
Bachelor’s degree or equivalent experience and/or military experience
3+ years of architecting and/or implementing complex Networking, Data Center, Collaboration and/or Security solutions
1+ year experience of architecting and/or implementing the Cisco FSO stack
*****
ABOUT PRESIDIO
Presidio is committed to Diversity, Equity, and Inclusion at the highest levels and has strengthened its drive to build and drive systemic DEI change process across all levels of the organization. Cultivating a culture of inclusion where the expression of all our differences are valued, celebrated, and add to our collective achievements.
Presidio is a global digital services and solutions provider accelerating business transformation through secured technology modernization. Highly skilled teams of engineers and solutions architects with deep expertise across cloud, security, networking and modern data center infrastructure help customers acquire, deploy and operate technology that delivers impactful business outcomes. Presidio is a trusted strategic advisor with a flexible full life cycle model of professional, managed, and support and staffing services to help execute, secure, operationalize and maintain technology solutions. We serve as an extension of our clients' IT teams, providing deep expertise and letting them focus on their core business. Presidio operates in 40+ US offices and offices in Ireland, London, Singapore, and India.
For more information visit: http://presidio.com
*****
Presidio is an Equal Opportunity / Affirmative Action Employer / VEVRAA Federal Contractor. All qualified candidates will receive consideration for this position regardless of race, color, creed, religion, national origin, age, sex, citizenship, ethnicity, veteran status, marital status, disability, sexual orientation, gender identification or any other characteristic protected by applicable federal, state and local statutes, regulations and ordinances.
To read more about discrimination protections under Federal Law, please visit: https://www.dol.gov/ofccp/regs/compliance/posters/pdf/OFCCP_EEO_Supplement_Final_JRF_QA_508c.pdf
If you have any difficulty using our online system and need an accommodation in the job application process due to a disability, please send an email to recruitment@presidio.com for assistance.
Presidio is a VEVRAA Federal Contractor requesting priority referrals of protected veterans for its openings. State Employment Services, please provide priority referrals to recruitment@presidio.com.
RECRUITMENT AGENCIES PLEASE NOTE:
Agencies/3 Parties may not solicit to any employee of Presidio. Any candidate information received from any Agency/3 Party will be considered a gift and property of Presidio, unless the Agency/3 Party is an Authorized Vendor of Presidio with an up-to-date Presidio Contract in hand signed by Presidio Talent Acquisition. No payment will be made to any Agency/3 Party who is not an Authorized Vendor, nor has specific approval in writing from Presidio Talent Acquisition to engage in recruitment efforts for Presidio.
To apply to this job, click Apply Now
Show Less
Report",4.0,1001 to 5000 Employees,2006,Subsidiary or Business Segment,Information Technology Support Services,Information Technology,Unknown / Non-Applicable
Data Domain Architect Senior Associate - Data Pipeline Streaming,$138K - $200K (Employer est.),JPMorgan Chase & Co4.0 ★,"Jersey City, NJ","JOB DESCRIPTION

This position will be a key role within the Data Pipeline (DPL) Streaming product office. Under limited supervision, this role will be responsible for leading both product development and customer engagement. From initial meetings and demos to leading proof-of-concept evaluations, you will be the customers trusted advisor on all things Streaming related. Working in conjunction with the engagement analyst(s) and product team, you will be primarily responsible for ensuring that clients technical criteria are defined, documented and have the appropriate validation events scoped and executed to ensure a technical “win” and customer “adoption”. Duties include but not limited to are:
Support the DPL Streaming Product office in the overall engagement process
Offer expert advice on use cases and solution scope, from initial planning, implementation to resolution of technical issues
Effective in assessing business problems and recommending solutions
Lead meetings and/or workshops with potential clients to determine the technical and business requirements and ensure that all necessary information is collated prior to producing a solution
Support the Streaming team with overall customer requirements - translating customer requirements into internal facing documentation for purpose of definition and estimations of requirements
Technical Architecture to solution of required feature
Build productive relationships internally and externally, credible with both business and technical functions
Manage Product Engagement Analysts
Qualifications
3+ years experience and supporting a technical product
Ability to think strategically and work in a global environment
Ability to solution and specification of required technical features
AWS cloud proficient, preferably with related certifications.
Diligent and efficient in execution even under tight time constraints; consistently overcomes and helps others overcome obstacles to completion
High proficiency in Excel, Word, and PowerPoint
Able to change tone of situations positively; drives change and always considers diverse perspectives to get the best outcome
Ability to thrive in a fast-paced, collaborative and cross-functional environment
Excellent written and verbal communication skills: able to present facts, thoughts, and ideas in a clear, concise, and convincing manner to senior stakeholders
Experience working in agile/scrum teams preferred
Exhibit an organized and systematic approach to problem solving, understanding of both design thinking and systems thinking
Very organized and able to work on multiple projects concurrently
Excellent interpersonal and presentation skills; both face to face and remotely
Strong customer facing and presentation skills
Minimum BS or equivalent level of education/experience required
JPMorgan Chase is an Equal Opportunity and Affirmative Action Employer, M/F/D/V.
ABOUT US

Chase is a leading financial services firm, helping nearly half of America’s households and small businesses achieve their financial goals through a broad range of financial products. Our mission is to create engaged, lifelong relationships and put our customers at the heart of everything we do. We also help small businesses, nonprofits and cities grow, delivering solutions to solve all their financial needs.
We recognize that our people are our strength and the diverse talents they bring to our global workforce are directly linked to our success. We are an equal opportunity employer and place a high value on diversity and inclusion at our company. We do not discriminate on the basis of any protected attribute, including race, religion, color, national origin, gender, sexual orientation, gender identity, gender expression, age, marital or veteran status, pregnancy or disability, or any other basis protected under applicable law. In accordance with applicable law, we make reasonable accommodations for applicants’ and employees’ religious practices and beliefs, as well as any mental health or physical disability needs.

The health and safety of our colleagues, candidates, clients and communities has been a top priority in light of the COVID-19 pandemic. JPMorgan Chase was awarded the “WELL Health-Safety Rating” for all of our 6,200 locations globally based on our operational policies, maintenance protocols, stakeholder engagement and emergency plans to address a post-COVID-19 environment.
As a part of our commitment to health and safety, we have implemented various COVID-related health and safety requirements for our workforce. Employees are expected to follow the Firm’s current COVID-19 or other infectious disease health and safety requirements, including local requirements. Requirements include sharing information including your vaccine card in the firm’s vaccine record tool, and may include mask wearing. Requirements may change in the future with the evolving public health landscape. JPMorgan Chase will consider accommodation requests as required by applicable law.
We offer a competitive total rewards package including base salary determined based on the role, experience, skill set, and location. For those in eligible roles, discretionary incentive compensation which may be awarded in recognition of individual achievements and contributions. We also offer a range of benefits and programs to meet employee needs, based on eligibility. These benefits include comprehensive health care coverage, on-site health and wellness centers, a retirement savings plan, backup childcare, tuition reimbursement, mental health support, financial coaching and more. Additional details about total compensation and benefits will be provided during the hiring process.
Equal Opportunity Employer/Disability/Veterans



ABOUT THE TEAM

Our Consumer & Community Banking division serves our Chase customers through a range of financial services, including personal banking, credit cards, mortgages, auto financing, investment advice, small business loans and payment processing. We’re proud to lead the U.S. in credit card sales and deposit growth and have the most-used digital solutions – all while ranking first in customer satisfaction.
Apply Now: click Apply Now
Show Less
Report",4.0,10000+ Employees,1799,Company - Public,Banking & Lending,Financial Services,$10+ billion (USD)
"Sr Lead Solution Architect - Remote, US",$100K - $224K (Employer est.),Lumen3.5 ★,Remote,"About Lumen
Lumen is guided by our belief that humanity is at its best when technology advances the way we live and work. With 450,000 route fiber miles serving customers in more than 60 countries, we deliver the fastest, most secure global platform for applications and data to help businesses, government and communities deliver amazing experiences. Learn more about Lumen’s network, edge cloud, security and communication and collaboration solutions and our purpose to further human progress through technology at news.lumen.com, LinkedIn: /lumentechnologies, Twitter: @lumentechco, Facebook: /lumentechnologies, Instagram: @lumentechnologies and YouTube: /lumentechnologies.
The Role
Lumen is looking for Solution Architects who are passionate about leveraging technology innovation for the betterment of humanity. This exciting solution architecture role will work in partnership with the Business Units, leading innovative conversations that help shape the growth of our Mass Markets ecosystem. Solution Architects design and architect solutions utilizing our technology services platform. The successful Solution Architect must have a strong desire to leverage their technical and communication skills, including business acumen, to understand business requirements, develop a technical architecture, and effectively present solutions that address our business partner’s requirements and provide business value.
The Solution Architect will be responsible for analyzing customer needs and requirements through strategic discovery, utilizing technical thought leadership, discussing industry best practices, and then delivering a technical solution that meets or exceeds the business need – including non-functional specifications, enablers, 3rd party requirements, and delivers the documented business value.
The Main Responsibilities
Business Meetings: Leads and attends business meetings in person and via collaboration tools. Prepares and delivers technical proposals and presentations with the appropriate level of business acumen for the audience. Provides detailed, specific responses to solution and technology questions. Demonstrates strong solution ‘selling abilities’ and effective, proactive business communications. Interacts with all levels of IT and Business teams.
Solution Development: Analyze and identify our Business Partner’s business and technology objectives, conduct full technical discovery, and architect business solutions to meet gathered requirements. Assess business and operations impacted by technology. Craft and propose solutions that meet the business’s requirements and objectives by asking probing questions that are meaningful to the business to collect information that enables the architecture team to be more effective and responsive to clients’ needs. Ability to complete complex custom designs.
Customer Advocate: Acts as a client advocate, participating in efforts including technical presentations, architecture design discussions, proof-of-concept engagements, RFP/RFI responses, solution demonstrations, and technical workshops. Deliver findings including key pain points, proposed solutions to meet business needs, and ROI where applicable. Design, architect and demonstrate visionary solutions in a way that closely reflects our client's technology roadmap.
What We Look For in a Candidate
Education: B.S. Computer Science, Engineering, MIS, or equivalent work experience in the private sector
Experience: Minimum of 8+ years in developing IT solutions, including but not limited to: Telecommunications B/OSS system architecture, Operations, Infrastructure/Database Architecture, and/or Applications Development
Technical Knowledge: Possess knowledge of Mass Markets Architecture and Design. Demonstrate technical knowledge across one or more Lumen technology pillars.
Communication: Ability to lead & engage in technical workshops, and solution discussions with Business and IT Stakeholders. Strong listening, reasoning, and objection handling skills.
Problem-Solving: General problem-solving skills and ability to methodically understand and resolve complex issues. Must demonstrate the ability to focus ambiguous business needs into specific, deliverable requirements. Must demonstrate creative solution development.
Work Style: Ability to work independently, or as part of a team to build complex customer solutions. Must be able to build strong team relationships and easily transfer technical information. Ability to work under pressure with tight deadlines and on multiple projects simultaneously. Must be very detail-oriented and demonstrate a high degree of accuracy. Attention to detail with good organizational capabilities. Ability to prioritize with good time management skills.
Presentation Skills: Strong presentation skills as well as the ability to build and present high-quality solutions to both technical and executive audiences.

Preferred Skills:
Broad technology experience in application development, cloud architecture, Relational/NoSQL databases, analytics, machine learning, DevOps, management, and monitoring
Industry experience in Telco or ECommerce or Agent Ordering
Experience architecting/designing solutions in the cloud and non-cloud platforms
Expertise in documenting and understanding different types of diagrams including but not limited to: Dataflow diagrams, Context diagrams, and Sequence diagrams
What to Expect Next
Requisition #: 328548
When applying for a position, you may be subject to a background screen (criminal records check, motor vehicle report, and/or drug screen), depending on the requirements for the position. More information on what’s included in these checks can be found in the Post Offer section of our FAQ page. Job-related concerns noted in the background screen may disqualify you from the new position or your current role. Background results will be evaluated on a case-by-case basis.
EEO Statement
We are committed to providing equal employment opportunities to all persons regardless of race, color, ancestry, citizenship, national origin, religion, veteran status, disability, genetic characteristic or information, age, gender, sexual orientation, gender identity, marital status, family status, pregnancy, or other legally protected status (collectively, “protected statuses”). We do not tolerate unlawful discrimination in any employment decisions, including recruiting, hiring, compensation, promotion, benefits, discipline, termination, job assignments or training.
NOTE: Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.
Disclaimer
The above job definition information has been designed to indicate the general nature and level of work performed by employees within this classification. It is not designed to contain or be interpreted as a comprehensive inventory of all duties, responsibilities, and qualifications required of employees assigned to this job. Job duties and responsibilities are subject to change based on changing business needs and conditions.
Salary Range
Salary Min :
100440
Salary Max :
223680
This information reflects the anticipated base salary range for this position based on current national data. Minimums and maximums may vary based on location. Individual pay is based on skills, experience and other relevant factors.
This position is eligible for either short-term incentives or sales compensation. Director and VP positions also are eligible for long-term incentive. To learn more about our bonus structure, you can view additional information here. We're able to answer any additional questions you may have as you move through the selection process.
As part of our comprehensive benefits package, Lumen offers a broad range of Health, Life, Voluntary Lifestyle and other benefits and perks that enhance your physical, mental, emotional and financial wellbeing. You can learn more by clicking here.
Note: For union-represented postings, wage rates and ranges are governed by applicable collective bargaining agreement provisions.
Apply Now: click Apply Now
Show Less
Report",3.5,10000+ Employees,1968,Company - Public,Enterprise Software & Network Solutions,Information Technology,$10+ billion (USD)
Sr Data Engineer/data architect,$70.00 - $90.00 Per Hour (Employer est.),Devcare Solutions3.6 ★,"Columbus, OH","Role : Data Architect / Bigdata Architect / Hadoop / senior data engineer/ senior Bigdata
skills: oracle, SQL, Hadoop, bigdata , cloud era, Hive, data migration etc.
8+ years Data analysis/architecture experience in Waterfall and Agile Methodology in various domains (prefer Healthcare) in a data warehouse environment.
Good knowledge of relational database, Hadoop big data platform and tools, data vault and dimensional model design.
Strong SQL experience (prefer Oracle, Hive and Impala) in creating DDL’s and DML’s in Oracle, Hive and Impala (minimum of 8 years’ experience).
Experience in analysis, design, development, support and enhancements in data warehouse environment with Cloudera Bigdata Technologies (with a minimum of 8-9 years’ experience in Hadoop, MapReduce, Sqoop, PySpark, Spark, HDFS, Hive, Impala, Stream Sets, Kudu, Oozie, Hue, Kafka, Yarn, Python, Flume, Zookeeper, Sentry, Cloudera Navigator) along with Informatica.
Experience (minimum of 8 years) in working with Sqoop scripts, PySpark programs, HDFS commands, HDFS file formats (Parquet, Avro, ORC etc.), Stream Sets pipelines, jobs scheduling, hive/impala queries, Unix commands, scripting and shell scripting etc.
Experience in migrating data from relational database (prefer Oracle) to big data – Hadoop platform is a plus.
Experience eliciting, analyzing and documenting functional and non-functional requirements.
Ability to document business, functional and non-functional requirements, meeting minutes, and key decisions/actions.
Experience in identifying data anomalies.
Experience building data sets and familiarity with PHI and PII data.
Ability to establish priorities & follow through on projects, paying close attention to detail with minimal supervision.
Effective communication, presentation, & organizational skills.
Good experience in working with Visio, Excel, PowerPoint, Word, etc.
Effective team player in a fast paced and quick delivery environment.
Required Education: BS/BA degree or combination of education & experience.
DESIRED Skill Sets:
Demonstrate effective leadership, analytical and problem-solving skills
Required excellent written and oral communication skills with technical and business teams.
Ability to work independently, as well as part of a team
Stay abreast of current technologies in area of IT assigned
Establish facts and draw valid conclusions
Recognize patterns and opportunities for improvement throughout the entire organization
Ability to discern critical from minor problems and innovate new solutions
Skill
Data analysis/architecture experience in Waterfall and Agile Methodology in various domains (prefer Healthcare) in a data warehouse environment.
Good knowledge of relational database, Hadoop big data platform and tools, data vault and dimensional model design.
Strong SQL experience (prefer Oracle, Hive and Impala) in creating DDL’s and DML’s in Oracle, Hive and Impala
analysis, design, development, support and enhancements in data warehouse environment with Cloudera Bigdata Technologies, along with Informatica
Experience in migrating data from relational database (prefer Oracle) to big data – Hadoop platform is a plus.
Job Type: Contract
Salary: $70.00 - $90.00 per hour
Benefits:
Dental insurance
Health insurance
Vision insurance
Schedule:
8 hour shift
Monday to Friday
Experience:
total: 10 years (Required)
oracle: 4 years (Required)
SQL: 3 years (Required)
cloud era: 3 years (Required)
hadoop / Bigdata: 3 years (Required)
data architect: 1 year (Required)
Data warehouse: 1 year (Required)
Willingness to travel:
100% (Required)
Work Location: On the road
Speak with the employer
+91 6148083833
Show Less
Report",3.6,51 to 200 Employees,2005,Company - Private,Information Technology Support Services,Information Technology,Unknown / Non-Applicable
Senior Data Architect (Remote),$150K - $200K (Employer est.),KBX3.8 ★,"Wichita, KS","Your Job
KBX Technology Solutions, LLC, a provider of transportation technology to industry leaders, is seeking a highly skilled Data Architect to join our dynamic team. You will be responsible for designing and implementing scalable, secure, and efficient data architectures that leverage cloud-native technologies and principles. You will play a critical role in defining data strategies, ensuring data integrity, and enabling advanced analytics and insights in our cloud-native environment.
Our Team
This role will be part of our Platform Architecture team. The Platform is the core foundation that all of products are built. Software, Cloud, and Data architects are part of one team that develop the strategy and guidelines for all of core capabilities and products.
What You Will Do

Design and Develop Data Architecture: Collaborate with cross-functional teams to design and develop scalable and robust data architectures that align with cloud-native principles. Evaluate and select appropriate technologies, tools, and frameworks to support data storage, processing, integration, and analytics.
Cloud-Native Data Solutions: Architect, implement, and optimize data solutions leveraging cloud-native technologies such as Kubernetes, Kafka, microservices, containers, and managed data services. Ensure that data solutions are highly available, scalable, and cost-effective in a cloud environment.
Data Modeling and Governance: Define and enforce data modeling and governance best practices. Develop data models, data dictionaries, data catalog, and data integration patterns to ensure consistency, standardization, and quality of data across the organization. Establish data governance frameworks, policies, and procedures to promote data integrity and security.
Data Integration and ETL: Design and oversee implementation of data integration processes, including Extract, Transform, Load (ETL) workflows, APIs, data pipelines, and data streaming. Collaborate with data engineers and developers to ensure seamless and efficient data integration between various systems and applications.
Contribute & Share Knowledge: Participate in various transformation initiatives across KBX requiring data-centric architecture and enablement guidance and contribute to the data management & enablement community within Koch companies to drive strategy development, modeling, and knowledge systems for leveraging data.

Who You Are (Basic Qualifications)
Experience translating business strategy into value creation through data by creating roadmaps and the data strategy while collaborating and implementing with cross functional teams.
Experience in integration of complex, cross-corporate processes, and information strategies, and/or designing strategic metrics and scorecards.
Experience in Information Technology systems and ability to understand how data interacts with the enterprise digital foundation.
Experience in data lake and data warehouse technologies
Strong knowledge of cloud platforms such as AWS, Azure, or Google Cloud Platform (GCP).
Proficiency in data modeling, data integration, and data governance concepts and best practices.
Proficiency in SQL and NoSQL databases

What Will Put You Ahead
Experience in machine learning model development, training, and lifecycle management
Familiarity with data integration tools and ETL processes.
Experience with cloud-native data technologies, such as Kubernetes, Kafka, microservices, containers, and managed data services.
Solid understanding of data security, privacy, and compliance requirements.
Strong analytical and critical thinking skills.
Excellent communication and collaboration abilities.
Experience working within large organizations, and the ability to develop strong relationships required.
Experience with business intelligence and data analytics
For this role, we anticipate paying $150,000 - $200,000 per year. This role is eligible for variable pay, issued as a monetary bonus or in another form.
At Koch companies, we are entrepreneurs. This means we openly challenge the status quo, find new ways to create value and get rewarded for our individual contributions. Any compensation range provided for a role is an estimate determined by available market data. The actual amount may be higher or lower than the range provided considering each candidate's knowledge, skills, abilities, and geographic location. If you have questions, please speak to your recruiter about the flexibility and detail of our compensation philosophy.
Hiring Philosophy
All Koch companies value diversity of thought, perspectives, aptitudes, experiences, and backgrounds. We are Military Ready and Second Chance employers. Learn more about our hiring philosophy here.
Who We Are
As a Koch company, KBX provides the global transportation, logistics and technology solutions that help our customers deliver life's essentials to people all over the world. We develop and deploy cutting-edge technologies to deliver better solutions for increasingly complex supply chains. Our team of tenacious problem-solvers are driven to create real, long-term value for our customers.
At Koch, employees are empowered to do what they do best to make life better. Learn how our business philosophy helps employees unleash their potential while creating value for themselves and the company.
Our Benefits
Our goal is for each employee, and their families, to live fulfilling and healthy lives. We provide essential resources and support to build and maintain physical, financial, and emotional strength focusing on overall wellbeing so you can focus on what matters most. Our benefits plan includes medical, dental, vision, flexible spending and health savings accounts, life insurance, ADD, disability, retirement, paid vacation/time off, educational assistance, and may also include infertility assistance, paid parental leave and adoption assistance. Specific eligibility criteria is set by the applicable Summary Plan Description, policy or guideline and benefits may vary by geographic region. If you have questions on what benefits apply to you, please speak to your recruiter.
Equal Opportunities
Equal Opportunity Employer, including disability and protected veteran status. Except where prohibited by state law, all offers of employment are conditioned upon successfully passing a drug test. This employer uses E-Verify. Please visit the following website for additional information: http://www.kochcareers.com/doc/Everify.pdf
Apply Now: click Apply Now
Show Less
Report",3.8,10000+ Employees,1940,Company - Private,Energy & Utilities,"Energy, Mining & Utilities",$10+ billion (USD)
"Global Analytics, Data Solutions Architect & Ops Manager",$100K - $147K (Employer est.),Colgate-Palmolive4.2 ★,"Piscataway, NJ","No Relocation Assistance Offered
# 153255 - Piscataway, New Jersey, United States
Do you want to be part of a team that is building a future to smile about? What about having the opportunity to connect with others across the world, full of stimulating discussions, and making impactful contributions?

If this is how you see your career, Colgate is the place to be!

Our dependable household brands, dedicated employees, and sustainability commitments make us a company passionate about building a future to smile about for our employees, consumers, and surrounding communities. The pride in our brand fuels a workplace that encourages creative thinking, champions experimentation, and promotes authenticity which has contributed to our enduring success.

If you want to work for a company that lives by their values, then give your career a reason to smile...every single day.

We're looking for an experienced data and analytics professional to join our Global Analytics Data Foundation team. The Data Solutions Architect and Ops Manager will play a meaningful role in architecting and evolving the data foundation to fuel the next generation of commercial analytics platforms and data products at Colgate-Palmolive. The ideal candidate will be comfortable wearing multiple hats - architecting, developing and automating data transformation pipelines integrating global data sources in operationally efficient manner to enable strategic analytics capabilities in key business practices such as Revenue Growth Management and helping define and run a data ops approach for supporting our production data architecture once scaled.

At Colgate-Palmolive, we have a culture of strong global, cross-functional collaboration so as a Lead/Manager, you will partner with teams across the world, including Global IT, data science and advanced analytics within Global and Divisional Analytics teams as well as various business functions such as Customer Development, Finance, Marketing, etc. In addition to architecting robust data transformation pipelines, your responsibilities will include leading the support, maintenance and operational stability, timeliness and quality of data delivery in partnership with the Global IT data ops team. Lastly, as a lead technical member of the Global Analytics Data Foundation Team, there will be opportunities to recruit, mentor and lead junior staff and/or external support as we further build out our expertise and capabilities over time.

What you will do
Lead the development of the data foundation architecture that will deliver timely and accurate data to power strategic Pricing & RGM Analytics as well as other data products for use throughout the global commercial organization
Use SQL (dbt) and Python (Airflow) to architect production-quality code/pipelines to meet the data transformation needs of Global Analytics applications, data scientists, and other business partners
Translate business requirements and logic into well-documented data architecture and data models to drive clarity and efficiency for end users
Collaborate cross functionally to understand and identify data needs and opportunities to use data to drive business solutions
Support the use of analytics platforms and data science workflows, while identifying ways to strengthen and scale our data foundation
Partner with Global IT to align on data architecture, analytics tools, and other related data technologies (e.g. data quality tools, data catalog, etc.)

Required Qualifications
Bachelor's Degree in a quantitative field
8+ years of professional experience as “hands-on” lead data architect, data solutions architect or data engineer with track record of architecting and supporting a complex, global scale data architecture/implementation for BI and/or downstream analytics workloads
Proven experience of modern data warehouse design principles within leading cloud warehouse (Snowflake, Databricks, Bigquery) along with data architecture/modeling and data engineering best practices including CI/CD
Proven expertise in the use of complex SQL and/or Python to clean and integrate data from a variety of sources in reproducible, robust production transformation pipelines including complex data processing frameworks for handling different cadence of data delivery from various external and internal sources, incremental processing vs. full refreshes, etc.
Mentoring or resource management experience- either internal or consultants
A change maker - an ambitious, partnering data technologist that is motivated to solve business problems through thoughtful, fit-for-purpose data solutions

Preferred Qualifications
Master's degree in a relevant field or related subject area (Computer Science, Engineering, Business Management, etc.)
Experience working on a global team that spans many geographies/timezones
Demonstrated expertise with Git/GitHub, dbt Core/Cloud, and Airflow
Proven understanding and experience with syndicated sales (Nielsen, IRI) and/or retailer POS (point of sale) data sources for use within BI/analytics

#LI-Hybrid
Salary Range $100,000 - $147,000 USD

Pay is based on several non discriminatory factors including but not limited to experience, education, skills and office location. In addition to your salary, Colgate-Palmolive offers a performance based bonus and competitive benefits package.

Equal Opportunity Employer
Colgate is an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity, sexual orientation, national origin, ethnicity, age, disability, marital status, veteran status (United States positions), or any other characteristic protected by law.
Are you interested in working for Colgate-Palmolive? You can apply online and attach all relevant documents such as a cover letter and resume or CV. Applications received by e-mail are not considered in the selection process. Become part of our team. We look forward to your application.
Colgate-Palmolive is a leading global consumer products company, tightly focused on Oral Care, Personal Care, Home Care and Pet Nutrition. Colgate sells its products in over 200 countries and territories around the world under such internationally recognized brand names as Colgate, Palmolive, elmex, Tom’s of Maine, Sorriso, Speed Stick, Lady Speed Stick, Softsoap, Irish Spring, Protex, Sanex, Elta MD, PCA Skin, Ajax, Axion, Fabuloso, Soupline and Suavitel, as well as Hill’s Science Diet and Hill’s Prescription Diet.
For more information about Colgate’s global business, visit the Company’s web site at http://www.colgatepalmolive.com. To learn more about Colgate Bright Smiles, Bright Futures® oral health education program, please visit http://www.colgatebsbf.com. To learn more about Hill's and the Hill’s Food, Shelter & Love program please visit http://www.hillspet.com. To learn more about Tom’s of Maine please visit http://www.tomsofmaine.com.
Reasonable accommodation during the application process is available for persons with disabilities. Please contact Application_Accommodation@colpal.com with the subject ""Accommodation Request"" should you require accommodation.
Start your job application: click Apply Now
Show Less
Report",4.2,10000+ Employees,1806,Company - Public,Consumer Product Manufacturing,Manufacturing,$10+ billion (USD)
Sr. Data Architect,-1,Planet Fitness3.4 ★,Remote,"About Us:
Founded in 1992 in Dover, NH, Planet Fitness is one of the largest and fastest-growing franchisors and operators of fitness centers in the United States by number of members and locations. We have over 2,400+ stores in 50 states, the District of Columbia, Puerto Rico, Canada, Panama, Mexico, and Australia. More than 90% of Planet Fitness stores are owned and operated by independent business men and women.

At Planet Fitness, our unique mission has always been to enhance people’s lives by providing a high-quality fitness experience in a welcoming, non-intimidating environment. And we’re proud of the amazing Planet Fitness team that supports our clubs and team members. They are comprised of dynamic, dedicated, and talented individuals who represent our values of integrity, transparency, passion, respect, and excellence (while having fun!) in everything they do.

Joining the PF family means being part of a company that cares about bettering the health and wellbeing of our communities. It means being a part of a supportive, engaging workforce with an inclusive culture that values diversity and creates an environment where everyone can feel they belong. It means encouraging professional growth and development. It means making true, lasting connections with your co-workers with celebrations, team building activities and engaging corporate events! It means creating a positive impact in our local communities through our Judgement Free Generation® philanthropic initiative. It means being part of a brand that you can be proud of!

For the past 30 years, we’ve helped millions of people in their fitness journey and revolutionized the industry along the way. And we’re just getting started!
Overview:
The Sr. Data Architect will be responsible for creating and maintaining a scalable enterprise data architecture at Planet Fitness. In this role, you will facilitate the development of data modeling standards, guidelines, and techniques. You will collaborate across the data engineering, business intelligence engineering, and data governance teams to ensure data architectures are consistent and adhere to defined policies and standards. And as our Sr. Data Architect, you will also collaborate with the broader technology organization to implement data management best practices and improve data quality at the source of truth/system of record.

For team collaboration purposes, the ideal candidate currently resides in the CST or EST zones.
Responsibilities:
Create and maintain data architecture designs that support business and technical requirements for high-quality, performant data solutions.
Implement data modeling standards and ensure adherence within data management solutions.
Research and recommend tools and services to improve data management processes and support architectural standards and patterns.
Participate in data solution prototyping initiatives.
Create and maintain documentation related to data architecture standards, protocols, and frameworks.
Implement culture of continuous improvement of data architecture approaches to align to best practices and data management technology evolution.
Foster environment of continuous learning, maintain current knowledge of emerging technologies and industry trends, and present ideas for innovation.
Perform analytical exploration and examination of data from multiple data sources.
Participate in enforcing data quality and governance best practices in the data platform.
Work with a multi-disciplinary team consisting of data analysts, data engineers, developers and data consumers in an agile, fast-paced environment.
Work with and support a team that is globally located.
Participate in review processes that involve architecture, design and quality assurance to preemptively identify conflicts and ensure consistency of implementation.
Ensure strict adherence to documentation best practices and change control processes.
Perform other duties as assigned.
Qualifications:
Bachelor’s degree in Computer Science, Information Technology, Data Analytics, Information Systems or a related field
10+ years of direct experience in Big Data, Data Warehousing, Data Analytics, and/or Information Management related projects
6+ years of direct experience in cloud data solution architectures, design and development including ETL, data warehousing, data lakes, and big data
5+ years of experience using SQL including development of stored procedures, functions, triggers and views
5+ years of direct experience with one or more database/data warehouse technologies (e.g., Oracle, MSSQL, MySQL, PostgreSQL, Hadoop, Teradata, Redshift, Snowflake)
5+ years of direct experience working in a cloud environment such as AWS, Azure or GCP
Excellent critical thinking and problem-solving skills
Must be self-sufficient and proactive
Deep understanding of agile development methods including: core values, guiding principles, and key agile practices
A strong understanding of data mining, predictive modeling, and statistical analysis
Experience working in retail business (preferred)
Experience working in a franchised business (preferred)
Extremely detail-oriented, efficient, and organized with an exceptional ability to establish and balance multiple priorities and objectives
Excellent presentation and communication skills along with the ability to communicate effectively across all levels of the organization
Able to establish and maintain effective, collaborative work relationships with diverse individuals, internally and externally
Creative, progressive, thought leadership with the ability to influence at all levels of the organization
Dedicated learner with a natural curiosity for consistent growth
Exhibits comfort, ease, and flexibility working in an extremely fast-paced ever-changing, deadline-driven environment
Cooperative team player with an upbeat, positive, “can-do” attitude!
Perks:
Remote work allowed
Volunteer days off
Competitive salaries and comprehensive benefits package, including medical, pharmacy, dental and vision benefits
Generous vacation/holiday pay
401(k) Retirement
Employee Stock Purchase Program
Childcare reimbursement
Pet care reimbursement
Learning and development programs
Discount programs, including vacations, theme parks, shopping, meal delivery services & much more
Free Black Card membership and fun exercise incentives
Company-sponsored social events
Start your job application: click Apply Now
Show Less
Report",3.4,201 to 500 Employees,1992,Company - Public,Beauty & Wellness,Personal Consumer Services,$5 to $25 million (USD)
"Architect, Data Engineering",$90K - $238K (Employer est.),Pennymac3.0 ★,"Agoura Hills, CA","PENNYMAC:
Pennymac (NYSE: PFSI) is a specialty financial services firm with a comprehensive mortgage platform and integrated business focused on the production and servicing of U.S. mortgage loans and the management of investments related to the U.S. mortgage market.

At Pennymac, our people are the foundation of our success and at the heart of our dynamic work culture. Together, we work towards a unified goal of helping millions of Americans achieve aspirations of homeownership through the complete mortgage journey.
A Typical Day:
The Architect, Data Engineering will assess the needs and challenges of a client and formulate the technical roadmap and technology solution that will support their business strategies and goals. As the Architect, Data Engineering, you will develop and manage relationships with internal and external technology partners to deliver projects on time, on budget, and with quality.

The Architect, Data Engineering will:

Orchestrate the management of technology scope and risks
Initiate new, and improve existing, systems processes
Manage and deliver multiple streams of projects end-to-end
Develop artifacts following the SDLC in place, including technical specifications, design specifications, unit test cases, and unit test plan and code, using tools such as Python, Snowflake, AWS, Tableau, etc.
Participate/assist in development of deployment plans for the systems developed
Perform other related duties as required and assigned
Demonstrate behaviors which are aligned with the organization’s desired culture and values
What You’ll Bring:
Bachelor’s degree or equivalent work experience
7+ years experience working with IT leadership to create technical strategies and with senior IT groups in an advisory role
Expertise in multiple technologies (such as: AWS, Snowflake, Python, SQL, Tableau, Data Integration, API, Internal Web Design) across software engineering, security, data interchange, data management, etc.
Must have experience in developing Enterprise level applications using an SOA-based Architecture (Web Service, Windows Service etc.)
Experience with relational databases (MySQL, PostgreSQL, SQL Server, DynamoDB, Snowflake)
Must have worked in a multi-developer/multi-site environment with multi-site management experience
Why You Should Join:
As one of the top mortgage lenders in the country, Pennymac has helped over 4 million lifetime homeowners achieve and sustain their aspirations of home. Our vision is to be the most trusted partner for home. Together, 4,000 Pennymac team members across the country are guided by our core values: to be Accountable, Reliable and Ethical in all that we do.
Pennymac is committed to conducting a business that makes positive contributions and promotes long-term sustainable growth and to fostering an equitable and inclusive environment, where all employees and customers feel valued, respected and supported.

Benefits That Bring It Home: Whether you're looking for flexible benefits for today, setting up short-term goals for tomorrow, or planning for long-term success and retirement, Pennymac's benefits have you covered. Some key benefits include:
Comprehensive Medical, Dental, and Vision
Paid Time Off Programs including vacation, holidays, illness, and parental leave
Wellness Programs, Employee Recognition Programs, and onsite gyms and cafe style dining (select locations)
Retirement benefits, life insurance, 401k match, and tuition reimbursement
Philanthropy Programs including matching gifts, volunteer grants, charitable grants and corporate sponsorships

To learn more about our benefits visit: https://pennymacnews.page.link/benefits

Compensation: Individual salary may vary based on multiple factors including specific role, geographic location / market data, and skills and experience as defined below:
Lower in range - Building skills and experience in the role
Mid-range - Experience and skills align with proficiency in the role
Higher in range - Experience and skills add value above typical requirements of the role

Some roles may be eligible for performance-based compensation and/or stock-based incentives awarded to employees based on company and individual performance.

Salary: $90,000 - $237,500 Work Model: HYBRID
To apply to this job, click Apply Now
Show Less
Report",3.0,1001 to 5000 Employees,2008,Company - Public,Banking & Lending,Financial Services,$1 to $5 billion (USD)
Senior data engineer,$114K - $152K (Glassdoor est.),bp4.1 ★,"Houston, TX","Location
US: Houston - Westlake Campus
Travel required
Up to 10% travel should be expected with this role
Job category
Digital & technology
Relocation available
This role is eligible for relocation within country
Job type
Professionals
Job code
RQ26058419
Experience level
Intermediate

Job summary
Entity:
Innovation & Engineering

Job Family Group:
IT&S Group

Job Summary:
Part of a cross-disciplinary team, working closely with other data engineers, software engineers, data scientists, data managers and business partners.

Architects, designs, implements and maintains reliable and scalable data infrastructure to move, process and serve data.

Writes, deploys and maintains software to build, integrate, manage, maintain, and quality-assure data at bp.

Adheres to and advocates for software engineering best practices (e.g. technical design, technical design review, unit testing, monitoring & alerting, checking in code, code review, documentation),

Responsible for deploying secure and well-tested software that meets privacy and compliance requirements; develops, maintains and improves CI / CD pipeline,

Responsible for service reliability and following site-reliability engineering best practices: on-call rotations for services they maintain, responsible for defining and maintaining SLAs. Design, build, deploy and maintain infrastructure as code. Containerizes server deployments.

Actively contributes to improve developer velocity.

Mentors others.

Job Description:
BS degree in computer science or related field
Deep and hands-on experience (typically 5+ years) designing, planning, building, productionizing, maintaining and documenting reliable and scalable data infrastructure and data products in complex environments
Development experience in one or more object-oriented programming languages (e.g. Python, Scala, Java, C#)
Advanced database and SQL knowledge
Experience designing and implementing large-scale distributed data systems
Deep knowledge and hands-on experience in technologies across all data lifecycle stages
Strong stakeholder management and ability to lead initiatives through technical influence
Continuous learning and improvement mindset
Desired
No prior experience in the energy industry required
Why join us
At bp, we support our people to learn and grow in a diverse and exciting environment. We believe that our team is strengthened by diversity. We are committed to fostering an inclusive environment in which everyone is respected and treated fairly.
There are many aspects of our employees’ lives that are important, so we offer benefits to enable your work to fit with your life. These benefits can include flexible working options, a generous paid parental leave policy, and excellent retirement benefits, among others!
We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation.

Travel Requirement
Up to 10% travel should be expected with this role

Relocation Assistance:
This role is eligible for relocation within country

Remote Type:
This position is a hybrid of office/remote working

Skills:

Legal Disclaimer:
We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, sex, gender, gender expression, sexual orientation, age, marital status, neurodiversity/neurocognitive functioning, veteran status or disability status. Individuals with disabilities may request a reasonable accommodation related to bp’s recruiting process (e.g., accessing the job application, completing required assessments, participating in telephone screenings or interviews, etc.). If you would like to request an accommodation related to the recruitment process, please contact us to request accommodations.
If you are selected for a position and depending upon your role, your employment may be contingent upon adherence to local policy. This may include pre-placement drug screening, medical review of physical fitness for the role, and background checks.
Start your job application: click Apply Now
Show Less
Report",4.1,10000+ Employees,1908,Company - Public,Energy & Utilities,"Energy, Mining & Utilities",$10+ billion (USD)
IT Software Engineer - Remote,$91K - $134K (Employer est.),Mayo Clinic3.9 ★,"Rochester, MN","Why Mayo Clinic

Mayo Clinic has been ranked the #1 hospital in the nation by U.S. News & World Report, as well as #1 in more specialties than any other care provider. As we work together to put the needs of the patient first, we are also dedicated to our employees, investing in competitive compensation and comprehensive benefit plans – to take care of you and your family, now and in the future. And with continuing education and advancement opportunities at every turn, you can build a long, successful career with Mayo Clinic. You’ll thrive in an environment that supports innovation, is committed to ending racism and supporting diversity, equity and inclusion, and provides the resources you need to succeed.


Responsibilities
Mayo Clinic is seeking a Software Engineer to design and build back-end services that support our portfolio of data-centric clinical and analytic applications. These applications leverage cloud computing, big data, mobile, data science, data warehousing, machine learning using state of the art software development applications and frameworks. Our Software Engineers ensures that these cloud-based micro-services adhere to uptime and accuracy targets, are resilient, and scale as data volumes and traffic increase. They work closely with the data engineering, platform, and solutions teams to develop applications as required to benefit our practice and patients.
Works closely with the Product Owners, Product Managers, Architects to translate requirements into code. Developing services around data warehousing, big data, cloud computing, business intelligence, analytics and machine learning. Participate in DevOps, Agile, continuous development and integration frameworks. Programming in high-level languages such as Go, Python, Java etc. Work on deployment automation/configuration management with tools including but not limited to ADO, Puppet, Chef or Ansible or Azure Pipelines, CloudFormation, Terraform following a DevOps model. Ensure all appropriate documentation of processes and source code is created and maintained. Communicate effectively with peers, leaders, and customers throughout the organization. Participate in expert level troubleshooting and resolve problems through root cause analysis, data and system investigation. Continues to build knowledge of the organization, processes and customers. Performs a range of mainly straightforward assignments. Uses prescribed guidelines or policies to analyze and resolve problems. Receives a moderate level of guidance and direction.

Qualifications
Bachelor's Degree in Computer Science/Engineering or related field; Or an Associates’ degree in Computer Science/Engineering or related field with an additional 2 years of experience as described below.
Have working knowledge and experience of Software Engineering with a minimum of internships and a minimum of 1 yr. of experience, or 2yrs of experience coding applications or services in a high-level language (C, C++, Golang, Java, C# etc.).
Demonstrated problem solving and time management skills.
Possesses strong technical aptitude for designing and implementing software solutions.
Experience with modern application development frameworks
Knowledge of professional software engineering practices & best practices for the full software development life cycle, including coding standards, code reviews, source control management, build processes, testing, and operations.
Deep hands-on technical expertise, excellent verbal and written communication skills.
Experience with Agile software development techniques.
Preferred qualifications:
Ability to use a wide variety of open-source technologies and cloud-based services.
Experience with Google and Azure cloud environments
Experience in databases, analytics, big data systems or business intelligence products
Experience with building high-performance, highly available and scalable distributed systems.
Experience developing software for healthcare related industries.
Authorization to work and remain in the United States, without necessity for Mayo Clinic sponsorship now, or in the future (for example, be a U.S. Citizen, national, or permanent resident, refugee, or asylee). Also, Mayo Clinic does not participate in the F-1 STEM OPT extension program.

Exemption Status

Exempt

Compensation Detail

$90,937.60 - $133,681.60 / year

Benefits Eligible

Yes

Schedule

Full Time

Hours/Pay Period

80

Schedule Details

Monday - Friday

Weekend Schedule

N/A

International Assignment

No

Site Description
Just as our reputation has spread beyond our Minnesota roots, so have our locations. Today, our employees are located at our three major campuses in Phoenix/Scottsdale, Arizona, Jacksonville, Florida, Rochester, Minnesota, and at Mayo Clinic Health System campuses throughout Midwestern communities, and at our international locations. Each Mayo Clinic location is a special place where our employees thrive in both their work and personal lives. Learn more about what each unique Mayo Clinic campus has to offer, and where your best fit is.

Affirmative Action and Equal Opportunity Employer

As an Affirmative Action and Equal Opportunity Employer Mayo Clinic is committed to creating an inclusive environment that values the diversity of its employees and does not discriminate against any employee or candidate. Women, minorities, veterans, people from the LGBTQ communities and people with disabilities are strongly encouraged to apply to join our teams. Reasonable accommodations to access job openings or to apply for a job are available.


Recruiter

Miranda Grabner

Department Title

Information Technology
Show Less
Report",3.9,10000+ Employees,-1,Nonprofit Organization,Health Care Services & Hospitals,Healthcare,$10+ billion (USD)
"Portfolio Architect, Core Data Platforms",$168K - $281K (Employer est.),Macy’s3.4 ★,"Johns Creek, GA","Macy's is proudly America's Department Store. For more than 160 years, Macy's has served generations at every stage of their lives. Customers come to us for fashion, value, and celebration. Now is an exciting time to join Macy's, Inc. The face of retail is changing, and change requires innovation.

Macy's Technology provides modern tools, platforms, and services to all parts of the business. Our team supports millions of customers in connected commerce across the technology hub at Macy's. Join our team to help shape the future of e-commerce and set the pace in retail technology. Whether focused on store technology, supply chain tech, application security, merchandising systems, or the mobile app – you'll have opportunities to grow your career while finding meaningful ways to make a difference.

Job Overview:
The Portfolio Architect, Core Data Platforms defines a high-level portfolio architecture and advises on its implementation, drives alignment with enterprise standards while collaborating with Product leadership to drive out architecturally significant decisions and do just enough architecture to keep enabling development. This role will work closely with Domain and Product Architects to ensure alignment with the overall organization's vision. This role supports and facilitates architecture assurance activities and reimagines the future of technology for their product/platform portfolio. This role will be a critical contributor to Macy’s overall strategy for transactional and analytic data and help Macy’s on its journey in implementing our Google based data lake house.

Essential Functions:
Collaborate with the business (and respective domain/product inputs) to iteratively design an end-to-end technical solution for the portfolio
Identify required architectural significant decisions and associated risks
Collaboratively define key architectural components with domains/products through portfolio Agile events
Identify opportunities for reuse and extensibility balanced against complexity, cost and timelines
Collaborate with domains/products to identify non-functional requirements and provides appropriate guidance and leadership to help maintain quality solutions
Facilitate the resolution and escalation of technical impediments raised by domain/products through close collaboration with product counterparts
Manage, track, and refine functional and technical domain target state and roadmaps
Support and facilitate architecture governance activities and front-door management process
Manage evolution and advocacy for architecture function scope/model
Provide technical guidance to teams on architecture and design
Assess new opportunities and prioritize the roadmap

Qualifications and Competencies:
BA/BS in Computer Science, Information Technology, related field required, Master's Degree/MBA preferred.
We encourage candidates with either a bachelor’s degree or equivalent work experience in a related field to apply
15+ years of experience in software engineering, engineering management, and delivering large-scale transformation initiatives in retail required.
Executive leadership experience in managing multiple and large technology initiatives in distributed computing environments.
Expert architecture and design skills with proven track record of doing so at large enterprises.
Expert understanding of solution design and architecture standards.
Cross-disciplinary technical expertise with development, operations, security, quality assurance, architecture and more.
Experience in cloud technologies with a proven track record of migrating legacy on-premise applications into the cloud is required.
Experience driving data architecture utilizing cloud native technologies.
Experience constructing data mesh and advanced ingestion pipeline architectures.
Experience in Agile, especially managing or participating in multi-functional Agile teams within a large enterprise.
Excellent written and verbal communication skills, and an innate ability to easily communicate technical concepts
Articulate and persuasive leader who can serve as an effective member of the senior management team and who is able to communicate to a broad range of technical and non-technical staff.
Collaborates and engages others by gathering multiple views and being open to diverse perspectives.
Results and detail-oriented with excellent organizational skills while engaging and collaborative.
Able to think operationally and strategically, have strong analytical skills, and process disparate data and information into a cohesive and responsive action plan.
The ability to gain acceptance and win the confidence and cooperation of business partners is critical.
Able to juggle multiple priorities - can identify primary and secondary objectives, prioritize time, and communicate timeline to team members.
Ability and desire to take product/project ownership.
Ability to work a flexible schedule based on department and Company needs.
This position involves regular ambulating, sitting, hearing, and talking. May occasionally involve stooping, kneeling, or crouching. May involve close vision, color vision, depth perception, and focus adjustment. Involve use of hands and fingers for typing on keyboard and using a mouse. May be a need to move or lift items under 10 pounds.
TECH00
Apply Now: click Apply Now
Show Less
Report",3.4,10000+ Employees,1858,Company - Public,"Department, Clothing & Shoe Stores",Retail & Wholesale,$10+ billion (USD)
Senior Azure Data Architect,-1,Lighthouse MTG LLC,Rhode Island,"Azure Data Architect
Description:
Spyglass MTG (Microsoft Technology Group) is a Microsoft Gold Certified Partner. We hire people who are professional consultants in addition to being highly competent performers in their specific discipline. As a Consultant at Spyglass MTG you will be working on projects to develop Microsoft technology focused solutions for a variety of clients in industries such as Financial Services, Healthcare, Life Sciences, Manufacturing and Higher Education. Our office is in Lincoln, RI, however our clients are typically located in the Greater Boston and New England area. You will be working in a team environment that consists of Spyglass and Client members.
As an Azure Data Architect, you will join our increasingly growing and exciting Azure Data and Analytics practice. You will be required to apply enterprise principles, standards and practices serving as the conduit for influencing our clients Enterprise Data Architecture’s direction while optimizing solutions for them. You will evaluate business needs and objectives, current and future state and transform into Azure data solutions that meet performance, scalability, reliability, and security needs. You must also provide technical guidance and oversight to development team, mentor those in less senior positions and ensure a consistent state of excellence during and post-delivery of the solution. You will be integral to the design, development, and delivery of all modern data solutions on Azure for our clients.
Candidate Expectations:
Architect, Design and deploy architecture to support data transformation, data structures, metadata, dependency, and workload management.
Experience deploying modern data solutions leveraging components like Azure functions, Azure Data Factory, Data Flows, Azure Data Lake, Azure SQL, Azure Synapse, Streaming Analytics and more.
Provide oversight and guidance to data, BI and ML engineering teams. It is expected that you provide direct experience within these core areas.
Experience with one or more languages: Python & Pyspark, T-SQL, SparkR & R, Scala.
Experience with code deployment in Azure Databricks environment.
Familiarity with DevOps tools like Azure DevOps, Jenkins, Maven etc.
Experience working with Azure data platforms, integration techniques & self-service data preparation.
Assist business users on functional and data requirements to enhance data models and pipelines.
Experience in requirements analysis, design, and prototyping.
Basic Qualifications:
8+ years of relevant professional technology experience
5+ years of experience in a programming language like SQL, Python or Scala
5+ years of working experience with SQL Server, data warehousing and data analytics projects
5+ years of experience data engineering in cloud and on-prem environments
MUST HAVE Experience deploying Azure data solution with Azure Data Factory, Azure Synapse, Data Lake or other Azure data service.
MUST HAVE Experience architecting and Azure data solution with Azure Data Factory, Azure Synapse, Data Lake or other Azure data service.
MUST HAVE Experience data engineering Azure Data Factory or Azure Synapse
Experience building scalable data platforms.
Experience with Azure solutions and infrastructure
Minimum of a Bachelor’s degree in Computer Science, Computer Engineering, Software Design, Software Engineering, or a related field, or equivalent alternative education, skills, and/or practical experience
Preferred Qualifications:
MS Certified: Data Engineering Associate
MS Certified: Azure Solutions Architect Expert
3+ years of experience with Azure SQL, Azure Synapse, SQL DW or other Cloud Data Services.
2+ years of experience with version control and DevOps or DataOps.
5+ years programming with SQL, Python, Scala or R.
5+ years developing, deploying, and testing data pipelines in Azure or other cloud provider.
5+ years of data engineering with Hadoop, Spark, Databricks, SSIS or other data integration tool.
Master’s degree in Computer Science, Computer Engineering, Software Design, Software Engineering, or a related field, or equivalent alternative education, skills, and/or practical experience.
Benefits:
Medical, Vision and Dental Plans
Life and Disability Insurance
Open PTO Policy
Holiday PTO
Paid training certification
Bonus plan
401k
Flexible working arrangements
& more
All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, transgender status, national origin, citizenship, age, disability or protected veteran status.
Show Less
Report",-1,Unknown,-1,Company - Public,-1,-1,Unknown / Non-Applicable
Solution Architect,-1,Alcon3.7 ★,Remote,"At Alcon, we aspire to lead the world in innovating life-changing vision products because when people see brilliantly, they live brilliantly. As a global leader in eye care, we believe in innovating especially through cutting edge technology. We are on a journey to offer the widest array of eye care and eye health offerings with products that can treat the entire eye at each stage of life.

Alcon is looking to hire a Solution Architect for our Digital Health Team in Ft. Worth, TX. The Solution Architect will lead the technical vision and design decisions for building cutting-edge software to innovate our supply chain and enable a seamless experience for eye care professionals and patients.

Our Digital Health team plays an instrumental role in our push to improving customer experience with cutting-edge technology solutions. The team focuses on helping eye care professionals work effectively and improve patient outcomes by innovating the supply chain for critical eye care products and equipment (e.g., data ingestion and modeling techniques to forecast demand and automate decision making to reimagine inventory management).

You will be the visionary force behind our technical solutions and guide on technical design and requirements while working on exciting ideas with our product teams and leaders across the business. We are a new and fast-growing team which will give you the opportunity to shape our ways of working and culture - think start-up, but inside a global leader in eye care.

Key Responsibilities:
Design the overall technical architecture for Digital Heath team with the help of the Product Lead and Enterprise Architect
Constantly look for better ways of solving technical problems and designing the solution, not afraid to challenge the status quo
Develop proof-of-concept solutions, architectural diagrams, and specifications in response to business needs, and align technical stakeholders Responsible for technical design and infrastructure / environments strategy, including deployments, ensuring that these are kept in-line with an MVP mindset of ‘emerging architecture’
Define standards and guide technical teams on technology strategy related to coding quality standards, continuous integration, an automated deployment
Collaborate with Product Managers to align product roadmap with strengths and opportunities within the technical stack, and share responsibility for building reusable and scalable components
Participate in design and sprint reviews to identify and remove technical impediments, shape the trajectory of our products, and improve patient outcomes
Manage technical priorities within the backlog effectively to ensure projects are completed on time and within budget.
Responsible for creating and reviewing Application Architecture and provide technical leadership in the evaluation of Digital solutions to satisfy business and technical requirements.

Key Requirements/Minimum Qualifications
Bachelor’s Degree or Equivalent years of directly related experience (or high school +18 yrs; Assoc.+14 yrs; M.S.+7 yrs; PhD+6 yrs)
The ability to fluently read, write, understand, and communicate in English
10 Years of Relevant Experience
6 Years of Demonstrated Leadership
Work hours: 40
Travel Requirements: 10%
Relocation assistance: Yes
Sponsorship available: Yes

Preferred Experiences:
Developed solutions for healthcare and knowledge of healthcare interoperability standards like HL7, FHIR, and DICOM
Alcon is an Equal Opportunity Employer and participates in E-Verify. Alcon takes pride in maintaining a diverse environment and our policies are not to discriminate in recruitment, hiring, training, promotion or other employment practices for reasons of race, color, religion, gender, national origin, age, sexual orientation, gender identity, marital or veteran status, disability, or any other legally protected status. Alcon is also committed to working with and providing reasonable accommodation to individuals with disabilities. If, because of a medical condition or disability, you need a reasonable accommodation for any part of the application process, or in order to perform the essential functions of a position, please send an email to alcon.recruitment@alcon.com and let us know the nature of your request and your contact information.
To apply to this job, click Apply Now
Show Less
Report",3.7,10000+ Employees,1945,Company - Public,Biotech & Pharmaceuticals,Pharmaceutical & Biotechnology,$5 to $10 billion (USD)
Data Architect,$87K - $125K (Glassdoor est.),"ISF, Inc.4.1 ★","Tallahassee, FL","Solving the Future
ISF is a leader in government consulting, providing strategy, planning, modernization, process innovation, and technology solutions. We partner with our clients to address the real day-to-day challenges they face and achieve the outcomes they care about. ISF helps our clients do amazing things. ISF has been doing work with state government for over 42 years. We bring our expertise to solve the unique challenges of government. ISF focuses on the client’s vision, goals, and the results they need. Strategy, Process, and Technology are not just services, but a proven methodology we believe in. First, we define their long-term plans and the steps to achieve their vision. Then, we develop the processes to support those strategies. Finally, ISF develops, integrates, and implements the technologies that support those processes and provide the tools and data required to achieve success.
Overview:
ISF, Inc., welcomes applicants for our expert/lead technical Database Programmer role. This is a 1099 (Independent Contractor) position.

The Database Programmer is responsible for enterprise-wide data design, balancing optimization of data access with batch loading and resource utilization factors.
Other responsibilities include:
Being knowledgeable in most aspects of designing and constructing data architectures, operational data stores, and data marts.
Focusing on enterprise-wide data modeling and database design.
Defining data architecture standards, policies and procedures for the organization, structure, attributes and nomenclature of data elements, and applies accepted data content standards to technology projects.
Business analysis, data acquisition and access analysis and design.
Database Management Systems optimization, recovery strategy and load strategy design and implementation.
Define and plan database architectures for enterprise systems.
Works on multiple projects as a project leader or as the subject matter expert.
Works on projects/issues of high complexity that require in-depth knowledge across multiple technical areas and business segments.
Coaches and mentors more junior technical staff.
Experience:
A minimum of 7 years of experience with large and complex database management systems.
Education:
Bachelor’s or Master's Degree in Computer Science, Information Systems, or other related field. Or equivalent work experience.

We are committed to providing equal opportunity in all of our employment practices, including selection, hiring, promotion, transfer, and compensation, to all qualified applicants and employees without regard to age, race, color, sex, religion, national origin, marital status, gender identity or expression, or sexual orientation, disability or any other protected status in accordance with the requirements of all federal, state and local laws.
ZroPqxIMFj
Show Less
Report",4.1,51 to 200 Employees,1979,Company - Private,Information Technology Support Services,Information Technology,$5 to $25 million (USD)
Sr Data Engineer,$112K - $152K (Glassdoor est.),Voloridge Investment Management4.7 ★,"Jupiter, FL","At Voloridge Investment Management our quantitative systems are deeply dependent on vast quantities of data. The Senior Data Engineer must understand the many different and evolving use cases for data at Voloridge and design systems that supply high-performance datasets for advanced analytics. In this role the Sr. Data Engineer / Architect will provide mentorship and impart experience to the data engineering team.
Summary of Job Functions
Collaborate effectively with Stakeholders, Project Managers, Software Engineers, Data Analysts, QA Analysts, DBAs, and Data Engineers
Build and maintain data pipelines based on functional and non-functional requirements
Proactively seek out information and overcome obstacles to deliver projects efficiently
Ensure that data pipelines incorporate best practices related to performance, scaling, extensibility, fault tolerance, instrumentation, and maintainability
Ensure that data pipelines are kept simple and not overly engineered
Produce and maintain design and operational documentation
Analyze complex data problems and engineer elegant solutions
Stay abreast of emerging technologies and make relevant recommendations
Upgrade existing data models and pipelines leveraging newer features and techniques
Work in a Kanban environment
Mentor less experienced data engineers
Participate in engineering standards and best practices evolution
Participate in an on-call rotation
Lead investigations to troubleshoot pipeline issues
Minimum Requirements
10+ years with hands-on data engineering and deep knowledge of data architecture fundamentals including:
Extensive experience building ETL/ELT pipelines from a variety of data sources
Broad experience with SQL Server 2019+, including advanced SQL Server features such as Table Partitioning, Columnstore
Deep knowledge and measurable experience in performance tuning TSQL, execution plan analysis blocking/deadlock analysis and index optimization
Extensive experience using SSMS to create and maintain SQL Server tables, views, functions, stored procedures, and user-defined table types
Comprehensive experience with data modeling indexes, Temporal tables, CLR, and Service Broker
Deep understanding of the development of data pipelines with either SSIS or Python and building data pipelines using multiple external data sources and transport mechanisms
Strong initiative, collaboration, accountability, impartiality, and communication
Strong analytical skills, a real passion for working with data and strong interest in solving data problems
Strong track record for judging core requirements and meeting deadlines
Experience managing master data
Experience writing C#, PowerShell, and Python
Experience with Git source control integration with SSMS
Experience working in a Kanban SDLC and a strong understanding of traditional Kanban SDLC workflows
Experience with deploying changes through segregated Development, QA, UAT and Production SDLC stages
Experience owning mission-critical processes
Bachelor’s degree in Computer Science, Information Systems, or related disciplines
Ability to work onsite in our Jupiter, FL office
Preferred Skills and Previous Experience
Python programming using libraries such as Pandas, Numpy, csv, Traceback, JSON, PyODBC, Math
Experience with source code branching and pull requests / code reviews
Experience with AWS
Experience working with trading / financial / investment / accounting data
Experience with tools such as Red Gate, Grafana, OpsGenie and JAMS
Experience with MPP databases such as Greenplum
MS/PhD in Computer Science, Information Systems, or related disciplines
Compensation and Benefits
Highly competitive base salary
Profit sharing bonus
Health, dental, vision, life, and disability insurance
401K
Additional Information
Voloridge Investment Management is an SEC registered investment advisor. A private investment company founded in 2009, our mission is to deliver superior risk-adjusted returns for qualified investors, using advanced proprietary modeling technology, conservative investment tactics and sophisticated risk management.
Voloridge Investment Management is an Equal Opportunity Employer. All qualified applicants are encouraged to apply and will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, protected veteran status, or any other legally protected characteristic or status.
Show Less
Report",4.7,51 to 200 Employees,2009,Company - Private,Investment & Asset Management,Financial Services,Unknown / Non-Applicable
"Senior Data Architect, Data Engineering",$140K - $206K (Employer est.),Chipotle Mexican Grill3.4 ★,"Newport Beach, CA","Senior Data Architect, Data Engineering
Description

CULTIVATE A BETTER WORLD
Food served fast does not have to be a typical fast-food experience. Chipotle has always done things differently, both in and out of our restaurants. We are changing the face of fast food, starting conversations, and directly supporting efforts to shift the future of farming and food. We hope you will join us as we continue to learn, evolve, and shape what comes next on our mission to make better food accessible to everyone.

THE OPPORTUNITY
As the Senior Data Architect, you will play a critical role in making sure our Data and Analytics data strategy is envisioned, designed, developed and implemented across the enterprise to support our strategic business goals. They are responsible for definition, creation and maintenance of architecture artifacts of enterprise data solutions along with definition of Data Architecture processes across Data & Analytics. The Sr. Data Architect also brings extreme passion and advocacy to building a culture of data driven decision making through outstanding information management solutions. The Data Architect must be able to think holistically across the organization. The Data Architect is expected to understand current and future reporting and warehousing technologies in order to architect forward-looking solutions for Enterprise Data and advanced analytics.

WHAT YOU’LL DO
Design data solutions that support Chipotle’s reporting and analytic needs. Work towards an information/data strategy that maximizes the value of data as an asset.
Leading and providing practical experience in the maturity of cloud-native data services such as Azure, Snowflake, DBT
Responsible for definition, creation and maintenance of architecture artifacts of Enterprise Data solutions including architecture, data flow diagrams, Conceptual/Logical Data models, data dictionaries, and database design
Provide leadership, oversight, and development execution of data architecture design and associated delivery
Provide training and coaching to other team members on data architecture standards and best practices.
Collaborate closely with Enterprise Architects and Technical Review Board to assure all systems and changes to the data environments are in line with the long-term IT strategy and architectural standards
Investigating & analyzing data sources to identify relevant information for inclusion in our data solutions
Own Data solutions vendor relationships for new technology

WHAT YOU’LL BRING TO THE TABLE
Have a Bachelor’s degree in Computer Science, Engineering, Math, Finance, Statistics or related discipline, or an equivalent in education and experience.
5-8 years in-depth, hands-on knowledge and execution of foundational data architectures such as data warehouses, data modeling, data mining, ETL, and in-memory models
Proficient knowledge in modern data architecture that supports advanced analytics including Snowflake, Azure, etc.
Ability to thrive in a fast-paced environment, responding quickly to oversight and following instruction closely, while anticipating needs and developing efficiencies on repeat tasks.
Excellent problem-solving, critical thinking and analytics skill with the ability to work in a cross-functional team.
Quick self-motivated learner who can initiate and drive new data solutions and patterns in anticipation of management and client goals and objectives with little or no supervision
Self-directed and comfortable supporting the data needs of multiple teams, systems and products.
Must be able to adapt to change in direction and priorities in a project and deadline-oriented environment.
Expert knowledge of data modeling, documentation and governance tools and techniques.
Demonstrated human relation skills to effectively interact with peers, subordinates, internal and external customers and vendors
Proven ability to influence and empower individuals and teams
Sophisticated oral and written communication skills and experience presenting to different levels of leadership
Sophisticated analytical skills related to cost / benefit analysis of large dollar hardware and software implementations
Experience working in an Agile/Scrum environment

WHO WE ARE
Chipotle Mexican Grill, Inc. (NYSE: CMG) is cultivating a better world by serving responsibly sourced, classically cooked, real food with wholesome ingredients without artificial colors, flavors or preservatives. Chipotle has over 3,000 restaurants in the United States, Canada, the United Kingdom, France and Germany and is the only restaurant company of its size that owns and operates all its restaurants. Chipotle is ranked on the Fortune 500 and is recognized on the 2022 list for Fortune's Most Admired Companies. With over 100,000 employees passionate about providing a great guest experience, Chipotle is a longtime leader and innovator in the food industry. Chipotle is committed to making its food more accessible to everyone while continuing to be a brand with a demonstrated purpose as it leads the way in digital, technology and sustainable business practices. For more information or to place an order online, visit www.chipotle.com

PAY TRANSPARENCY
A reasonable estimate of the current base salary range for this position is $140,000 to $206,000. You are also eligible for annual cash bonuses and equity awards based upon performance and other factors. Actual compensation offered may vary depending on skill level, experience, and/or education. Chipotle offers a competitive total rewards package, which includes medical, dental, and vision insurance, 401k, sick leave, vacation time, and much more. Visit https://jobs.chipotle.com/benefits

Chipotle Mexican Grill is an equal opportunity employer that values diversity at all levels. As a people-first company rooted in values, our purpose extends beyond serving nutritious food using real ingredients. It means hiring world-class individuals and fostering a culture that champions diversity, ensures equity, and celebrates inclusion. All qualified applicants, regardless of personal characteristics, are encouraged to apply.

Qualified applicants with disabilities may be entitled to reasonable accommodation under the terms of the Americans with Disabilities Act and/or certain state or local laws. Please contact ADAaccommodations@chipotle.com if you need an accommodation due to a disability to complete an application, job interview, and/or to otherwise participate in the hiring process. This email does not respond to non-accommodations related requests.

Primary Location: CA-Newport Beach-(-9998 - 610 Newport Office-(09998)
Work Locations: 9998 - 610 Newport Office-(09998) 610 Newport Center Drive Newport Beach 92660
Job: Information Technology
Job Posting: Jul 14, 2023, 3:26:14 PM
Job Number: 23020721
Apply Now: click Apply Now
Show Less
Report",3.4,10000+ Employees,1993,Company - Public,Restaurants & Cafes,Restaurants & Food Service,$5 to $10 billion (USD)
Sr. Systems Administrator,$100K - $145K (Employer est.),Set Solutions4.6 ★,"Fort Worth, TX","Set Solutions is working exclusively with a client hiring for a Sr. Systems Engineer in the Dallas Fort Worth area. The role is full time hybrid with two days a week on site.
Job Description:
Design and implement information systems to support the enterprise infrastructure of an organization by ensuring that all systems are working at optimal levels and supporting development of new technologies and system requirements
Vet emerging technologies and act as a subject matter expert to determine technology and infrastructure standards cross functionally
Define and document target architecture models, processes and policies related to core infrastructure
Anticipate growth and ensure scalability of the infrastructure to include servers, storage, and infrastructure applications
Applies deep technical expertise and problem-solving methodologies focused on analyzing complex data and systems, anticipating issues, and finding ways to mitigate risk
Works with other platforms to architect and implement changes required to resolve issues and modernize the organization and its technology processes
Responsible for infrastructure engineering in accordance with business requirements
Maintain and support the Azure, and on prem servers, networks, and virtual environment
Participate in the design and implementation of the infrastructure security architecture
Collaborate with the global IT team to monitor and maintain the corporate infrastructure
Drives thought leadership within the product line
Executes work according to compliance standards, risk and security, and business objectives
Advises junior engineers and technologists
Requirements:
8+ years of IT experience
4 year college degree mandatory
Strong experience with Azure infrastructure and migrations
Experience with MS Windows Server (DNS, Administration, Clustering, IIS, Group Policy), VMware, Nutanix, Cisco routers, switches, firewalls, and Active Directory
Knowledge of Citrix or VMware on premise cloud solutions
Experience with Office 365 support and architecture in a hybrid environment
Dell EMC data storage experience
Must have excellent communication skills both written and verbal with a high level of professionalism
Ability for work on multiple priorities simultaneously
Must be a self-starter and highly motivated
Job Type: Full-time
Pay: $100,000.00 - $145,000.00 per year
Benefits:
401(k)
Dental insurance
Flexible schedule
Health insurance
Paid time off
Tuition reimbursement
Vision insurance
Compensation package:
Yearly pay
Experience level:
8 years
Schedule:
Monday to Friday
Ability to commute/relocate:
Fort Worth, TX 76102: Reliably commute or planning to relocate before starting work (Required)
Education:
Bachelor's (Required)
Experience:
VMWare: 2 years (Preferred)
Active Directory: 7 years (Required)
Work Location: Hybrid remote in Fort Worth, TX 76102
Show Less
Report",4.6,51 to 200 Employees,-1,Company - Private,Enterprise Software & Network Solutions,Information Technology,$5 to $25 million (USD)
Data Engineer,$70.00 Per Hour (Employer est.),Tellus solutions3.7 ★,"Sunnyvale, CA","Job Description:
The role will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams.
The ideal candidate is an experienced data pipeline builder and data wrangler who enjoy optimizing data systems and building them from the ground up.
The Data Engineer will support our software developers, database architects, and data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple teams, systems and products.
The right candidate will be excited by the prospect of optimizing or even re-designing our data architecture to support our next generation of products and data initiatives.
Responsibilities:
Create and maintain optimal data pipeline architecture for data intensive applications.
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using Azure SQL, Cosmo DB, Databricks and other legacy databases.
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.
Keep our data separated and secure across national boundaries through multiple data centers and Azure regions.
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
Work with data and analytics experts to strive for greater functionality in our data systems.
Qualifications for Data Engineer
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Extensive Experience on Databricks on Azure Cloud platform, deep understanding on Delta lake, Lake House Architecture.
Programming experience on Python, Shell scripting, PySpark, and other data programming language.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with Data Visualization Dashboard, Metrics and etc.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
Skills:
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Working knowledge of message queuing, stream processing, and highly scalable 'big data' data stores.
Familiar with Deployment tool like Docker and building CI/CD pipelines.
Experience supporting and working with cross-functional teams in a dynamic environment.
8+ years' experience in software development, Data engineering, and
Bachelor's degree in computer science, Statistics, Informatics, Information Systems or another quantitative field. Postgraduate/master's degree is preferred.
Experience in Machine Learning and Data Modeling is a plus.
Job Type: Contract
Salary: Up to $70.00 per hour
Benefits:
401(k)
Dental insurance
Health insurance
Schedule:
8 hour shift
Day shift
Application Question(s):
Only US Citizen and Green Card Holder
Experience:
Python, Shell scripting, PySpark: 5 years (Required)
Azure SQL: 5 years (Required)
Work Location: On the road
Show Less
Report",3.7,51 to 200 Employees,2006,Company - Private,Information Technology Support Services,Information Technology,$5 to $25 million (USD)
"Software Engineer, Data Products",$119K - $163K (Glassdoor est.),LaunchDarkly4.1 ★,"Oakland, CA","Please note, before progressing to our application, this position is based in the San Francisco Bay Area and not suitable for remote candidates.
About the Job:
We are looking for exceptional Software Engineers to make a profound impact on how data products will be integrated into companies' software in the future. We are integrating data into everything LaunchDarkly offers on top of our unrivaled feature management platform.
As a Data Products - Software Engineer, you will help us architect and write fast, reliable, and scalable data processing tools to process data from our thousands of customers and their hundreds of millions of users around the world. We're looking for someone who knows what it takes to deliver value to customers and takes pride in the quality of their work.
The primary technologies we use daily include Golang, Scala, Kinesis, and Flink. If working as a part of such a poly-functional team to bring to change how experimentation is done forever appeals to you then come join the Experimentation team at LaunchDarkly.
Responsibilities:
Build and expand our data platform and services
Help us identify the best technologies for our evolving data needs
Collaborate with product team to spec and deliver user-facing features
Monitor and improve data pipeline performance
Actively participate in code reviews
Improve engineering standards, tooling, and processes
Qualifications:
Proven experience and fluency in a JVM or functional language
Experience building data platforms (e.g. using Flink, Kafka, DataFlow, Hadoop, Spark)
Strong communication skills, a positive attitude, and empathy
You write code that can be easily understood by others, with an eye towards maintainability
You hold yourself and others to a high bar when working with production systems
You value high code quality, automated testing, and other engineering best practices
Pay:
Target pay range for a Level P3 in San Francisco/Bay Area: $144,000 - $169,000*
Restricted Stock Units (RSUs), health, vision, and dental insurance, and mental health benefits in addition to salary.
LaunchDarkly operates from a place of high trust and transparency; we are happy to state the pay range for our open roles to best align with your needs. Exact compensation may vary based on skills, experience, degree level, and location.
About LaunchDarkly:
LaunchDarkly is a Feature Management Platform that serves trillions of feature flags daily to help software teams build better software, faster. Feature flagging is an industry standard methodology of wrapping a new or risky section of code or infrastructure change with a flag. Each flag can easily be turned off independent of code deployment (aka ""dark launching""). LaunchDarkly has SDKs for all major web and mobile platforms. We are building a diverse team so that we can offer robust products and services. Our team culture is dynamic, friendly, and supportive. Our headquarters are in Oakland.
At LaunchDarkly, we believe in the power of teams. We're building a team that is humble, open, collaborative, respectful and kind. We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, gender identity, sexual orientation, age, marital status, veteran status, or disability status.
One of our company values is 'Widen the Circle'. Which means we seek out diversity of perspectives to get better results. We understand everyone has their own unique talents and experiences. We encourage you to apply to this role even if you don’t think you meet 100% of the qualifications outlined above. We can find out together if it's the right match for your skillset.
We've partnered with KeyValues to help demonstrate the amazing culture we've built here at LaunchDarkly, find more info at https://www.keyvalues.com/launchdarkly.
LaunchDarkly is also committed to giving back to our community and is a part of Pledge 1%, an organization that helps companies make this a priority. Through this initiative and its charitable arm, the LaunchDarkly Foundation, the company is committed to such causes as supporting education for the underserved, homelessness relief and moving towards having a net-zero carbon footprint. You can find more about the LaunchDarkly Foundation and the organizations we serve at https://launchdarkly.com/foundation/.
Do you need a disability accommodation?
Fill out this accommodations request form and someone from our People Operations team will contact you for assistance.
Show Less
Report",4.1,501 to 1000 Employees,2014,Company - Private,Enterprise Software & Network Solutions,Information Technology,$100 to $500 million (USD)
Data Domain Architect Senior Associate - Data Pipeline Streaming,$138K - $200K (Employer est.),JPMorgan Chase & Co4.0 ★,"Jersey City, NJ","JOB DESCRIPTION

This position will be a key role within the Data Pipeline (DPL) Streaming product office. Under limited supervision, this role will be responsible for leading both product development and customer engagement. From initial meetings and demos to leading proof-of-concept evaluations, you will be the customers trusted advisor on all things Streaming related. Working in conjunction with the engagement analyst(s) and product team, you will be primarily responsible for ensuring that clients technical criteria are defined, documented and have the appropriate validation events scoped and executed to ensure a technical “win” and customer “adoption”. Duties include but not limited to are:
Support the DPL Streaming Product office in the overall engagement process
Offer expert advice on use cases and solution scope, from initial planning, implementation to resolution of technical issues
Effective in assessing business problems and recommending solutions
Lead meetings and/or workshops with potential clients to determine the technical and business requirements and ensure that all necessary information is collated prior to producing a solution
Support the Streaming team with overall customer requirements - translating customer requirements into internal facing documentation for purpose of definition and estimations of requirements
Technical Architecture to solution of required feature
Build productive relationships internally and externally, credible with both business and technical functions
Manage Product Engagement Analysts
Qualifications
3+ years experience and supporting a technical product
Ability to think strategically and work in a global environment
Ability to solution and specification of required technical features
AWS cloud proficient, preferably with related certifications.
Diligent and efficient in execution even under tight time constraints; consistently overcomes and helps others overcome obstacles to completion
High proficiency in Excel, Word, and PowerPoint
Able to change tone of situations positively; drives change and always considers diverse perspectives to get the best outcome
Ability to thrive in a fast-paced, collaborative and cross-functional environment
Excellent written and verbal communication skills: able to present facts, thoughts, and ideas in a clear, concise, and convincing manner to senior stakeholders
Experience working in agile/scrum teams preferred
Exhibit an organized and systematic approach to problem solving, understanding of both design thinking and systems thinking
Very organized and able to work on multiple projects concurrently
Excellent interpersonal and presentation skills; both face to face and remotely
Strong customer facing and presentation skills
Minimum BS or equivalent level of education/experience required
JPMorgan Chase is an Equal Opportunity and Affirmative Action Employer, M/F/D/V.
ABOUT US

Chase is a leading financial services firm, helping nearly half of America’s households and small businesses achieve their financial goals through a broad range of financial products. Our mission is to create engaged, lifelong relationships and put our customers at the heart of everything we do. We also help small businesses, nonprofits and cities grow, delivering solutions to solve all their financial needs.
We recognize that our people are our strength and the diverse talents they bring to our global workforce are directly linked to our success. We are an equal opportunity employer and place a high value on diversity and inclusion at our company. We do not discriminate on the basis of any protected attribute, including race, religion, color, national origin, gender, sexual orientation, gender identity, gender expression, age, marital or veteran status, pregnancy or disability, or any other basis protected under applicable law. In accordance with applicable law, we make reasonable accommodations for applicants’ and employees’ religious practices and beliefs, as well as any mental health or physical disability needs.

The health and safety of our colleagues, candidates, clients and communities has been a top priority in light of the COVID-19 pandemic. JPMorgan Chase was awarded the “WELL Health-Safety Rating” for all of our 6,200 locations globally based on our operational policies, maintenance protocols, stakeholder engagement and emergency plans to address a post-COVID-19 environment.
As a part of our commitment to health and safety, we have implemented various COVID-related health and safety requirements for our workforce. Employees are expected to follow the Firm’s current COVID-19 or other infectious disease health and safety requirements, including local requirements. Requirements include sharing information including your vaccine card in the firm’s vaccine record tool, and may include mask wearing. Requirements may change in the future with the evolving public health landscape. JPMorgan Chase will consider accommodation requests as required by applicable law.
We offer a competitive total rewards package including base salary determined based on the role, experience, skill set, and location. For those in eligible roles, discretionary incentive compensation which may be awarded in recognition of individual achievements and contributions. We also offer a range of benefits and programs to meet employee needs, based on eligibility. These benefits include comprehensive health care coverage, on-site health and wellness centers, a retirement savings plan, backup childcare, tuition reimbursement, mental health support, financial coaching and more. Additional details about total compensation and benefits will be provided during the hiring process.
Equal Opportunity Employer/Disability/Veterans



ABOUT THE TEAM

Our Consumer & Community Banking division serves our Chase customers through a range of financial services, including personal banking, credit cards, mortgages, auto financing, investment advice, small business loans and payment processing. We’re proud to lead the U.S. in credit card sales and deposit growth and have the most-used digital solutions – all while ranking first in customer satisfaction.
Apply Now: click Apply Now
Show Less
Report",4.0,10000+ Employees,1799,Company - Public,Banking & Lending,Financial Services,$10+ billion (USD)
Azure - Senior Data Engineering Architect,$108K - $210K (Employer est.),Publicis Sapient3.8 ★,"Arlington, TX","Azure - Senior Data Engineering Architect
Full-time
Company Description
Publicis Sapient is a digital transformation partner helping established organizations get to their future, digitally-enabled state, both in the way they work and the way they serve their customers. We help unlock value through a start-up mindset and modern methods, fusing strategy, consulting and customer experience with agile engineering and problem-solving creativity. As digital pioneers with 20,000 people and 53 offices around the globe, our experience spanning technology, data sciences, consulting and customer obsession – combined with our culture of curiosity and relentlessness – enables us to accelerate our clients’ businesses through designing the products and services their customers truly value. Publicis Sapient is the digital business transformation hub of Publicis Groupe. For more information, visit publicissapient.com.
Job Description
Publicis Sapient is looking for a hands-on Senior Manager to join our team of bright thinkers and doers. You’ll use your problem-solving creativity to design, architect, and develop high-end technology solutions that solve our clients’ most complex and challenging problems across different industries. We are on a mission to transform the world, and you will be instrumental in shaping how we do it with your ideas, thoughts, and solutions.
Your impact:
Develop, design, and implement consumer data models based on business requirements and objectives.
Collaborate with various stakeholders, such as business analysts, architects, and developers, to understand data needs and convert these needs into effective data models.
Evaluate and optimize existing data models for improvement.
Ensure that data models adhere to industry best practices, standards, and guidelines.
Conduct data profiling and analysis to identify data quality issues and propose data cleansing and remediation strategies.
Collaborate with database administrators to optimize database performance and maintain data integrity.
Work closely with ETL developers to integrate data models into data integration processes.
Stay updated on the latest trends and technologies in data modeling, cloud computing, and database design.
Mentor, support and manage team members
Qualifications
Your Skills and Experience:
Demonstrable experience in enterprise level data platforms involving implementation of end-to-end data pipelines
Hands-on experience with at least one of the leading public cloud data platforms (Amazon Web Services, Azure or Google Cloud)
Experience with column-oriented database technologies (e.g., Big Query, Redshift, Vertica), NoSQL database technologies (e.g., DynamoDB, BigTable, Cosmos DB, etc.) and traditional database systems (e.g., SQL Server, Oracle, MySQL)
Experience in architecting data pipelines and solutions for both streaming and batch integrations using tools/frameworks like Glue ETL, Lambda, Google Cloud DataFlow, Azure Data Factory, Spark, Spark Streaming, etc.
Metadata definition and management via data catalogs, service catalogs, and stewardship tools such as OpenMetadata, DataHub, Alation, AWS Glue Catalog, Google Data Catalog.
Test plan creation and test programming using automated testing frameworks, data validation and quality frameworks, and data lineage frameworks
Data modeling, querying, and optimization for relational, NoSQL, timeseries, graph databases, data warehouses and data lakes
Data processing programming using SQL, DBT, Python, and similar tools
Logical programming in Python, Spark, PySpark, Java, Javascript, and/or Scala
Cloud-native data platform design with a focus on streaming and event-driven architectures
Participate in integrated validation and analysis sessions of components and subsystems on production servers
Data ingest, validation, and enrichment pipeline design and implementation
SDLC optimization across workstreams within a solution
Bachelor’s degree in Computer Science, Engineering, or related field
Additional Information
Pay Range:$108,000 -$210,000
Benefits of Working Here:
Flexible vacation policy; time is not limited, allocated, or accrued
16 paid holidays throughout the year
Generous parental leave and new parent transition program
Tuition reimbursement
Corporate gift matching program
As part of our dedication to an inclusive and diverse workforce, Publicis Sapient is committed to Equal Employment Opportunity without regard for race, color, national origin, ethnicity, gender, protected veteran status, disability, sexual orientation, gender identity, or religion. We are also committed to providing reasonable accommodations for qualified individuals with disabilities and disabled veterans in our job application procedures. If you need assistance or an accommodation due to a disability, you may contact us at [email protected] or you may call us at +1-617-621-0200.
To apply to this job, click Apply Now
Show Less
Report",3.8,10000+ Employees,1990,Company - Public,Business Consulting,Management & Consulting,Unknown / Non-Applicable
"Senior Solution Architect, Data & Analytics - Remote",$128K - $200K (Employer est.),EPAM Systems4.1 ★,Remote,"Are you an influential Architecture leader with a passion for leading strategic initiatives that make a huge impact? We are hiring a Senior Data Solution Architect, who will work alongside a dynamic team to identify complex business problems and create solution-oriented strategies for some of the most recognized brands. Apply now to connect with a recruiter about this influential role at EPAM!

Req.#180339287

RESPONSIBILITIES
Provide support in the solution decision making process as a trusted technical advisor
Design, implement, and deploy data platforms at scale in public and private cloud enviroments
Guide clients on establishing a data practice on an enterprise level by improving their data strategy, data governance, data architecture and data quality management
Drive and execute the technical stream of data strategy engagements by conducting customer workshops, discovery sessions solution and presentations
Educate clients on modern technologies, architectures and approaches for data & analytics by explaining their value for business
Define business and development processes as well as platform + tool usage for data acquisition, storage, transformation, and analysis
Communicate different solution and technology options, while articulating short and long-term consequences & their impact on business
Develop roadmaps and implementation strategy around data & analytics initiatives
Review and audit existing solutions, designs and system architectures while creating architecture documentation & presentations
Implement scalable data platform architecture
Discuss proposed solution to multiple level of stakeholders from C-level to engineering teams

REQUIREMENTS
Extensive experience within Solution Architecture with a strong background in data & analytics
Highly Skilled with designing, developing and maintaining enterprise scale data platforms
History working with with big data technologies and frameworks such as Databricks, Snowflake, Apache Spark, Kafka, Apache Flink, AWS Glue + Redshift, GCP Dataflow + BigQuery, Azure Data Factory + Synapse
Expert within Big Data solutions developed in large cloud computing infrastructures such as Amazon Web Services, Azure Cloud, or Google Cloud
Hands on experience with client-driven large-scale implementation projects
Background in programming and scripting languages such as Java, Python, or Scala
Strong understanding of Data Science and Analytics experience such as Machine Learning, Deep Learning, Recommendation Engines & Search Personalizations
Comfortable leading technical agile teams with common SCRUM & SDLC practices
Solid knowledge of design patterns, refactoring concepts, unit tests and CI/CD
Practical expertise in performance tuning &optimization
Solid troubleshooting & problems analysis skills
Ability to travel up to 20%

BENEFITS
Medical, Dental and Vision Insurance (Subsidized)
Health Savings Account
Flexible Spending Accounts (Healthcare, Dependent Care, Commuter)
Short-Term and Long-Term Disability (Company Provided)
Life and AD&D Insurance (Company Provided)
Employee Assistance Program
Unlimited access to LinkedIn learning solutions
Matched 401(k) Retirement Savings Plan
Paid Time Off – the employee will be eligible to accrue 15-25 paid days, depending on specific level and tenure with EPAM (accrual eligibility may change over time)
Paid Holidays - nine (9) total per year
Legal Plan and Identity Theft Protection
Accident Insurance
Employee Discounts
Pet Insurance
Employee Stock Purchase Program
If otherwise eligible, participation in the discretionary annual bonus program
If otherwise eligible and hired into a qualifying level, participation in the discretionary Long-Term Incentive (LTI) Program

ABOUT EPAM
EPAM is a leading global provider of digital platform engineering and development services. We are committed to having a positive impact on our customers, our employees, and our communities. We embrace a dynamic and inclusive culture. Here you will collaborate with multi-national teams, contribute to a myriad of innovative projects that deliver the most creative and cutting-edge solutions, and have an opportunity to continuously learn and grow. No matter where you are located, you will join a dedicated, creative, and diverse community that will help you discover your fullest potential

ADDITIONAL
This posting includes a good faith range of the salary EPAM would reasonably expect to pay the selected candidate. The range provided reflects base salary only. Individual compensation offers within the range are based on a variety of factors, including, but not limited to: geographic location, experience, credentials, education, training; the demand for the role; and overall business and labor market considerations. Most candidates are hired at a salary within the range disclosed. Salary range: $128k - $200k In addition, the details highlighted in this job posting above are a general description of all other expected benefits and compensation for the position
Start your job application: click Apply Now
Show Less
Report",4.1,10000+ Employees,1993,Company - Public,Information Technology Support Services,Information Technology,$1 to $5 billion (USD)
Lead Data Engineer,-1,Wells Fargo3.7 ★,"Minneapolis, MN","Wells Fargo is seeking a Lead Data Engineer to join the Enterprise Service Management (ESM) Data Services team. As part of Enterprise Function Technology (EFT) the Data Services Team helps Enterprise Information Technologies (EIT) and Enterprise Information Securities (EIS) manage IT assets and their associated risks. Our current focus is to maintain and enhance existing solutions, including IT Asset Management Data Mart (ITADM), Vulnerability Remediation Data Warehouse (VRDW) and IT Asset Management Operational Data Stores (ITAM ODS).

Our current technical landscape consists of a typical data architecture leveraging Microsoft / Teradata database technologies and SSIS / Ab-Initio ETL tools. However we will also be embarking on a migration of the aforementioned applications onto cloud based architecture in the coming 12 - 18 months.

In order to meet our strategic goals we have an exciting opportunity for a Lead Data Engineer to join our team. This individual contributor role will providing technical guidance and execution across several Data Services initiatives.

Initial primary focus will be to provide data analysis and support for the IT Asset Management Operational Data Store (ITAM ODS) and will expand to include our cloud modernization efforts. (Google or Azure). In this role, the Principle Data Engineer will be designing, building and operationalizing large-scale enterprise data solutions and applications using one or more data and analytics services in combination with 3rd party cloud and big data platforms.

In parallel to cloud migration we are also assessing our data quality & completeness capabilities. This role may also play a key role in maturing Data Quality within our data portfolio.

In this role, you will:
Initially be responsible to assess downstream Data Enquiries and Enhancement Requests: This encompasses understanding requirements. Determining if data is fit for purpose through data profiling of existing and new sources. Partner with other ETL developers on delivery including pre / post implementation validation.
Lead efforts in Business Requirements analysis, Data Analysis, and Profiling. Being able to receive broad technical guidance of analytical and technology outcomes and constraints, and implement them accurately by providing detailed direction to team resources.
Assisting in defining data strategy particularly in the area of cloud technologies and data quality
Build relationships with SME's on respective development teams and with business partners. Leverage existing Subject Matter expertise to understand additional insights about business processes and state of the infrastructure.
Utilize excellent data analysis skills to resolve complex Data Requirements.
Develop a broad but detailed understanding of IT Asset Management data, and an intimate knowledge of how it is transformed within all DataMart's.
Collaborate with application aligned DBA's, Data Technologies and Infrastructure Architects and Systems Administrators on all aspects of data management.
Make decisions in complex and multi-faceted data engineering situations requiring understanding of software package options and programming language and compliance requirements that influence and lead Technology to meet deliverables and drive organizational change. (Particularly with respect to Cloud migration)
Required Qualifications, US:
5+ years of Database Engineering experience, or equivalent demonstrated through one or a combination of the following: work experience, training, military experience, education
5+ years of data management experience.
5+ years of SDLC (System Development Life Cycle) experience
1+ year of PL/SQL experience
Knowledge and understanding of database architecture, design, and support
Experience conducting root cause analysis for data-driven process-related improvements
Strong analytical skills with high attention to detail and accuracy
Desired Qualifications:
3+ years of experience securing public cloud deployments on Google Cloud Platform (GCP) and / or Azure
ETL (Extract, Transform, Load) Programming experience
Python experience
SSIS or Ab-Initio Experience
Data Modelling
GitHub Experience
Apache Spark design and development experience using Scala, Java, Python or Data Frames with Resilient Distributed Datasets (RDDs)
Knowledge and understanding of asset management function support
Ability to develop operational reporting and performing complex data analysis
We Value Diversity

At Wells Fargo, we believe in diversity, equity and inclusion in the workplace; accordingly, we welcome applications for employment from all qualified candidates, regardless of race, color, gender, national origin, religion, age, sexual orientation, gender identity, gender expression, genetic information, individuals with disabilities, pregnancy, marital status, status as a protected veteran or any other status protected by applicable law.

Employees support our focus on building strong customer relationships balanced with a strong risk mitigating and compliance-driven culture which firmly establishes those disciplines as critical to the success of our customers and company. They are accountable for execution of all applicable risk programs (Credit, Market, Financial Crimes, Operational, Regulatory Compliance), which includes effectively following and adhering to applicable Wells Fargo policies and procedures, appropriately fulfilling risk and compliance obligations, timely and effective escalation and remediation of issues, and making sound risk decisions. There is emphasis on proactive monitoring, governance, risk identification and escalation, as well as making sound risk decisions commensurate with the business unit's risk appetite and all risk and compliance program requirements.

Candidates applying to job openings posted in US: All qualified applicants will receive consideration for employment without regard to race, color, religion, age, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.

Candidates applying to job openings posted in Canada: Applications for employment are encouraged from all qualified candidates, including women, persons with disabilities, aboriginal peoples and visible minorities. Accommodation for applicants with disabilities is available upon request in connection with the recruitment process.

Drug and Alcohol Policy

Wells Fargo maintains a drug free workplace. Please see our Drug and Alcohol Policy to learn more.
To apply to this job, click Apply Now
Show Less
Report",3.7,10000+ Employees,1852,Company - Public,Banking & Lending,Financial Services,$10+ billion (USD)
"Solutions Architect, Cisco FSO (Remote)",$64K - $100K (Glassdoor est.),Presidio4.0 ★,"Raleigh, NC","SEIZE THE OPPORTUNITY TO BE A PART OF SOMETHING GREAT!
Presidio is on the leading edge of a technology-driven movement to transform the way business is done, for our customers and our customers' customers. Joining Presidio means immersing yourself in a culture of self-starters, collaborators and innovators who make real, lasting change in the marketplace via cutting-edge technology and business solutions. At Presidio, we know that it’s our people that make the connections happen.
WHY YOU SHOULD JOIN US? You will set your career on track for outstanding achievement with a company that knows no limits. Presidio is a leading a global digital services and solutions provider focused on Digital Infrastructure, Business Analytics, Cloud, Security & Emerging solutions.

THE ROLE: Internal Job Title

Job Summary:
As a Solutions Architect (SA) and a member of the Pre-Sales Engineering Team, the candidate will be responsible for working with Presidio account managers and customers to collect requirements and build solutions tailored around the Cisco Full Stack Observability (FSO) portfolio products. This position will be remote, as the role will support Presidio accounts across the entire country.

A successful Solutions Architect should be able to present and explain the various use cases for the Cisco FSO stack to customers, guide them through requirements gathering, and formulate a solution consisting of one or more offerings. SAs are responsible for creating scopes of work and task lists for various types of projects in support of these solutions.
Travel Requirements: In this role you will be expected to travel up to 20%. It will be based in any location in the United States (Remote)

Job Responsibilities:
Meet with Presidio’s customers, collecting requirements for observability solutions
Present and explain technologies to customers, guide them through requirements gathering and formulate a solution consisting of software, licensing, and engineering services
Develop engineering solutions for sale to Presidio customers.
Work with Account Manager/Sales Team to develop customer relationships and solutions to assist in the sales process
Create high level solutions designs/architecture and present to customers
Creative customer-facing presentations
Create Bills of Materials & Configurations for solutions
Develop Professional Services Pricing
Write Statements of Work and Proposals
Create scope of work and task lists for various types of projects in support of these solutions.
Mentor deployment engineers and provide technical leadership around the FSO stack
Required Skills:
Demonstrated passion for technology, solution design, and self-study
Comfortable leading group presentations, solution demonstrations, and whiteboard sessions
Strong sales acumen and technical expertise
Candidates must have strong written and verbal communication skills
Candidates should have a depth of knowledge and experience with design, implementation and support of at least 3 of the following:
Complex campus and data center routing and switching solutions
Cisco Wireless
Firewall, SASE, and malware (Palo Alto, Cisco and/or Fortinet)
SD-WAN
Cisco Meraki portfolio
Cloud networking (AWS/Azure/GCP)
Education and Experience:
Bachelor’s degree or equivalent experience and/or military experience
3+ years of architecting and/or implementing complex Networking, Data Center, Collaboration and/or Security solutions
1+ year experience of architecting and/or implementing the Cisco FSO stack
*****
ABOUT PRESIDIO
Presidio is committed to Diversity, Equity, and Inclusion at the highest levels and has strengthened its drive to build and drive systemic DEI change process across all levels of the organization. Cultivating a culture of inclusion where the expression of all our differences are valued, celebrated, and add to our collective achievements.
Presidio is a global digital services and solutions provider accelerating business transformation through secured technology modernization. Highly skilled teams of engineers and solutions architects with deep expertise across cloud, security, networking and modern data center infrastructure help customers acquire, deploy and operate technology that delivers impactful business outcomes. Presidio is a trusted strategic advisor with a flexible full life cycle model of professional, managed, and support and staffing services to help execute, secure, operationalize and maintain technology solutions. We serve as an extension of our clients' IT teams, providing deep expertise and letting them focus on their core business. Presidio operates in 40+ US offices and offices in Ireland, London, Singapore, and India.
For more information visit: http://presidio.com
*****
Presidio is an Equal Opportunity / Affirmative Action Employer / VEVRAA Federal Contractor. All qualified candidates will receive consideration for this position regardless of race, color, creed, religion, national origin, age, sex, citizenship, ethnicity, veteran status, marital status, disability, sexual orientation, gender identification or any other characteristic protected by applicable federal, state and local statutes, regulations and ordinances.
To read more about discrimination protections under Federal Law, please visit: https://www.dol.gov/ofccp/regs/compliance/posters/pdf/OFCCP_EEO_Supplement_Final_JRF_QA_508c.pdf
If you have any difficulty using our online system and need an accommodation in the job application process due to a disability, please send an email to recruitment@presidio.com for assistance.
Presidio is a VEVRAA Federal Contractor requesting priority referrals of protected veterans for its openings. State Employment Services, please provide priority referrals to recruitment@presidio.com.
RECRUITMENT AGENCIES PLEASE NOTE:
Agencies/3 Parties may not solicit to any employee of Presidio. Any candidate information received from any Agency/3 Party will be considered a gift and property of Presidio, unless the Agency/3 Party is an Authorized Vendor of Presidio with an up-to-date Presidio Contract in hand signed by Presidio Talent Acquisition. No payment will be made to any Agency/3 Party who is not an Authorized Vendor, nor has specific approval in writing from Presidio Talent Acquisition to engage in recruitment efforts for Presidio.
Start your job application: click Apply Now
Show Less
Report",4.0,1001 to 5000 Employees,2006,Subsidiary or Business Segment,Information Technology Support Services,Information Technology,Unknown / Non-Applicable
"Engineering Director, Commercial Data Engineering",$170K - $255K (Employer est.),Amex4.2 ★,"Phoenix, AZ","You Lead the Way. We’ve Got Your Back.
With the right backing, people and businesses have the power to progress in incredible ways. When you join Team Amex, you become part of a global and diverse community of colleagues with an unwavering commitment to back our customers, communities and each other. Here, you’ll learn and grow as we help you create a career journey that’s unique and meaningful to you with benefits, programs, and flexibility that support you personally and professionally.
At American Express, you’ll be recognized for your contributions, leadership, and impact—every colleague has the opportunity to share in the company’s success. Together, we’ll win as a team, striving to uphold our company values and powerful backing promise to provide the world’s best customer experience every day. And we’ll do it with the utmost integrity, and in an environment where everyone is seen, heard and feels like they belong.
Join Team Amex and let's lead the way together.

As part of our diverse tech team, you can architect, code and ship software that makes us an essential part of our customers’ digital lives. Here, you can work alongside talented engineers in an open, supportive, inclusive environment where your voice is valued, and you make your own decisions on what tech to use to solve challenging problems. Amex offers a range of opportunities to work with the latest technologies and encourages you to back the broader engineering community through open source. And because we understand the importance of keeping your skills fresh and relevant, we give you dedicated time to invest in your professional development. Find your place in technology on #TeamAmex

How will you make an impact in this role?
We’re looking for an experienced data engineering leader to join our Commercial Data Engineering organization. We build data-centric solutions to support the Global Commercial Services product suite including B2B payments, large corporate clients, and our small and medium enterprise ecosystem. You’ll lead your team and partner cross functionally to create innovative, scalable, resilient data systems that enable us to unlock the value of our data for all of our products.
Cultivate an environment of continuous improvement through technical guidance, coaching, mentoring, and feedback.
Lead one or more data engineering teams that iterate on our large-scale distributed, high-performance data platform.
Establish and maintain strong relationships with key stakeholders and cross functional partners to deliver collaboratively.
Perform hands-on architecture, design, development, and testing.
Drive high-level & detailed technical designs and conduct designs & code reviews as needed.
Implement process improvements to streamline areas for your team such as hiring, onboarding, software delivery, and internal/external communication.
Recruit and retain engineering talent.

Minimum Qualifications
Excellent written and verbal communication skills.
Expertise with a major cloud vendor (AWS/GCP).
Expertise with spark, python, SQL.
Experience leading high-performing data engineering teams focused on iterative delivery.
Experience partnering cross functionally and being a hands-on leader to drive successful execution.
Experience with CI/CD and strong understanding of implementing iterative software delivery practices.
Preferred Qualifications
Experience building unified data driven solutions with a data-lakehouse architecture.
Experience building event driven data streaming solutions
Salary Range: $170,000.00 to $255,000.00 annually + bonus + equity (if applicable) + benefits
The above represents the expected salary range for this job requisition. Ultimately, in determining your pay, we'll consider your location, experience, and other job-related factors.
We back our colleagues and their loved ones with benefits and programs that support their holistic well-being. That means we prioritize their physical, financial, and mental health through each stage of life. Benefits include:
Competitive base salaries
Bonus incentives
6% Company Match on retirement savings plan
Free financial coaching and financial well-being support
Comprehensive medical, dental, vision, life insurance, and disability benefits
Flexible work arrangements and schedules with hybrid and virtual options with Amex Flex
20+ weeks paid parental leave for all parents, regardless of gender, offered for pregnancy, adoption or surrogacy
Free access to global on-site wellness centers staffed with nurses and doctors (depending on location)
Free and confidential counseling support through our Healthy Minds program
Career development and training opportunities
For a full list of Team Amex benefits, visit our Colleague Benefits Site.
At American Express, you’ll be recognized for your contributions, leadership, and impact—every colleague has the opportunity to share in the company’s success. Together, we’ll win as a team, striving to uphold our company values and powerful backing promise to provide the world’s best customer experience every day. And we’ll do it with the utmost integrity, and in an environment where everyone is seen, heard and feels like they belong.
American Express is an equal opportunity employer and makes employment decisions without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, veteran status, disability status, age, or any other status protected by law.
We back our colleagues with the support they need to thrive, professionally and personally. That's why we have Amex Flex, our enterprise working model that provides greater flexibility to colleagues while ensuring we preserve the important aspects of our unique in-person culture. Depending on role and business needs, colleagues will either work onsite, in a hybrid model (combination of in-office and virtual days) or fully virtually.
US Job Seekers/Employees - Click here to view the “Know Your Rights” poster and supplement and the Pay Transparency Policy Statement.
If the links do not work, please copy and paste the following URLs in a new browser window: https://www.dol.gov/agencies/ofccp/posters to access the three posters.
To apply to this job, click Apply Now
Show Less
Report",4.2,10000+ Employees,1850,Company - Public,Financial Transaction Processing,Financial Services,$10+ billion (USD)
Principal data engineer,$118K - $171K (Glassdoor est.),bp4.1 ★,"Houston, TX","Location
United States of America - Texas - Houston
Travel required
No travel is expected with this role
Job category
Digital & technology
Relocation available
This role is not eligible for relocation
Job type
Professionals
Job code
RQ063058
Experience level
Senior

Job summary
Entity:
Innovation & Engineering

Job Family Group:
IT&S Group

Job Summary:
As a Principal Data Engineer, you will be part of bp’s Compute Platforms organisation, the group responsible for the computing platforms and services that underpin all bp’s computing services. The portfolio covers technologies that include on-premise data centres, cloud infrastructure and services, high-performance computing, databases, and supporting services.

Job Description:
Key Accountabilities:
Led a team of DevOps squads made up of software engineers, platform engineers, platform architects, and platform security engineers using agile development ceremonies including Kanban, refinement, and retrospectives, to deliver the Azure platform and resource provisioning services necessary for service and platform owners to deliver their agendas.
Build the platform strategy and product roadmap for Azure by working with partners internal and external to the team.
Develop a cloud alignment strategy for both AWS and Azure to provide a consistent customer experience.
Build relationships with external teams, including Digital Security and Architecture, to provide a balance of security and functionality in the Azure platform.
Provide a principle (architecture, design, and security) led service to allow the DevOps teams to be mostly autonomous squads to help deliver solutions rapidly.
Provide governance to enable prioritization of customer demand to ensure new and enhanced services are available for customer projects.
Provide guest platforms (DBaaS, CaaS, CPIN, WVD) the ability to deliver their services while minimizing their dependency on the Azure platform team.
Identify areas of continuous improvement to reduce the effort customers must put in to consume the Azure services (reduce customer friction).
Manage suppliers providing services for the Azure platform to ensure they provide people that are able to develop products/features following out team standards and principles.
Develop training programs with Microsoft to upskill bp staff and contractors as related to Azure capabilities.
Mentor and coach team members, while defining and promoting usage of standards, principles, and lessons learned
Essential Experience:
Developing and leading digital/technology strategies
Broad and strategic knowledge of the cloud technology landscape
Demonstrate strong product management and design thinking foresight skills
Strong facilitation and leadership skills: bringing multiple partners from architecture, digital security, and product/service owners together towards agreed outcomes.
Outstanding communication and relationship skills, ability to engage with a broad range of partners, capable of leading by influence.
Knowledge and understanding of modern development methodologies (agile using Kanban, DevOps, 2-pizza teams, agile ceremonies).
Knowledge and understanding of modern approaches to source-code management and control through tools (SonarCube, Azure DevOps, coding standards)
Bachelor's degree and/or MBA in relevant subject or equivalent preferred or equivalent experience.
Why join us

At bp, we support our people to learn and grow in a diverse and exciting environment. We believe that our team is strengthened by diversity. We are committed to fostering an inclusive environment in which everyone is respected and treated fairly.

There are many aspects of our employees’ lives that are important, so we offer benefits to enable your work to fit with your life. These benefits can include flexible working options, a generous paid parental leave policy, and excellent retirement benefits, among others!

We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation.

Travel Requirement
No travel is expected with this role

Relocation Assistance:
This role is not eligible for relocation

Remote Type:
This position is a hybrid of office/remote working

Skills:

Legal Disclaimer:
We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, sex, gender, gender expression, sexual orientation, age, marital status, neurodiversity/neurocognitive functioning, veteran status or disability status. Individuals with disabilities may request a reasonable accommodation related to bp’s recruiting process (e.g., accessing the job application, completing required assessments, participating in telephone screenings or interviews, etc.). If you would like to request an accommodation related to the recruitment process, please contact us to request accommodations.
If you are selected for a position and depending upon your role, your employment may be contingent upon adherence to local policy. This may include pre-placement drug screening, medical review of physical fitness for the role, and background checks.
Apply Now: click Apply Now
Show Less
Report",4.1,10000+ Employees,1908,Company - Public,Energy & Utilities,"Energy, Mining & Utilities",$10+ billion (USD)
ETL & Data Warehouse Manager / Architect (Remote),$94K - $128K (Glassdoor est.),Crum & Forster4.0 ★,"Morristown, NJ","Crum & Forster Company Overview:
Crum & Forster (C&F) Crum & Forster (C&F), with a proud history dating to 1822, provides specialty and standard commercial lines insurance products through our admitted and surplus lines insurance companies. C&F enjoys a financial strength rating of ""A"" (Excellent) by AM Best and is proud of our superior customer service platform. Our claims and risk engineering services are recognized as among the best in the industry.
Our most valuable asset is our people: more than 2000 employees in locations throughout the United States. The company is increasingly winning recognition as a great place to work, earning several workplace and wellness awards, including the October 2022 Great Place to Work® Award for our employee-first focus and our steadfast commitment to diversity, equity and Inclusion.
C&F is part of Fairfax Financial Holdings, a global, billion dollar organization. For more information about Crum & Forster, please visit our website: www.cfins.com.
Job Description:

C&F is looking for a passionate ETL & Data Warehouse Manager / Architect for our Snowflake implementation initiative, with significant experience in ETL solutions using SQL Server Integration Services and Snowflake. In this role, you will be responsible for designing and managing the development of robust ETL solutions for loading & extracting data from various source and target systems from our Snowflake Data warehouse. You will also be responsible for maintaining the Snowflake Data Warehouse schema design.
What you will do:

Collaborate with stakeholders and various IT groups to implement an overall data strategy that is in line with business objectives
Help the organization to bring our “one trusted data source” vision to life through a formal enterprise data lake house
Design build and maintain data models, data warehouses, data lakes, data marts and reporting/analytics solutions
Develop and maintain data integration and data transformation best practices and standards
Keep up-to-date with industry trends and advancements in ETL technologies and tools
Manage a team of ETL developers, providing guidance, support, and training as needed. This team will:
Identify and proactively resolve issues that could impact system performance, reliability, and usability
Develop and maintain ETL documentation, including technical specifications, data mappings, and data lineage
Perform data profiling and data quality analysis to ensure that ETL processes are accurate and reliable
Troubleshoot and resolve ETL issues and errors
What you will bring to C&F:

8+ years of experience in ETL development and data integration solutions using SSIS or any other ETL tool
8+ years of database development experience using Microsoft SQL Server, Oracle, and any other RDBMS
Strong knowledge of SQL/T-SQL/PL-SQL, Query Optimization, and Data management skills
Experience in Data warehouse development; Logical and Physical Database design & development
Experience with Snowflake data warehouse would be a big plus
Experience with BI tools such as SSRS/SSAS would be a plus
Experience with any cloud data warehouse would be plus
Knowledge of code versioning tools such as Git or stash would be a plus
Experience working in an agile environment would be a plus
Work experience related to the Insurance vertical would be a plus
Excellent critical thinking, analytical and problem-solving skills
Ability to think outside of the box and propose innovative solutions
Excellent written and oral communication skills
#LI-MS

# LI-REMOTE
What C&F will bring to you:
Competitive compensation package
Generous 401K employer match
Employee Stock Purchase plan with employer matching
Generous Paid Time Off
Excellent benefits that go beyond health, dental & vision. Our programs are focused on your whole family’s wellness, including your physical, mental and financial wellbeing
A core C&F tenet is owning your career development, so we provide a wealth of ways for you to keep learning, including tuition reimbursement, industry-related certifications and professional training to keep you progressing on your chosen path
A dynamic, ambitious, fun and exciting work environment
We believe you do well by doing good and want to encourage a spirit of social and community responsibility, matching donation program, volunteer opportunities, and an employee-driven corporate giving program that lets you participate and support your community

At C&F you will BELONG

If you require special accommodations, please let us know.We value inclusivity and diversity. We are committed to equal employment opportunity and welcome everyone regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity, or Veteran status. If you require special accommodations, please let us know
To apply to this job, click Apply Now
Show Less
Report",4.0,1001 to 5000 Employees,1822,Subsidiary or Business Segment,Insurance Carriers,Insurance,Unknown / Non-Applicable
Sr Data Engineer/data architect,$70.00 - $90.00 Per Hour (Employer est.),Devcare Solutions3.6 ★,"Columbus, OH","Role : Data Architect / Bigdata Architect / Hadoop / senior data engineer/ senior Bigdata
skills: oracle, SQL, Hadoop, bigdata , cloud era, Hive, data migration etc.
8+ years Data analysis/architecture experience in Waterfall and Agile Methodology in various domains (prefer Healthcare) in a data warehouse environment.
Good knowledge of relational database, Hadoop big data platform and tools, data vault and dimensional model design.
Strong SQL experience (prefer Oracle, Hive and Impala) in creating DDL’s and DML’s in Oracle, Hive and Impala (minimum of 8 years’ experience).
Experience in analysis, design, development, support and enhancements in data warehouse environment with Cloudera Bigdata Technologies (with a minimum of 8-9 years’ experience in Hadoop, MapReduce, Sqoop, PySpark, Spark, HDFS, Hive, Impala, Stream Sets, Kudu, Oozie, Hue, Kafka, Yarn, Python, Flume, Zookeeper, Sentry, Cloudera Navigator) along with Informatica.
Experience (minimum of 8 years) in working with Sqoop scripts, PySpark programs, HDFS commands, HDFS file formats (Parquet, Avro, ORC etc.), Stream Sets pipelines, jobs scheduling, hive/impala queries, Unix commands, scripting and shell scripting etc.
Experience in migrating data from relational database (prefer Oracle) to big data – Hadoop platform is a plus.
Experience eliciting, analyzing and documenting functional and non-functional requirements.
Ability to document business, functional and non-functional requirements, meeting minutes, and key decisions/actions.
Experience in identifying data anomalies.
Experience building data sets and familiarity with PHI and PII data.
Ability to establish priorities & follow through on projects, paying close attention to detail with minimal supervision.
Effective communication, presentation, & organizational skills.
Good experience in working with Visio, Excel, PowerPoint, Word, etc.
Effective team player in a fast paced and quick delivery environment.
Required Education: BS/BA degree or combination of education & experience.
DESIRED Skill Sets:
Demonstrate effective leadership, analytical and problem-solving skills
Required excellent written and oral communication skills with technical and business teams.
Ability to work independently, as well as part of a team
Stay abreast of current technologies in area of IT assigned
Establish facts and draw valid conclusions
Recognize patterns and opportunities for improvement throughout the entire organization
Ability to discern critical from minor problems and innovate new solutions
Skill
Data analysis/architecture experience in Waterfall and Agile Methodology in various domains (prefer Healthcare) in a data warehouse environment.
Good knowledge of relational database, Hadoop big data platform and tools, data vault and dimensional model design.
Strong SQL experience (prefer Oracle, Hive and Impala) in creating DDL’s and DML’s in Oracle, Hive and Impala
analysis, design, development, support and enhancements in data warehouse environment with Cloudera Bigdata Technologies, along with Informatica
Experience in migrating data from relational database (prefer Oracle) to big data – Hadoop platform is a plus.
Job Type: Contract
Salary: $70.00 - $90.00 per hour
Benefits:
Dental insurance
Health insurance
Vision insurance
Schedule:
8 hour shift
Monday to Friday
Experience:
total: 10 years (Required)
oracle: 4 years (Required)
SQL: 3 years (Required)
cloud era: 3 years (Required)
hadoop / Bigdata: 3 years (Required)
data architect: 1 year (Required)
Data warehouse: 1 year (Required)
Willingness to travel:
100% (Required)
Work Location: On the road
Speak with the employer
+91 6148083833
Show Less
Report",3.6,51 to 200 Employees,2005,Company - Private,Information Technology Support Services,Information Technology,Unknown / Non-Applicable
Senior data engineer,$114K - $152K (Glassdoor est.),bp4.1 ★,"Houston, TX","Location
US: Houston - Westlake Campus
Travel required
Up to 10% travel should be expected with this role
Job category
Digital & technology
Relocation available
This role is eligible for relocation within country
Job type
Professionals
Job code
RQ26058419
Experience level
Intermediate

Job summary
Entity:
Innovation & Engineering

Job Family Group:
IT&S Group

Job Summary:
Part of a cross-disciplinary team, working closely with other data engineers, software engineers, data scientists, data managers and business partners.

Architects, designs, implements and maintains reliable and scalable data infrastructure to move, process and serve data.

Writes, deploys and maintains software to build, integrate, manage, maintain, and quality-assure data at bp.

Adheres to and advocates for software engineering best practices (e.g. technical design, technical design review, unit testing, monitoring & alerting, checking in code, code review, documentation),

Responsible for deploying secure and well-tested software that meets privacy and compliance requirements; develops, maintains and improves CI / CD pipeline,

Responsible for service reliability and following site-reliability engineering best practices: on-call rotations for services they maintain, responsible for defining and maintaining SLAs. Design, build, deploy and maintain infrastructure as code. Containerizes server deployments.

Actively contributes to improve developer velocity.

Mentors others.

Job Description:
BS degree in computer science or related field
Deep and hands-on experience (typically 5+ years) designing, planning, building, productionizing, maintaining and documenting reliable and scalable data infrastructure and data products in complex environments
Development experience in one or more object-oriented programming languages (e.g. Python, Scala, Java, C#)
Advanced database and SQL knowledge
Experience designing and implementing large-scale distributed data systems
Deep knowledge and hands-on experience in technologies across all data lifecycle stages
Strong stakeholder management and ability to lead initiatives through technical influence
Continuous learning and improvement mindset
Desired
No prior experience in the energy industry required
Why join us
At bp, we support our people to learn and grow in a diverse and exciting environment. We believe that our team is strengthened by diversity. We are committed to fostering an inclusive environment in which everyone is respected and treated fairly.
There are many aspects of our employees’ lives that are important, so we offer benefits to enable your work to fit with your life. These benefits can include flexible working options, a generous paid parental leave policy, and excellent retirement benefits, among others!
We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation.

Travel Requirement
Up to 10% travel should be expected with this role

Relocation Assistance:
This role is eligible for relocation within country

Remote Type:
This position is a hybrid of office/remote working

Skills:

Legal Disclaimer:
We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, sex, gender, gender expression, sexual orientation, age, marital status, neurodiversity/neurocognitive functioning, veteran status or disability status. Individuals with disabilities may request a reasonable accommodation related to bp’s recruiting process (e.g., accessing the job application, completing required assessments, participating in telephone screenings or interviews, etc.). If you would like to request an accommodation related to the recruitment process, please contact us to request accommodations.
If you are selected for a position and depending upon your role, your employment may be contingent upon adherence to local policy. This may include pre-placement drug screening, medical review of physical fitness for the role, and background checks.
To apply to this job, click Apply Now
Show Less
Report",4.1,10000+ Employees,1908,Company - Public,Energy & Utilities,"Energy, Mining & Utilities",$10+ billion (USD)
Azure Solutions Architect,-1,Ness Digital Engineering4.2 ★,Remote,"Description
Description
Ness Digital Engineering provides strategic IT consulting to global enterprises. Our Cloud and Data practice provides solutions, methodologies, and strategic guidance for cloud mobility, software modernization and automation initiatives.
We are problem-solvers, architects, strategists, implementors, and lifelong learners. We collaborate with each other and with our clients to help them meet their short- and long-term goals. Our culture is open, transparent, challenging, and fun.

We solve complex business problems with technology and insight. Our business domain knowledge, technology expertise, and Agile delivery process have helped some of our most innovative clients execute on digital transformations. We’re an Azure Consulting Partner, a Premier Confluent Systems Integrator, and a Snowflake Select Services Partner.
We aim to hire engineers and architects who want to figure out what needs to be done and take ownership in delivering results.

As a Senior Azure Solutions Architect for Analytics, you will:
Advise clients on strategic technical decisions, develop and present best practices.
Lead Discovery engagements to assess a clients’ existing workloads, infrastructure & software environments.
Propose, Designing, developing, and implementing Azure Analytics solutions that meet the business requirements of clients.
Translate business requirements of clients into technical solutions leveraging the Azure Analytics platform.
Design and architect end-to-end Azure Analytics solutions that meet the client's business needs and requirements, ensuring that they are scalable, secure, and performant.
Develop and implement Azure Analytics solutions, including data modeling, ETL/ELT, data warehousing, and reporting/visualization.
Conduct POC engagements to demonstrate the capabilities and benefits of Azure Analytics solutions to potential clients.
Collaborate with the sales team to identify opportunities, develop proposals, and provide presales support.
Provide technical leadership and guidance to project teams, ensuring that projects are delivered on time, within budget, and meet the client's expectations.
Keep up to date with the latest trends, technologies, and best practices in Azure Analytics, and share knowledge with the team.
Requirements
All candidates must have:
10 years’ experience in a technology organization with significant responsibility for setting technical direction.
Bachelor’s or master’s degree in computer science, Information Systems, or a related field
Demonstrated ability to work independently and with limited direction, translate high level goals into measurable milestones and deliver on them.
Broad familiarity with Linux/Windows systems, Cloud infrastructure, Messaging/Streaming technologies, Data-stores/Databases, Application/API design, Internet and Networking Protocols, Security Architecture, Version Control Systems and CI/CD tools.
Deep familiarity with Azure offerings and how they can be best utilized to deliver scale, reliability, resiliency, and resource efficiency.
Strong knowledge of data engineering and analytics technologies, including Azure Data Factory, Azure Synapse Analytics, Azure Analysis Services, and Power BI
Experience in presales activities, including conducting POC engagements, presenting solutions to potential clients and writing proposals.
Excellent communication and interpersonal skills, with the ability to build relationships with clients and team members.
Strong problem-solving skills, with the ability to think creatively and strategically to provide solutions to complex problems.
Experience with automation using Terraform/Bicep/Arm and configuration management using Ansible, Chef, PowerShell or similar.
Some form of programming experience
A desire and demonstrated ability to learn new technologies, develop new skills, and solve tough problems.
Excellent written and verbal English communication skills
Excellent presentation skills
Experience working with both Agile and Waterfall project management.
In addition, ideal candidates will also have experience with:
Interacting directly with clients and senior executives in an advisory or consulting capacity
Large cloud deployments on AWS, Azure, Google Compute or OpenStack
Event-Driven Architecture, Micro-services, distributed compute/processing systems
Automated Testing and/or Test Data Management
Containerization technologies and best practices, especially Kubernetes
Experience working in globally distributed teams.
Show Less
Report",4.2,5001 to 10000 Employees,1999,Company - Private,Information Technology Support Services,Information Technology,$100 to $500 million (USD)
"Global Analytics, Data Solutions Architect & Ops Manager",$100K - $147K (Employer est.),Colgate-Palmolive4.2 ★,"Piscataway, NJ","No Relocation Assistance Offered
# 153255 - Piscataway, New Jersey, United States
Do you want to be part of a team that is building a future to smile about? What about having the opportunity to connect with others across the world, full of stimulating discussions, and making impactful contributions?

If this is how you see your career, Colgate is the place to be!

Our dependable household brands, dedicated employees, and sustainability commitments make us a company passionate about building a future to smile about for our employees, consumers, and surrounding communities. The pride in our brand fuels a workplace that encourages creative thinking, champions experimentation, and promotes authenticity which has contributed to our enduring success.

If you want to work for a company that lives by their values, then give your career a reason to smile...every single day.

We're looking for an experienced data and analytics professional to join our Global Analytics Data Foundation team. The Data Solutions Architect and Ops Manager will play a meaningful role in architecting and evolving the data foundation to fuel the next generation of commercial analytics platforms and data products at Colgate-Palmolive. The ideal candidate will be comfortable wearing multiple hats - architecting, developing and automating data transformation pipelines integrating global data sources in operationally efficient manner to enable strategic analytics capabilities in key business practices such as Revenue Growth Management and helping define and run a data ops approach for supporting our production data architecture once scaled.

At Colgate-Palmolive, we have a culture of strong global, cross-functional collaboration so as a Lead/Manager, you will partner with teams across the world, including Global IT, data science and advanced analytics within Global and Divisional Analytics teams as well as various business functions such as Customer Development, Finance, Marketing, etc. In addition to architecting robust data transformation pipelines, your responsibilities will include leading the support, maintenance and operational stability, timeliness and quality of data delivery in partnership with the Global IT data ops team. Lastly, as a lead technical member of the Global Analytics Data Foundation Team, there will be opportunities to recruit, mentor and lead junior staff and/or external support as we further build out our expertise and capabilities over time.

What you will do
Lead the development of the data foundation architecture that will deliver timely and accurate data to power strategic Pricing & RGM Analytics as well as other data products for use throughout the global commercial organization
Use SQL (dbt) and Python (Airflow) to architect production-quality code/pipelines to meet the data transformation needs of Global Analytics applications, data scientists, and other business partners
Translate business requirements and logic into well-documented data architecture and data models to drive clarity and efficiency for end users
Collaborate cross functionally to understand and identify data needs and opportunities to use data to drive business solutions
Support the use of analytics platforms and data science workflows, while identifying ways to strengthen and scale our data foundation
Partner with Global IT to align on data architecture, analytics tools, and other related data technologies (e.g. data quality tools, data catalog, etc.)

Required Qualifications
Bachelor's Degree in a quantitative field
8+ years of professional experience as “hands-on” lead data architect, data solutions architect or data engineer with track record of architecting and supporting a complex, global scale data architecture/implementation for BI and/or downstream analytics workloads
Proven experience of modern data warehouse design principles within leading cloud warehouse (Snowflake, Databricks, Bigquery) along with data architecture/modeling and data engineering best practices including CI/CD
Proven expertise in the use of complex SQL and/or Python to clean and integrate data from a variety of sources in reproducible, robust production transformation pipelines including complex data processing frameworks for handling different cadence of data delivery from various external and internal sources, incremental processing vs. full refreshes, etc.
Mentoring or resource management experience- either internal or consultants
A change maker - an ambitious, partnering data technologist that is motivated to solve business problems through thoughtful, fit-for-purpose data solutions

Preferred Qualifications
Master's degree in a relevant field or related subject area (Computer Science, Engineering, Business Management, etc.)
Experience working on a global team that spans many geographies/timezones
Demonstrated expertise with Git/GitHub, dbt Core/Cloud, and Airflow
Proven understanding and experience with syndicated sales (Nielsen, IRI) and/or retailer POS (point of sale) data sources for use within BI/analytics

#LI-Hybrid
Salary Range $100,000 - $147,000 USD

Pay is based on several non discriminatory factors including but not limited to experience, education, skills and office location. In addition to your salary, Colgate-Palmolive offers a performance based bonus and competitive benefits package.

Equal Opportunity Employer
Colgate is an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity, sexual orientation, national origin, ethnicity, age, disability, marital status, veteran status (United States positions), or any other characteristic protected by law.
Are you interested in working for Colgate-Palmolive? You can apply online and attach all relevant documents such as a cover letter and resume or CV. Applications received by e-mail are not considered in the selection process. Become part of our team. We look forward to your application.
Colgate-Palmolive is a leading global consumer products company, tightly focused on Oral Care, Personal Care, Home Care and Pet Nutrition. Colgate sells its products in over 200 countries and territories around the world under such internationally recognized brand names as Colgate, Palmolive, elmex, Tom’s of Maine, Sorriso, Speed Stick, Lady Speed Stick, Softsoap, Irish Spring, Protex, Sanex, Elta MD, PCA Skin, Ajax, Axion, Fabuloso, Soupline and Suavitel, as well as Hill’s Science Diet and Hill’s Prescription Diet.
For more information about Colgate’s global business, visit the Company’s web site at http://www.colgatepalmolive.com. To learn more about Colgate Bright Smiles, Bright Futures® oral health education program, please visit http://www.colgatebsbf.com. To learn more about Hill's and the Hill’s Food, Shelter & Love program please visit http://www.hillspet.com. To learn more about Tom’s of Maine please visit http://www.tomsofmaine.com.
Reasonable accommodation during the application process is available for persons with disabilities. Please contact Application_Accommodation@colpal.com with the subject ""Accommodation Request"" should you require accommodation.
Start your job application: click Apply Now
Show Less
Report",4.2,10000+ Employees,1806,Company - Public,Consumer Product Manufacturing,Manufacturing,$10+ billion (USD)
AWS Data Architect IV,$98K - $142K (Glassdoor est.),Habemco3.5 ★,"Upper Lake, CA","Habemco is a shared services company wholly owned and operated by the Habematolel Pomo of Upper Lake, a federally recognized Native American tribe located in Northern California. Our talented team provides cross-functional support services to various tribal business and government entities. Habemco’s primary support services power the Tribe’s flagship online lending brand, Uprova, and any future brands, through product development, technology, and other support needed for growth. The Habemco team plays a critical role in ensuring a successful future for our customers, our employees, and the Tribe.
Headquartered in a beautiful, yet remote part of California, the Tribe recognizes that to compete in the highly competitive FinTech industry, the Tribe must access expertise throughout the nation. In addition to employees that work remotely, the Tribe has employees clustered at headquarters in Upper Lake, California, and a call center in Lenexa, Kansas.
Employees receive competitive pay and benefits, quarterly performance bonuses and 401(k) with a 4% match. Our team is ambitious, forward-thinking, passionate and moves fast! Are you ready to grow with us?

Purpose of the Position:
The AWS Data Architect IV will provide technology architectural assessments, strategies, and roadmaps for one or more projects & oversee the development and implementation of programs and provide technical leadership and support to the data development teams by identifying best-fit architectural solutions. To be successful in this role, you need deep expertise in design and architecture. You will partner closely with the business analyst, product owners, management, and stakeholders to align the architecture and recommend solutions that meet business and technology needs. All offers are contingent upon signing a confidentiality agreement and satisfactory completion of drug screening and background checks.
Essential Duties
Responsible for overall architecture and design of the solution delivered by the team.
Formulate target state architecture and roadmaps.
Lead a team and provide technical oversight, guidance, and review of the team's deliverables.
Data Modeling & Solution design for data solutions.
Embrace and incubate emerging technology and open-source products across all platforms.
Think outside the box and bring new ideas to the table to modernize the company's existing tech stacks and data platforms.
Advance the enterprise information data & integration architecture strategy.
Partner with architects, product owners, data professionals, and software & data engineers to drive the implementation of new applications.
Work within and across Agile teams to design, develop, test, implement and support technical solutions across full-stack development tools and technologies.
Lead efforts to deploy new and existing applications into AWS environments and provide operational support for the applications.
Conduct design and code reviews to ensure compliance with applicable standards.
Performs ad hoc duties and responsibilities as needed.
Stay up to date with technology, trends, and tools in Big Data.
Regular, reliable attendance during normal business hours.
In-person attendance and travel as requested.
Other duties as assigned.
Education and Experience
Required:
Bachelor's Degree Computer Science or other related technical discipline.
7+ years in IT and 5 years’ experience working as an AWS Data Architect.
5 years in Data warehouse, ETL, and BI projects.
5+ years of experience with Big Data, data streaming, & cloud-based platforms.
5+ years of experience with Data Lake Infrastructure, Data Warehousing, and Data Analytics tools.
Experience in AWS in developing solutions using microservices.
Hands-onexperience on AWS in developing solutions using microservices, AWS Lambda, API / Microservices (Code build, Code deploy and govern), API Gateway, and S3 Storage.
5+ years of experience in solution architecture, design detailing, and technology delivery with a particular focus on AWS platform services.
5+ years of experience in AWS platform services, such as: compute, containers, integration, internet of things, storage, web, and DevOps.
A minimum of two end-to-end implementations of Datawarehouse on Amazon cloud.
Expertise in AWS Platform as a Service (PAAS).
Strong track record of successfully architecting and deploying AWS solutions.
Exposure in defining solution architecture, design detailing, and technology delivery with a particular focus on AWS platform services, such as: compute, containers, integration, internet of things, storage, web, and DevOps.
Hands-on experience on AWS storage services like AmazonS3, Amazon Kinesis, Amazon Dynamo DB, Amazon RDS.
All offers are contingent upon signing a confidentiality agreement and satisfactory completion of drug screening and background checks.Employer observes federal standards for controlled substances.
Preferred:
Hands-on experience on AWS Event/ Data Processing services like AWS Lambda, Amazon Kinesis, Amazon EMR, Amazon Machine Learning.
Hands-on experience on AWS Data Analysis services like Amazon Redshift, Amazon Quick sight.
Experience/knowledge in AWS EKS, AWS Databases (RDS, Dynamo DB, DMS, Elastic Cache, etc.), AWS Faregate, SNS/SQS/Kinesis, Logic Apps, IoT, S3 Data Lake, Athena, and AWS Director services.
Skills and Ability
Advanced problem-solving skills and the ability to optimize data for the best possible outcome.
Ability to prioritize and manage multiple milestones and projects efficiently.
A willingness to dig deep, learn from others, share your own skills, and be part of a talented and dedicated team.
Superior attention to detail.
Highly adaptable, a driver of change, and capable of quickly rallying teams.
Effectively prioritizes and executes tasks in a highly productive yet autonomous environment.
Strong decision-making and problem-solving skills (i.e., design, debugging, and testing) and experience with software development projects.
Ability to present technical ideas in concise, user-friendly, or layman's language.
Strong interpersonal skills used in developing effective working relationships and listening skills.
Result-driven and solutions-oriented with the ability to develop and implement the resolution in time-sensitive situations.
Motivate and mentor team members to grow their skills and careers by creating a nurturing environment that encourages innovation and continual learning.
Ability to work in a fast-paced, time-sensitive, and confidential environment.
Excellent communication skills: utilizing the ability to communicate effectively both orally and in writing with professionalism, excellent grammar, respect and courteousness.
Possess a balance of assertiveness and diplomacy along with adaptability in order to communicate on all levels.
Physical Requirements
Prolonged periods in a stationary seated position, such as working on a computer.
Frequently move, transport, and manipulate computer equipment up to 15 pounds.
Verbal communication sufficient to exchange accurate ideas and information.
In-person attendance and travel as requested.
Show Less
Report",3.5,Unknown,-1,Unknown,Investment & Asset Management,Financial Services,Unknown / Non-Applicable
"Portfolio Architect, Core Data Platforms",$168K - $281K (Employer est.),Macy’s3.4 ★,"Johns Creek, GA","Macy's is proudly America's Department Store. For more than 160 years, Macy's has served generations at every stage of their lives. Customers come to us for fashion, value, and celebration. Now is an exciting time to join Macy's, Inc. The face of retail is changing, and change requires innovation.

Macy's Technology provides modern tools, platforms, and services to all parts of the business. Our team supports millions of customers in connected commerce across the technology hub at Macy's. Join our team to help shape the future of e-commerce and set the pace in retail technology. Whether focused on store technology, supply chain tech, application security, merchandising systems, or the mobile app – you'll have opportunities to grow your career while finding meaningful ways to make a difference.

Job Overview:
The Portfolio Architect, Core Data Platforms defines a high-level portfolio architecture and advises on its implementation, drives alignment with enterprise standards while collaborating with Product leadership to drive out architecturally significant decisions and do just enough architecture to keep enabling development. This role will work closely with Domain and Product Architects to ensure alignment with the overall organization's vision. This role supports and facilitates architecture assurance activities and reimagines the future of technology for their product/platform portfolio. This role will be a critical contributor to Macy’s overall strategy for transactional and analytic data and help Macy’s on its journey in implementing our Google based data lake house.

Essential Functions:
Collaborate with the business (and respective domain/product inputs) to iteratively design an end-to-end technical solution for the portfolio
Identify required architectural significant decisions and associated risks
Collaboratively define key architectural components with domains/products through portfolio Agile events
Identify opportunities for reuse and extensibility balanced against complexity, cost and timelines
Collaborate with domains/products to identify non-functional requirements and provides appropriate guidance and leadership to help maintain quality solutions
Facilitate the resolution and escalation of technical impediments raised by domain/products through close collaboration with product counterparts
Manage, track, and refine functional and technical domain target state and roadmaps
Support and facilitate architecture governance activities and front-door management process
Manage evolution and advocacy for architecture function scope/model
Provide technical guidance to teams on architecture and design
Assess new opportunities and prioritize the roadmap

Qualifications and Competencies:
BA/BS in Computer Science, Information Technology, related field required, Master's Degree/MBA preferred.
We encourage candidates with either a bachelor’s degree or equivalent work experience in a related field to apply
15+ years of experience in software engineering, engineering management, and delivering large-scale transformation initiatives in retail required.
Executive leadership experience in managing multiple and large technology initiatives in distributed computing environments.
Expert architecture and design skills with proven track record of doing so at large enterprises.
Expert understanding of solution design and architecture standards.
Cross-disciplinary technical expertise with development, operations, security, quality assurance, architecture and more.
Experience in cloud technologies with a proven track record of migrating legacy on-premise applications into the cloud is required.
Experience driving data architecture utilizing cloud native technologies.
Experience constructing data mesh and advanced ingestion pipeline architectures.
Experience in Agile, especially managing or participating in multi-functional Agile teams within a large enterprise.
Excellent written and verbal communication skills, and an innate ability to easily communicate technical concepts
Articulate and persuasive leader who can serve as an effective member of the senior management team and who is able to communicate to a broad range of technical and non-technical staff.
Collaborates and engages others by gathering multiple views and being open to diverse perspectives.
Results and detail-oriented with excellent organizational skills while engaging and collaborative.
Able to think operationally and strategically, have strong analytical skills, and process disparate data and information into a cohesive and responsive action plan.
The ability to gain acceptance and win the confidence and cooperation of business partners is critical.
Able to juggle multiple priorities - can identify primary and secondary objectives, prioritize time, and communicate timeline to team members.
Ability and desire to take product/project ownership.
Ability to work a flexible schedule based on department and Company needs.
This position involves regular ambulating, sitting, hearing, and talking. May occasionally involve stooping, kneeling, or crouching. May involve close vision, color vision, depth perception, and focus adjustment. Involve use of hands and fingers for typing on keyboard and using a mouse. May be a need to move or lift items under 10 pounds.
TECH00
To apply to this job, click Apply Now
Show Less
Report",3.4,10000+ Employees,1858,Company - Public,"Department, Clothing & Shoe Stores",Retail & Wholesale,$10+ billion (USD)
Data Solutions Architect,$196K - $265K (Employer est.),Asana4.4 ★,"San Francisco, CA","We are looking for a Senior Solutions Architect within the Enterprise Technology function who will have the opportunity to demonstrate & provide technical skills to help shape strategy, architecture, design, and implementation of scalable solutions for the Data Intelligence team. We are looking for highly motivated individuals with excellent problem-solving skills and the ability to prioritize shifting workloads in a rapidly changing environment. An effective communicator, you'll be a confident leader equipped with strong people management skills and a genuine passion to make things happen in a dynamic organization.
The enterprise technology team supports insights with data and the technical systems that give our teams leverage to accomplish their goals. We work cross-functionally with Asana's business teams to understand their objectives and ensure they have the data and technical support they need to reach our audience.
What you'll achieve
Design a scalable, long-term architecture to address complex business problems.
Conduct workshops with senior stakeholders in Sales, Finance, and Engineering teams to collate technical and functional requirements.
Translate business requirements into technical solutions, utilizing strong business acumen.
Analyze current business practices, processes, and procedures, identifying opportunities for leveraging Data & Analytics solutions on multiple platforms.
Develop comprehensive solution proposals outlining project scope, approach, deliverables, and timeline.
Provide architectural expertise for Sales, Finance, and other analytics projects.
Identify risks, assumptions, and design Data & Analytics solutions.
Oversee the implementation of solutions, providing guidance to delivery teams.
Mentor and guide junior team members in all aspects of technical solutioning.
About you
15-20 years of experience in Big Data, data warehouse, and data analytics projects, with at least 2 years as a solutions architect.
Demonstrated experience in engaging with both technical and non-technical stakeholders.
Proven track record in building large-scale enterprise data architectures using commercial and/or open-source Data Analytics technologies.
Prior experience in developing data products for lead-to-renewal processes and finance simplification.
Ability to estimate complexity, effort, and cost, and produce solution architecture and business understandable presentations.
Excellent communication skills to lead and facilitate workshops.
Strong expertise in data stack technologies, including Snowflake, S3, Databricks, Snaplogic, and Tableau.
Proficiency in data modeling and architecting, with a strong foundation in data warehousing concepts, data normalization, and dimensional data modeling (e.g., OLAP or data vault).
Good knowledge of DevOps engineering using Continuous Integration/Delivery tools.
In-depth understanding of Cloud solutions (AWS, Azure, and/or GCP) and experience integrating them into traditional hosting/delivery models.
What we'll offer
Our comprehensive compensation package plays a big part in how we recognize you for the impact you have on our path to achieving our mission. We believe that compensation should be reflective of the value you create relative to the market value of your role. To ensure pay is fair and not impacted by biases, we're committed to looking at market value which is why we check ourselves and conduct a yearly pay equity audit.
For this role, the estimated base salary range is between $196,000- $265,000. The actual base salary will vary based on various factors, including market and individual qualifications objectively assessed during the interview process. The listed range above is a guideline, and the base salary range for this role may be modified.
In addition to base salary, your compensation package may include additional components such as equity, sales incentive pay (for most sales roles), and benefits. If you're interviewing for this role, speak with your Talent Acquisition Partner to learn more about the total compensation and benefits for this role.
About us
Asana helps teams orchestrate their work, from small projects to strategic initiatives. Millions of teams around the world rely on Asana to achieve their most important goals, faster. Asana has been named a Top 10 Best Workplace for 5 years in a row, is Fortune's #1 Best Workplace in the Bay Area, and one of Glassdoor's and Inc.'s Best Places to Work. After spending more than a year physically distanced, Team Asana is safely and mindfully returning to in-person collaboration, incorporating flexibility that adds hybrid elements to our office-centric culture. With 11+ offices all over the world, we are always looking for individuals who care about building technology that drives positive change in the world and a culture where everyone feels that they belong.
We believe in supporting people to do their best work and thrive, and building a diverse, equitable, and inclusive company is core to our mission. Our goal is to ensure that Asana upholds an inclusive environment where all people feel that they are equally respected and valued, whether they are applying for an open position or working at the company. We provide equal employment opportunities to all applicants without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by law.
#LI-BM2
Start your job application: click Easy Apply
Show Less
Report",4.4,1001 to 5000 Employees,2008,Company - Public,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable
Data Architect (Azure),$140K - $160K (Employer est.),LTI - Larsen & Toubro Infotech3.8 ★,"Charlotte, NC","Role: Azure Data Architect.
Location: Charlotte, NC (Onsite or Hybrid Model (3 days onsite/week)
Duration: FTE.
Responsibilities:
You are an expert in Azure Data Analytics having thorough understanding of Azure Data Platform tools
Expertise and hands-on experience on Azure Platform among: Data Factory, Azure Spark
Collaborate with project stakeholders like database administrators, technical architects, , business analysts, big data admins, security experts, information modelling experts to determine project needs and plan development and implementation strategies.
To define, review, and explain Data Architecture requirements & design to all the project stakeholders
Lead the migration of data from legacy systems to newly developed solution.
To create strategies and design solutions for wide variety use cases like Data Migration (end to end ETL process), database optimization, data architectural solutions for Analytics and Big Data Projects
To design, develop and troubleshoot highly complex technical problems in OLAP/OLTP/DW, Analytics, Big Data environments and provide solutions for Enterprise level Applications utilizing Azure Data Platform
To implement data quality processes for use with MDM, BI solutions, data warehouses, EAI solutions, etc.
Work on streamlining data flows and data models consistently
Have a keen focus on improving and tuning data quality, accessibility, performance and security needs
Skills Required
Bachelor/ master’s degree in computer science engineering,
Self-driven, and able to think holistically of the product roadmap
Performing reviews of data Architecture and Designs
Research new technologies and data modelling methods
Creative in solving complex business problems
Hands-on experience in business analysis, pre-sales, solution proposals, development
Excellent written & verbal communication
Job Type: Full-time
Salary: $140,000.00 - $160,000.00 per year
Benefits:
401(k)
401(k) matching
Dental insurance
Health insurance
Paid time off
Vision insurance
Schedule:
Monday to Friday
Ability to commute/relocate:
Charlotte, NC 28202: Reliably commute or planning to relocate before starting work (Required)
Experience:
Data Architect: 10 years (Required)
Azure: 8 years (Required)
Azure data factory: 5 years (Required)
Azure DataBricks: 5 years (Required)
Data modeling: 8 years (Required)
Adobe Spark: 5 years (Required)
Data Migration: 4 years (Required)
OLAP: 6 years (Required)
Work Location: In person
Show Less
Report",3.8,10000+ Employees,1997,Company - Private,Information Technology Support Services,Information Technology,Unknown / Non-Applicable
Senior Data Engineer,$50.00 - $55.00 Per Hour (Employer est.),Access to Future Inc,"Sunnyvale, CA","Required Skills
Tech stack requirements: • High-level Databricks experience • Python, bash, or shell scripting • Experience architecting data pipelines and providing strategy/guidance on how to build from scratch • SQL queries and building dashboards and reports (Databricks visualization preferred but ok with Tableau or PowerBI)
Location: 2 days/week on-site in Sunnyvale, CA or San Bruno, CA
Job Description
We are looking for a savvy Data Engineer to join our growing team of analytics experts. The role will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross-functional teams. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. The Data Engineer will support our software developers, database architects, data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple teams, systems, and products. The right candidate will be excited by the prospect of optimizing or even re-designing our data architecture to support our next generation of products and data initiatives.
Responsibilities for Data Engineer
Create and maintain optimal data pipeline architecture for data-intensive applications.
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using Azure SQL, Cosmo DB, Databricks, and other legacy databases.
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
Work with stakeholders including the Executive, Product, Data, and Design teams to assist with data-related technical issues and support their data infrastructure needs.
Keep our data separated and secure across national boundaries through multiple data centers and Azure regions.
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
Work with data and analytics experts to strive for greater functionality in our data systems.
Qualifications for Data Engineer
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Extensive Experience on Databricks on Azure Cloud platform, deep understanding of Delta lake, Lake House Architecture.
Programming experience in Python, Shell scripting, PySpark, and other data programming language.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with Data Visualization Dashboards, Metrics and etc.
Build processes supporting data transformation, data structures, metadata, dependency, and workload management.
A successful history of manipulating, processing, and extracting value from large disconnected datasets.
Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.
Familiar with Deployment tools like Docker and building CI/CD pipelines.
Experience supporting and working with cross-functional teams in a dynamic environment.
8+ years’ experience in software development, Data engineering, and
Bachelor’s degree in computer science, Statistics, Informatics, Information Systems or another quantitative field. A postgraduate/master’s degree is preferred.
Experience in Machine Learning and Data Modeling is a plus.
Job Type: Contract
Pay: $50.00 - $55.00 per hour
Experience level:
10 years
8 years
9 years
Schedule:
8 hour shift
Work Location: On the road
Show Less
Report",-1,1 to 50 Employees,-1,Company - Public,-1,-1,Unknown / Non-Applicable
Senior Principal Big Data Architect,$220K - $352K (Employer est.),Zillow3.9 ★,Remote,"About the team
Are you looking for an opportunity to help millions of customers navigate one of the biggest life decisions they'll ever make? Zillow's mission is to give people the power to unlock life's next chapter. We work with Designers, Engineers, Data Scientists, and Researchers to solve complex engineering problems and build products that transform the real estate industry. Our Product Teams are tasked with finding solutions to bridge the gap between you and your next address by delivering end-to-end experiences for customers actively shopping, renting, touring, or financing their home. Our Teams are also working to solve difficult problems for real estate agents in the field by providing industry leading platforms and tooling.

We maintain our competitive edge by making data driven decisions that we evolve through rapid testing and iteration to ensure we are launching enjoyable experiences to the world’s largest online real estate marketplace. We are not done yet. Our goal is to achieve Zillow 2.0, which will deliver seamlessly comprehensive solutions for buyers, sellers, and agents transacting with all the services Zillow provides. And, we need your help to do it!
About the role
As a Senior Principal Data Architect you will lead data architecture practice and represent Data Engineering at the enterprise level. The Data Engineering (DE) team is building the new generation of a Data Platform to enable implementation of Data Mesh principles and drastically improve time to value for all engineers who work with data. This work requires proven expertise in big data combined with a never ending ability to learn and evolve your thinking.

You will facilitate cross-team collaboration for defining and building enterprise data management architecture from principals to tools, oversee cross-functional adoption of new architecture, and enable a new level of engineering efficiency when working with data.

You will get to:
Defining enterprise data architecture for data platform
Working with Platform team on building platform functionality and with data engineers on adoption of platform functionality
Influencing and educating whole team on topics of modern data architecture
Shape data lakehouse data models and bring it to performant physical models specifically tailored to chosen storage format and data tech stack
Advance best DE architecture practices with focus on performance, scalability, security, enabling future capabilities and resilience. Drive and communicate architecture decisions across the Zillow Data Ecosystem.
Create cohesive architecture practices across DE producing standard methodologies and reference architecture that the team can leverage.
Create consensus and alignment on technology choices, data formats and data flows and provide guidance to teams on new technologies and future technical investments.
Create alignment with product teams on technical vision and long term product vision.
Represent the DE architecture in the Enterprise Architecture Group
This role has been categorized as a Remote position. “Remote” employees do not have a permanent corporate office workplace and, instead, work from a physical location of their choice which must be identified to the Company. Employees may live in any of the 50 US States, with limited exceptions. In certain cases, an employee in a remote-designated job may need to live in a specific region or time zone to support customers or clients as part of their role.
In California, Colorado, Connecticut, Nevada, New York City and Washington the standard base pay range for this role is $220,200.00 - $351,800.00 Annually. This base pay range is specific to California, Colorado, Connecticut, Nevada, New York City and Washington and may not be applicable to other locations.
In addition to a competitive base salary this position is also eligible for equity awards based on factors such as experience, performance and location. Actual amounts will vary depending on experience, performance and location.
Who you are
You have built data platforms and solutions, accumulated enough experience to know how to solve non-trivial challenges for a non-trivial business and how to shape enterprise data systems into a cohesive enterprise data management platform.
You can demonstrate successful projects related to data systems at medium and large size companies in leading architecture roles
Experience mentoring engineers and oversee project execution and delivery for adhering to blueprints and architecture principles.
You are designing enterprise systems and processes that span org structures and levels, inspire with your strong and robust vision and technical leadership
Previous experience leading technical organizations through change in leading data management practices to next level and enabling business to get data-rooted results
You are a master of concepts, but you think in code. There is a wide array of proven tools in your toolbox - Spark, advanced Python, unlimited SQL, deep knowledge of data streaming, intimate understanding of data structures. You are native to cloud thinker, ready to demonstrate your ideas with prototypes and partner with data engineers on complex implementations, helping guide work and showcase architecture principles
Ability to explain advanced concepts in simple to understand manner
Strong partnership with Zillow Enterprise Architecture (ZGEA) group advocating for data management
Able to balance multiple contending priorities in a fast-paced environment

Get to know us
Zillow is reimagining real estate to make home a reality for more and more people.
As the most-visited real estate website in the United States, Zillow® and its affiliates help movers find and win their home through digital solutions, first class partners, and easier buying, selling, financing and renting experiences. Millions of people visit Zillow Group sites every month to start their home search, and now they can rely on Zillow to help make it easier to move. The work we do helps people get home and no matter what job you're in, you will play a critical role in making home a reality for more and more people.
Our efforts to streamline the real estate transaction are supported by a deep-rooted culture of innovation, our passion to redefine the employee experience, a fundamental commitment to Equity and Belonging, and world-class benefits. These benefits include comprehensive medical, dental, vision, life, and disability coverages as well as parental leave, family benefits, retirement contributions, and paid time off. We’re also setting the standard for work experiences of the future, where our employees are supported in doing their best work and living a flexible, well-balanced life. But don’t just take our word for it. Read recent reviews on Glassdoor and recent recognition from multiple organizations, including: the 100 Best Companies to Work For, Glassdoor Employees’ Choice Award, Bloomberg Gender-Equality Index, Human Rights Campaign (HRC) Corporate Equity Index, and TIME 100 Most Influential Companies list.
Zillow Group is an equal opportunity employer committed to fostering an inclusive, innovative environment with the best employees. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. If you have a disability or special need that requires accommodation, please contact us at RecruitingAccessibility@zillowgroup.com.
Applicants who receive job offers from Zillow Group will be asked to sign a Proprietary Rights Agreement which includes confidentiality, intellectual property assignment, customer and employee non-solicitation, and non-competition provisions. If you are contacted for a role at Zillow Group and wish to review a copy of the Proprietary Rights Agreement prior to receiving an offer, you may request a copy from your Recruiter.
To apply to this job, click Apply Now
Show Less
Report",3.9,5001 to 10000 Employees,2005,Company - Public,Internet & Web Services,Information Technology,$1 to $5 billion (USD)
Sr. Data Solutions Architect,-1,Planet Fitness3.4 ★,Remote,"About Us:
Founded in 1992 in Dover, NH, Planet Fitness is one of the largest and fastest-growing franchisors and operators of fitness centers in the United States by number of members and locations. We have over 2,400+ stores in 50 states, the District of Columbia, Puerto Rico, Canada, Panama, Mexico, and Australia. More than 90% of Planet Fitness stores are owned and operated by independent business men and women.

At Planet Fitness, our unique mission has always been to enhance people’s lives by providing a high-quality fitness experience in a welcoming, non-intimidating environment. And we’re proud of the amazing Planet Fitness team that supports our clubs and team members. They are comprised of dynamic, dedicated, and talented individuals who represent our values of integrity, transparency, passion, respect, and excellence (while having fun!) in everything they do.

Joining the PF family means being part of a company that cares about bettering the health and wellbeing of our communities. It means being a part of a supportive, engaging workforce with an inclusive culture that values diversity and creates an environment where everyone can feel they belong. It means encouraging professional growth and development. It means making true, lasting connections with your co-workers with celebrations, team building activities and engaging corporate events! It means creating a positive impact in our local communities through our Judgement Free Generation® philanthropic initiative. It means being part of a brand that you can be proud of!

For the past 30 years, we’ve helped millions of people in their fitness journey and revolutionized the industry along the way. And we’re just getting started!
Overview:
The Sr. Data Solutions Architect will be responsible for creating and maintaining scalable architectures for end-to-end data solutions. In this role, you will work with a cross-functional group of business and technology stakeholders to understand business challenges and design data solutions that meet the data storage, processing, security, and visualization specifications required to deliver analytical solutions to support data-driven decision making. As our Sr. Data Solutions Architect, you will instill a culture of experimentation, prototyping and iterative solutioning to solve problems. You will also collaborate with the data engineering and business intelligence engineering teams to ensure implementation of best practices and adherence to architecture plans and patterns.

For team collaboration purposes, the ideal candidate currently resides in the CST or EST zones.
Responsibilities:
Collaborate with project teams and business stakeholders to assess functional requirements, design optimal solutions, and assist in the identification of data information needs.
Leverage strong business acumen to translate business requirements into scalable data solutions.
Synthesize technical and functional requirements into discrete solution architectures incorporating best practices and repeatable patterns for end-to-end solution implementation (i.e., data ingestion to visualization).
Support designing, building, and maintaining scalable data platforms that use emerging big data technologies.
Create and maintain vision for end-to-end data flows, logical data models, and architectures for data aggregation and consumption.
Perform analytical exploration and examination of data from multiple data sources.
Participate in enforcing data quality and governance best practices in the data platform.
Work with a multi-disciplinary team consisting of data analysts, data engineers, developers, and data consumers in an agile, fast-paced environment.
Work with and support a team that is globally located.
Work with a cross section of business stakeholders, data analysts and management to understand and document business requirements.
Work with project managers and data architects to create and document technical project proposals that include estimates, planning and schedules.
Participate in review processes that involve architecture, design and quality assurance to preemptively identify conflicts and ensure consistency of implementation.
Ensure strict adherence to documentation best practices and change control processes.
Perform other duties as assigned.
Qualifications:
Bachelor’s degree in Computer Science, Mathematics, Data Analytics, Information Systems or a related field, required
10+ years of direct experience in Big Data, Data Warehousing, Data Analytics, and/or Information Management related projects
6+ years of direct experience in cloud data solution architectures, design and development including ETL, data warehousing, data lakes, and big data
5+ years of direct experience using Snowflake and Snowflake utilities such as SnowSQL and SnowPipe
5+ years of direct experience with developing and deploying ETL pipelines on a big data platform using Hadoop or Apache Spark
5+ years of direct experience working in a cloud environment such as AWS, Azure or GCP
4+ years of direct experience with streaming data architectures and technologies for real-time and low-latency data processing
Demonstrated ability to describe technical solutions in business language required
Experience and familiarly with data virtualization tools and platforms
Must be self-sufficient and proactive
Deep understanding of agile development methods including: core values, guiding principles, and key agile practices
A strong understanding of data mining, predictive modeling, and statistical analysis
Experience working in retail business (preferred)
Experience working in a franchised business (preferred)
Excellent critical thinking and problem-solving skills
Extremely detail-oriented, efficient, and organized with an exceptional ability to establish and balance multiple priorities and objectives
Excellent presentation and communication skills along with the ability to communicate effectively across all levels of the organization
Able to establish and maintain effective, collaborative work relationships with diverse individuals, internally and externally
Creative, progressive, thought leadership with the ability to influence at all levels of the organization
Dedicated learner with a natural curiosity for consistent growth
Exhibits comfort, ease, and flexibility working in an extremely fast-paced ever-changing, deadline-driven environment
Cooperative team player with an upbeat, positive, “can-do” attitude!
Must be available to work off-hours and provide on-call support as needed
Perks:
Remote work allowed
Volunteer days off
Competitive salaries and comprehensive benefits package, including medical, pharmacy, dental and vision benefits
Generous vacation/holiday pay
401(k) Retirement
Employee Stock Purchase Program
Childcare reimbursement
Pet care reimbursement
Learning and development programs
Discount programs, including vacations, theme parks, shopping, meal delivery services & much more
Free Black Card membership and fun exercise incentives
Company-sponsored social events
Start your job application: click Apply Now
Show Less
Report",3.4,201 to 500 Employees,1992,Company - Public,Beauty & Wellness,Personal Consumer Services,$5 to $25 million (USD)
Big Data Architect,$93K - $166K (Employer est.),PSRTEK4.5 ★,"Denver, CO","Role: Data Architect
Location: Denver CO, (Day 1 Onsite)
Job Description
Big Data Architect experienced to Manage the Data with core foundational Data Architecture knowledge (12 to 15+yrs)
Data Archival, taxonomy, classification, Tagging,
Business Cataloging
Access control to Data
Data Governance
Data Management
Data Archival
Build Business glossary
Build Metadata
AWS Technologies skills or any cloud technologies a plus
Job Type: Contract
Salary: $92,559.20 - $165,638.64 per year
Ability to commute/relocate:
Denver, CO 80014: Reliably commute or planning to relocate before starting work (Required)
Experience:
Big Data: 10 years (Preferred)
Work Location: In person
Speak with the employer
+91 609-934-3291
Show Less
Report",4.5,Unknown,-1,Company - Private,Information Technology Support Services,Information Technology,Unknown / Non-Applicable
Senior Azure Data Architect,-1,Lighthouse MTG LLC,Rhode Island,"Azure Data Architect
Description:
Spyglass MTG (Microsoft Technology Group) is a Microsoft Gold Certified Partner. We hire people who are professional consultants in addition to being highly competent performers in their specific discipline. As a Consultant at Spyglass MTG you will be working on projects to develop Microsoft technology focused solutions for a variety of clients in industries such as Financial Services, Healthcare, Life Sciences, Manufacturing and Higher Education. Our office is in Lincoln, RI, however our clients are typically located in the Greater Boston and New England area. You will be working in a team environment that consists of Spyglass and Client members.
As an Azure Data Architect, you will join our increasingly growing and exciting Azure Data and Analytics practice. You will be required to apply enterprise principles, standards and practices serving as the conduit for influencing our clients Enterprise Data Architecture’s direction while optimizing solutions for them. You will evaluate business needs and objectives, current and future state and transform into Azure data solutions that meet performance, scalability, reliability, and security needs. You must also provide technical guidance and oversight to development team, mentor those in less senior positions and ensure a consistent state of excellence during and post-delivery of the solution. You will be integral to the design, development, and delivery of all modern data solutions on Azure for our clients.
Candidate Expectations:
Architect, Design and deploy architecture to support data transformation, data structures, metadata, dependency, and workload management.
Experience deploying modern data solutions leveraging components like Azure functions, Azure Data Factory, Data Flows, Azure Data Lake, Azure SQL, Azure Synapse, Streaming Analytics and more.
Provide oversight and guidance to data, BI and ML engineering teams. It is expected that you provide direct experience within these core areas.
Experience with one or more languages: Python & Pyspark, T-SQL, SparkR & R, Scala.
Experience with code deployment in Azure Databricks environment.
Familiarity with DevOps tools like Azure DevOps, Jenkins, Maven etc.
Experience working with Azure data platforms, integration techniques & self-service data preparation.
Assist business users on functional and data requirements to enhance data models and pipelines.
Experience in requirements analysis, design, and prototyping.
Basic Qualifications:
8+ years of relevant professional technology experience
5+ years of experience in a programming language like SQL, Python or Scala
5+ years of working experience with SQL Server, data warehousing and data analytics projects
5+ years of experience data engineering in cloud and on-prem environments
MUST HAVE Experience deploying Azure data solution with Azure Data Factory, Azure Synapse, Data Lake or other Azure data service.
MUST HAVE Experience architecting and Azure data solution with Azure Data Factory, Azure Synapse, Data Lake or other Azure data service.
MUST HAVE Experience data engineering Azure Data Factory or Azure Synapse
Experience building scalable data platforms.
Experience with Azure solutions and infrastructure
Minimum of a Bachelor’s degree in Computer Science, Computer Engineering, Software Design, Software Engineering, or a related field, or equivalent alternative education, skills, and/or practical experience
Preferred Qualifications:
MS Certified: Data Engineering Associate
MS Certified: Azure Solutions Architect Expert
3+ years of experience with Azure SQL, Azure Synapse, SQL DW or other Cloud Data Services.
2+ years of experience with version control and DevOps or DataOps.
5+ years programming with SQL, Python, Scala or R.
5+ years developing, deploying, and testing data pipelines in Azure or other cloud provider.
5+ years of data engineering with Hadoop, Spark, Databricks, SSIS or other data integration tool.
Master’s degree in Computer Science, Computer Engineering, Software Design, Software Engineering, or a related field, or equivalent alternative education, skills, and/or practical experience.
Benefits:
Medical, Vision and Dental Plans
Life and Disability Insurance
Open PTO Policy
Holiday PTO
Paid training certification
Bonus plan
401k
Flexible working arrangements
& more
All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, transgender status, national origin, citizenship, age, disability or protected veteran status.
Show Less
Report",-1,Unknown,-1,Company - Public,-1,-1,Unknown / Non-Applicable
"Architect, Data Engineering",$90K - $238K (Employer est.),Pennymac3.0 ★,"Agoura Hills, CA","PENNYMAC:
Pennymac (NYSE: PFSI) is a specialty financial services firm with a comprehensive mortgage platform and integrated business focused on the production and servicing of U.S. mortgage loans and the management of investments related to the U.S. mortgage market.

At Pennymac, our people are the foundation of our success and at the heart of our dynamic work culture. Together, we work towards a unified goal of helping millions of Americans achieve aspirations of homeownership through the complete mortgage journey.
A Typical Day:
The Architect, Data Engineering will assess the needs and challenges of a client and formulate the technical roadmap and technology solution that will support their business strategies and goals. As the Architect, Data Engineering, you will develop and manage relationships with internal and external technology partners to deliver projects on time, on budget, and with quality.

The Architect, Data Engineering will:

Orchestrate the management of technology scope and risks
Initiate new, and improve existing, systems processes
Manage and deliver multiple streams of projects end-to-end
Develop artifacts following the SDLC in place, including technical specifications, design specifications, unit test cases, and unit test plan and code, using tools such as Python, Snowflake, AWS, Tableau, etc.
Participate/assist in development of deployment plans for the systems developed
Perform other related duties as required and assigned
Demonstrate behaviors which are aligned with the organization’s desired culture and values
What You’ll Bring:
Bachelor’s degree or equivalent work experience
7+ years experience working with IT leadership to create technical strategies and with senior IT groups in an advisory role
Expertise in multiple technologies (such as: AWS, Snowflake, Python, SQL, Tableau, Data Integration, API, Internal Web Design) across software engineering, security, data interchange, data management, etc.
Must have experience in developing Enterprise level applications using an SOA-based Architecture (Web Service, Windows Service etc.)
Experience with relational databases (MySQL, PostgreSQL, SQL Server, DynamoDB, Snowflake)
Must have worked in a multi-developer/multi-site environment with multi-site management experience
Why You Should Join:
As one of the top mortgage lenders in the country, Pennymac has helped over 4 million lifetime homeowners achieve and sustain their aspirations of home. Our vision is to be the most trusted partner for home. Together, 4,000 Pennymac team members across the country are guided by our core values: to be Accountable, Reliable and Ethical in all that we do.
Pennymac is committed to conducting a business that makes positive contributions and promotes long-term sustainable growth and to fostering an equitable and inclusive environment, where all employees and customers feel valued, respected and supported.

Benefits That Bring It Home: Whether you're looking for flexible benefits for today, setting up short-term goals for tomorrow, or planning for long-term success and retirement, Pennymac's benefits have you covered. Some key benefits include:
Comprehensive Medical, Dental, and Vision
Paid Time Off Programs including vacation, holidays, illness, and parental leave
Wellness Programs, Employee Recognition Programs, and onsite gyms and cafe style dining (select locations)
Retirement benefits, life insurance, 401k match, and tuition reimbursement
Philanthropy Programs including matching gifts, volunteer grants, charitable grants and corporate sponsorships

To learn more about our benefits visit: https://pennymacnews.page.link/benefits

Compensation: Individual salary may vary based on multiple factors including specific role, geographic location / market data, and skills and experience as defined below:
Lower in range - Building skills and experience in the role
Mid-range - Experience and skills align with proficiency in the role
Higher in range - Experience and skills add value above typical requirements of the role

Some roles may be eligible for performance-based compensation and/or stock-based incentives awarded to employees based on company and individual performance.

Salary: $90,000 - $237,500 Work Model: HYBRID
To apply to this job, click Apply Now
Show Less
Report",3.0,1001 to 5000 Employees,2008,Company - Public,Banking & Lending,Financial Services,$1 to $5 billion (USD)
"Sr Lead Solution Architect - Remote, US",$100K - $224K (Employer est.),Lumen3.5 ★,Remote,"About Lumen
Lumen is guided by our belief that humanity is at its best when technology advances the way we live and work. With 450,000 route fiber miles serving customers in more than 60 countries, we deliver the fastest, most secure global platform for applications and data to help businesses, government and communities deliver amazing experiences. Learn more about Lumen’s network, edge cloud, security and communication and collaboration solutions and our purpose to further human progress through technology at news.lumen.com, LinkedIn: /lumentechnologies, Twitter: @lumentechco, Facebook: /lumentechnologies, Instagram: @lumentechnologies and YouTube: /lumentechnologies.
The Role
Lumen is looking for Solution Architects who are passionate about leveraging technology innovation for the betterment of humanity. This exciting solution architecture role will work in partnership with the Business Units, leading innovative conversations that help shape the growth of our Mass Markets ecosystem. Solution Architects design and architect solutions utilizing our technology services platform. The successful Solution Architect must have a strong desire to leverage their technical and communication skills, including business acumen, to understand business requirements, develop a technical architecture, and effectively present solutions that address our business partner’s requirements and provide business value.
The Solution Architect will be responsible for analyzing customer needs and requirements through strategic discovery, utilizing technical thought leadership, discussing industry best practices, and then delivering a technical solution that meets or exceeds the business need – including non-functional specifications, enablers, 3rd party requirements, and delivers the documented business value.
The Main Responsibilities
Business Meetings: Leads and attends business meetings in person and via collaboration tools. Prepares and delivers technical proposals and presentations with the appropriate level of business acumen for the audience. Provides detailed, specific responses to solution and technology questions. Demonstrates strong solution ‘selling abilities’ and effective, proactive business communications. Interacts with all levels of IT and Business teams.
Solution Development: Analyze and identify our Business Partner’s business and technology objectives, conduct full technical discovery, and architect business solutions to meet gathered requirements. Assess business and operations impacted by technology. Craft and propose solutions that meet the business’s requirements and objectives by asking probing questions that are meaningful to the business to collect information that enables the architecture team to be more effective and responsive to clients’ needs. Ability to complete complex custom designs.
Customer Advocate: Acts as a client advocate, participating in efforts including technical presentations, architecture design discussions, proof-of-concept engagements, RFP/RFI responses, solution demonstrations, and technical workshops. Deliver findings including key pain points, proposed solutions to meet business needs, and ROI where applicable. Design, architect and demonstrate visionary solutions in a way that closely reflects our client's technology roadmap.
What We Look For in a Candidate
Education: B.S. Computer Science, Engineering, MIS, or equivalent work experience in the private sector
Experience: Minimum of 8+ years in developing IT solutions, including but not limited to: Telecommunications B/OSS system architecture, Operations, Infrastructure/Database Architecture, and/or Applications Development
Technical Knowledge: Possess knowledge of Mass Markets Architecture and Design. Demonstrate technical knowledge across one or more Lumen technology pillars.
Communication: Ability to lead & engage in technical workshops, and solution discussions with Business and IT Stakeholders. Strong listening, reasoning, and objection handling skills.
Problem-Solving: General problem-solving skills and ability to methodically understand and resolve complex issues. Must demonstrate the ability to focus ambiguous business needs into specific, deliverable requirements. Must demonstrate creative solution development.
Work Style: Ability to work independently, or as part of a team to build complex customer solutions. Must be able to build strong team relationships and easily transfer technical information. Ability to work under pressure with tight deadlines and on multiple projects simultaneously. Must be very detail-oriented and demonstrate a high degree of accuracy. Attention to detail with good organizational capabilities. Ability to prioritize with good time management skills.
Presentation Skills: Strong presentation skills as well as the ability to build and present high-quality solutions to both technical and executive audiences.

Preferred Skills:
Broad technology experience in application development, cloud architecture, Relational/NoSQL databases, analytics, machine learning, DevOps, management, and monitoring
Industry experience in Telco or ECommerce or Agent Ordering
Experience architecting/designing solutions in the cloud and non-cloud platforms
Expertise in documenting and understanding different types of diagrams including but not limited to: Dataflow diagrams, Context diagrams, and Sequence diagrams
What to Expect Next
Requisition #: 328548
When applying for a position, you may be subject to a background screen (criminal records check, motor vehicle report, and/or drug screen), depending on the requirements for the position. More information on what’s included in these checks can be found in the Post Offer section of our FAQ page. Job-related concerns noted in the background screen may disqualify you from the new position or your current role. Background results will be evaluated on a case-by-case basis.
EEO Statement
We are committed to providing equal employment opportunities to all persons regardless of race, color, ancestry, citizenship, national origin, religion, veteran status, disability, genetic characteristic or information, age, gender, sexual orientation, gender identity, marital status, family status, pregnancy, or other legally protected status (collectively, “protected statuses”). We do not tolerate unlawful discrimination in any employment decisions, including recruiting, hiring, compensation, promotion, benefits, discipline, termination, job assignments or training.
NOTE: Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.
Disclaimer
The above job definition information has been designed to indicate the general nature and level of work performed by employees within this classification. It is not designed to contain or be interpreted as a comprehensive inventory of all duties, responsibilities, and qualifications required of employees assigned to this job. Job duties and responsibilities are subject to change based on changing business needs and conditions.
Salary Range
Salary Min :
100440
Salary Max :
223680
This information reflects the anticipated base salary range for this position based on current national data. Minimums and maximums may vary based on location. Individual pay is based on skills, experience and other relevant factors.
This position is eligible for either short-term incentives or sales compensation. Director and VP positions also are eligible for long-term incentive. To learn more about our bonus structure, you can view additional information here. We're able to answer any additional questions you may have as you move through the selection process.
As part of our comprehensive benefits package, Lumen offers a broad range of Health, Life, Voluntary Lifestyle and other benefits and perks that enhance your physical, mental, emotional and financial wellbeing. You can learn more by clicking here.
Note: For union-represented postings, wage rates and ranges are governed by applicable collective bargaining agreement provisions.
Start your job application: click Apply Now
Show Less
Report",3.5,10000+ Employees,1968,Company - Public,Enterprise Software & Network Solutions,Information Technology,$10+ billion (USD)
Senior Microsoft 365 Data Security Architect,$99K - $135K (Glassdoor est.),BDO3.8 ★,"Oak Brook, IL","Job Summary:
The Microsoft Compliance and Privacy Architect Manager leads the implementation of a variety of complex Microsoft 365, Microsoft Compliance, and Microsoft Priva solutions. Responsibilities for this role include analyzing, designing, and determining methods to achieve customer business goals for hybrid and cloud-based Microsoft compliance, security, and privacy outcomes. The Compliance and Privacy Architect considers business needs and client delivery then identifies the best approach to resolve.
Job Duties:
Leads the design and implementation of cloud infrastructure compliance and/or privacy solutions for architecture within Microsoft 365 and Microsoft Azure products
Designs, documents, and creates Microsoft 365 solution integrations for security and compliance
Manages small project teams and/or working across geographies with solution teams to create a holistic Microsoft 365 security and/or compliance implementation for a customer
Leads advanced troubleshooting on Enterprise Mobility + Security (EMS), Microsoft Purview, Microsoft Priva deployment and integration
Identifies, troubleshoots, and configures where multiple Microsoft 365 products interact, such as Microsoft Teams, Microsoft Exchange, Microsoft Purview, and Microsoft Priva to create a customer’s intended data protection and/or compliance outcome
Leads the assessment of customers’ Microsoft 365, Microsoft Purview, Defender for Endpoint and/or Defender for Cloud Apps configuration against customer requirements and recommends enhancement or optimization opportunities
Integrates customer Microsoft 365, Microsoft Purview, Microsoft Priva and other associated technologies to customer security operations and/or logging platforms
Configures and troubleshoots integrated tools such as Microsoft Defender for Cloud Apps or Microsoft Defender for Endpoint to consume and/or contribute necessary protection and/or policies for customer outcomes
Communicates with clients and project leads in a highly professional and timely manner
Leads technical teams through the design, implementation, testing, and deployment of projects, providing guidance and oversight
Provides administration and configuration support for Microsoft Purview and/or Microsoft Priva, and associated cloud or on-premises systems and products as a limited duration project, as needed
Must be open to travel to client sites, if needed
Other duties as required
Supervisory Responsibilities:
Manages Infrastructure solutions and delivery team
Proactively manages team to defined practice KPIs while responsible for team performance metrics, yield, and developing new skills
Evaluates and builds a high performing team while supporting the team’s hiring, recruiting, and retention
Manages professional development of team and leads performance evaluations of direct reports
Qualifications, Knowledge, Skills, and Abilities:
Education:
High school diploma, required
Bachelor’s degree, preferred
Experience:
Five (5) or more years of technical infrastructure implementation experience with increasing responsibility within Microsoft 365 Cloud Solutions, required
Four (4) or more years of experience in cloud and/or on-premises infrastructure security or with endpoint data loss prevention and/or endpoint security products, required
Experienced in one (1) or more of the following, required:
Design, Deployment, and Management of Endpoint Security Controls
Managing Endpoint Security technologies like Microsoft Defender for Endpoint
Managing security of Cloud workload environments in Microsoft Azure
Designing and deploying security and compliance for Microsoft 365 and/or Microsoft Azure cloud migrations
Designing data governance rules and/or policies implemented in one or more technical products
Five (5) or more years of experience in an advanced engineering role implementing Microsoft security and compliance components such as Data Loss Prevention, Microsoft 365 compliance, and/or Microsoft 365 security products, preferred
Experience implementing technical safeguards for a major regulatory compliance obligation (SOX, PCI, HIPAA, CCPA, GDPR or similar), preferred
Experience with information technology architecture and design, preferred
Client facing consulting experience, preferred
License/Certifications:
Certification on Microsoft 365 security and/or compliance, preferred
Software:
Experience with design and implementation in one (1) or more products such as Microsoft Purview or predecessor technologies from Microsoft security and compliance, required
Experience with Information Protection labeling and data classification, required
Intermediate experience with Microsoft security products for Microsoft 365 and/or Microsoft Azure, preferred
Microsoft Defender for Cloud Apps / Microsoft Cloud App Security, or another major industry CASB platform, preferred
Microsoft Records Management and/or Information Governance processes, preferred
Advanced knowledge of Microsoft 365 and Azure products for security, governance, and data protection, preferred
Language:
N/A
Other Knowledge, Skills & Abilities:
Superior verbal and written communication skills
Ability to troubleshoot issues, identify solutions, and lead small incident teams to complete necessary repairs and implementation
Strong analytical, facilitation, documentation, and communication skills
Strong project planning, scoping, and management skills
Strong business process analysis & design and process flow skills
Ability to work in a deadline-driven environment while handling multiple projects/tasks simultaneously with a focus on details
Ability to successfully multi-task while working independently or within a group environment
Ability to work well under pressure while dealing with unexpected problems in a professional manner
Ability to work well in a cross-functional team environment

BDO delivers assurance, tax, digital technology solutions and financial advisory services to clients throughout the country and around the globe. We offer numerous industry-specific practices, world-class resources, and an unparalleled commitment to meeting our clients’ needs. We currently serve more than 400 publicly traded domestic and international clients.
Unparalleled partner-involvement
Deep industry knowledge and participation
Geographic coverage across the U.S.
Cohesive global network
Focused capabilities across disciplines
BDO brings world-class resources and exceptional service to each and every one of our clients. BDO USA is a member of BDO International, the world’s fifth largest accounting network.

BDO offers a competitive Total Rewards package that encompass so much more than – “traditional benefits”. Our wide range of rewards and our employees’ ability to customize rewards to their individual needs are two of the reasons why BDO has been honored with so many workplace awards, including 100 Best Companies for Working Parents, Working Mother 100 Best Companies, Top Entry Level Employer, 2022 National Best & Brightest Companies to Work For and more.
Some examples of our Total Rewards offerings include:
Competitive pay and eligibility for an annual performance bonus.
A 401k plan plus an employer match
Comprehensive, medical, dental, vision, FSA, and prescription insurance from day one
Competitive Paid Time Off with daily accrual from day one of employment, plus paid holidays
Paid Parental Leave
Adoption Assistance
Firm paid life insurance
Wellness programs
Additional offerings include BDO Flex, Group Legal insurance, Pet insurance and Long-Term Care Insurance
Above offerings may be subject to eligibility requirements.
Click here to find out more!
Show Less
Report",3.8,10000+ Employees,2007,Company - Private,Accounting & Tax,Financial Services,$10+ billion (USD)
"Data Architect, IT",$83K - $129K (Glassdoor est.),UofL Health3.4 ★,"Louisville, KY","Overview:
We are Hiring for our Information Technology team.
Shift Options: Full Time & Days

About Us
UofL Health is a fully integrated regional academic health system with seven hospitals, four medical centers, nearly 200 physician practice locations, more than 700 providers, the Frazier Rehabilitation Institute and the Brown Cancer Center.
With more than 12,000 team members—physicians, surgeons, nurses, pharmacists and other highly skilled health care professionals—UofL Health is focused on one mission: delivering patient-centered care to each and every patient each and every day.

Our Mission
As an academic health care system, we will transform the health of the communities we serve through compassionate, innovative, patient-centered care.

Job Summary
The Data Architect supports the design, development and implementation of all data initiatives at ULH. Leads the enterprise information management strategy fostering IT – Business collaboration in understanding of enterprise data, binding disparate, heterogenous data sources together in a framework for access and sharing of data, developing data trust across the organization and instituting best practices and standards in data use.

Leads the implementation, enhancement and on-going support of enterprise data platform utilizing data modeling concepts for model extension and ETL programs to transform and ingest data.
Supports the data through its life cycle utilizing data governance principles that ensure data quality, integrity, stewardship, security, literacy and adoption.
Develops and enforces implementation of standards and best practices involved in data modeling (conceptual/logical/physical models), data architecture design patterns (EDW/data marts/data lakes) and ETL.
Conducts research and makes recommendations on products, tools, services, protocols and standards that will support ULH’s data management strategy.
Works in concert with BI Developers and business teams to understand business requirements and translating those requirements into developing value-add BI/Analytics solutions.
Designs and maintains a curriculum for coaching and training current and prospective end users to better understand how these tools can enhance business decision making capabilities.
Provides Level 1, 2 and 3 support for day-to-day production issues maintaining documentation in the appropriate tracking systems while adhering to prescribed escalation & change control procedures. Includes on call rotation.
Adheres to all Security Standards as set forth by the organization and National guidelines.
Additional tasks/responsibilities as defined.
Responsibilities:
Works closely with Analytics leadership team, business teams and IT infrastructure teams to design, implement and support the goals and objectives of the organization set by the leadership.
Leads the implementation, enhancement and on-going support of enterprise data platform utilizing data modeling concepts for model extension and ETL programs to transform and ingest data.
Conducts research and makes recommendations on products, tools, services, protocols and standards that will support ULH’s data management and BI strategies.
Supports the data through its life cycle utilizing data governance principles that ensure data quality, integrity, stewardship, security, literacy and adoption.
Proactively communicate and collaborate with internal and external customers to analyze information needs and functional requirements and delivery.
Performs Tier 1, 2 and 3 Application/Systems support.
Maintains relationship with vendors of hospital applications to understand current and future features and functionality and product life cycle.
Qualifications:
Education / Accreditation / Licensure (required & preferred):
Bachelor’s Degree in Business, Information Science or Computer Science required. Master’s Degree highly preferred

Experience (required and preferred):
7+ years of experience in supporting/developing/extending data warehouse/data mart solutions required.
5+ years of experience with data modeling concepts translating business requirements into conceptual, logical and physical models required.
5+ years of experience in ETL development preferably with SSIS required.
Expert knowledge of data governance practices and data life cycle management highly desired.
Experience in Agile development methodology for analytics projects required.
Experience and ability in working directly with vendors, customers and other IT teams.
To apply to this job, click Apply Now
Show Less
Report",3.4,1001 to 5000 Employees,-1,Hospital,Health Care Services & Hospitals,Healthcare,$100 to $500 million (USD)
Data Solutions Architect,$114K - $157K (Glassdoor est.),Koch Industries3.8 ★,"Atlanta, GA","Your Job
We are seeking an innovative and self-driven Data Solutions Architect to join our dynamic, fast-paced data management, enablement, and transformation team. Your role will be pivotal in accelerating the realization of Koch's transformation vision through the creation of technical solutions that maximize the value of our data assets. In this role, you will partner with product owners and consumers to tailor solutions for business problems and contribute to the creation and dissemination of data solution architecture patterns, practices, and reusable frameworks. You'll be required to coordinate with fellow architects and engineers, creating cloud data solutions and implementing logical data models in line with business requirements. Your ability to research and recommend new technologies, coupled with strong conceptual, analytical, and problem-solving skills, will be key in enhancing our existing data products and driving business value.
Our Team
The DMET (Data Management, Enablement and Transformation) team is focused on developing a long-term sustainable capability utilizing data and technology to transform finance. This includes a diverse group with multiple teams focused on data platform technologies, specific data products and transformation. Our strategy will empower the finance and tax organizations to create superior value while consuming few resources, unlocking analytical capabilities, mitigating risk, and meeting ever-changing regulatory requirements.
What You Will Do
Collaborate with product owners and consumers to comprehend the opportunity and devise strategic approaches to solve business problems.
Develop and share solution architecture patterns, practices, reusable frameworks, and best practices applicable across products/domains/Koch.
Work in harmony with peer architects across the team/Koch to enhance and align with enterprise best practices.
Analyze end user requirements and collaborate with engineers to craft data solutions and application integrations, adhering to the Koch Architecture First framework.
Collaborate with a diverse group of IT teams, including business analysts, project managers, architects, developers, and vendors, to design modern cloud data solutions (data pipelines, lakes, warehouses, marts, analytics).
Design, develop, implement, and manage logical data models in line with business requirements and aligned with conceptual models.
Work alongside data engineers and/or data analysts to procure data, ensure data quality and distribution, and prepare key elements for analytics.
Conduct research and recommend new technologies and applications to enhance existing data products, optimize costs/performance, and reduce time-to-business value.
Exhibit strong conceptual, analytical, collaboration, problem-solving skills, and an ability to articulate ideas and technical solutions effectively.

Who You Are (Basic Qualifications)
Proven experience in designing, implementing, managing, and maintaining cloud-based data lakes, warehouses, reporting and analytics solutions.
Experience in analyzing end user requirements and devising solutions that align with contemporary best practices in data solution architecture.
Demonstrable hands-on experience in business intelligence, data engineering, ETL, multi-dimensional data warehouses, and cubes, with proficiency in related languages and frameworks such as SQL, Python, etc. Familiarity with visualization tools like Tableau, Alteryx, or PowerBI is also desired.
Capable of creating data models that pull from financial and accounting data sources, with an understanding of the financial data lifecycle in standard ERP deployments.
General understanding of common DevSecOps/DataOps and CICD processes and methodologies

What Will Put You Ahead
Providing strategic insight and direction to aid in the design and implementation of the DevSecOps and DataOps aspects of the project and solution.
SnowPro certified and/or AWS Certified Big Data - Specialty and/or AWS Certified Solution Architect
Experience in data virtualization platforms (e.g., AtScale, Denodo, etc)
Proficiency in graph database technology, specifically Neo4j
Expertise in tuning and cost-optimizing for dynamic requirements
Ability to collaboratively drive consensus on complex matters involving diverse stakeholders where there may be varying points of view.

At Koch companies, we are entrepreneurs. This means we openly challenge the status quo, find new ways to create value and get rewarded for our individual contributions. Any compensation range provided for a role is an estimate determined by available market data. The actual amount may be higher or lower than the range provided considering each candidate's knowledge, skills, abilities, and geographic location. If you have questions, please speak to your recruiter about the flexibility and detail of our compensation philosophy.
Hiring Philosophy
All Koch companies value diversity of thought, perspectives, aptitudes, experiences, and backgrounds. We are Military Ready and Second Chance employers. Learn more about our hiring philosophy here .
Who We Are
Koch Industries creates and innovates a wide spectrum of products and services that make life better. Our work spans a vast number of industries across the world, including engineered technology, refining, chemicals and polymers, pulp and paper, glass, electronics and many more. Headquartered in Wichita, Kansas, Koch employs 122,000+ employees across the globe.
At Koch, employees are empowered to do what they do best to make life better. Learn how our business philosophy helps employees unleash their potential while creating value for themselves and the company.
Our Benefits
Our goal is for each employee, and their families, to live fulfilling and healthy lives. We provide essential resources and support to build and maintain physical, financial, and emotional strength focusing on overall wellbeing so you can focus on what matters most. Our benefits plan includes medical, dental, vision, flexible spending and health savings accounts, life insurance, ADD, disability, retirement, paid vacation/time off, educational assistance, and may also include infertility assistance, paid parental leave and adoption assistance. Specific eligibility criteria is set by the applicable Summary Plan Description, policy or guideline and benefits may vary by geographic region. If you have questions on what benefits apply to you, please speak to your recruiter.
Equal Opportunities
Equal Opportunity Employer, including disability and protected veteran status. Except where prohibited by state law, all offers of employment are conditioned upon successfully passing a drug test. This employer uses E-Verify. Please visit the following website for additional information: http://www.kochcareers.com/doc/Everify.pdf
#LI-KR5
Start your job application: click Apply Now
Show Less
Report",3.8,10000+ Employees,1940,Company - Private,Energy & Utilities,"Energy, Mining & Utilities",$10+ billion (USD)
Sr. Data Architect,-1,Planet Fitness3.4 ★,Remote,"About Us:
Founded in 1992 in Dover, NH, Planet Fitness is one of the largest and fastest-growing franchisors and operators of fitness centers in the United States by number of members and locations. We have over 2,400+ stores in 50 states, the District of Columbia, Puerto Rico, Canada, Panama, Mexico, and Australia. More than 90% of Planet Fitness stores are owned and operated by independent business men and women.

At Planet Fitness, our unique mission has always been to enhance people’s lives by providing a high-quality fitness experience in a welcoming, non-intimidating environment. And we’re proud of the amazing Planet Fitness team that supports our clubs and team members. They are comprised of dynamic, dedicated, and talented individuals who represent our values of integrity, transparency, passion, respect, and excellence (while having fun!) in everything they do.

Joining the PF family means being part of a company that cares about bettering the health and wellbeing of our communities. It means being a part of a supportive, engaging workforce with an inclusive culture that values diversity and creates an environment where everyone can feel they belong. It means encouraging professional growth and development. It means making true, lasting connections with your co-workers with celebrations, team building activities and engaging corporate events! It means creating a positive impact in our local communities through our Judgement Free Generation® philanthropic initiative. It means being part of a brand that you can be proud of!

For the past 30 years, we’ve helped millions of people in their fitness journey and revolutionized the industry along the way. And we’re just getting started!
Overview:
The Sr. Data Architect will be responsible for creating and maintaining a scalable enterprise data architecture at Planet Fitness. In this role, you will facilitate the development of data modeling standards, guidelines, and techniques. You will collaborate across the data engineering, business intelligence engineering, and data governance teams to ensure data architectures are consistent and adhere to defined policies and standards. And as our Sr. Data Architect, you will also collaborate with the broader technology organization to implement data management best practices and improve data quality at the source of truth/system of record.

For team collaboration purposes, the ideal candidate currently resides in the CST or EST zones.
Responsibilities:
Create and maintain data architecture designs that support business and technical requirements for high-quality, performant data solutions.
Implement data modeling standards and ensure adherence within data management solutions.
Research and recommend tools and services to improve data management processes and support architectural standards and patterns.
Participate in data solution prototyping initiatives.
Create and maintain documentation related to data architecture standards, protocols, and frameworks.
Implement culture of continuous improvement of data architecture approaches to align to best practices and data management technology evolution.
Foster environment of continuous learning, maintain current knowledge of emerging technologies and industry trends, and present ideas for innovation.
Perform analytical exploration and examination of data from multiple data sources.
Participate in enforcing data quality and governance best practices in the data platform.
Work with a multi-disciplinary team consisting of data analysts, data engineers, developers and data consumers in an agile, fast-paced environment.
Work with and support a team that is globally located.
Participate in review processes that involve architecture, design and quality assurance to preemptively identify conflicts and ensure consistency of implementation.
Ensure strict adherence to documentation best practices and change control processes.
Perform other duties as assigned.
Qualifications:
Bachelor’s degree in Computer Science, Information Technology, Data Analytics, Information Systems or a related field
10+ years of direct experience in Big Data, Data Warehousing, Data Analytics, and/or Information Management related projects
6+ years of direct experience in cloud data solution architectures, design and development including ETL, data warehousing, data lakes, and big data
5+ years of experience using SQL including development of stored procedures, functions, triggers and views
5+ years of direct experience with one or more database/data warehouse technologies (e.g., Oracle, MSSQL, MySQL, PostgreSQL, Hadoop, Teradata, Redshift, Snowflake)
5+ years of direct experience working in a cloud environment such as AWS, Azure or GCP
Excellent critical thinking and problem-solving skills
Must be self-sufficient and proactive
Deep understanding of agile development methods including: core values, guiding principles, and key agile practices
A strong understanding of data mining, predictive modeling, and statistical analysis
Experience working in retail business (preferred)
Experience working in a franchised business (preferred)
Extremely detail-oriented, efficient, and organized with an exceptional ability to establish and balance multiple priorities and objectives
Excellent presentation and communication skills along with the ability to communicate effectively across all levels of the organization
Able to establish and maintain effective, collaborative work relationships with diverse individuals, internally and externally
Creative, progressive, thought leadership with the ability to influence at all levels of the organization
Dedicated learner with a natural curiosity for consistent growth
Exhibits comfort, ease, and flexibility working in an extremely fast-paced ever-changing, deadline-driven environment
Cooperative team player with an upbeat, positive, “can-do” attitude!
Perks:
Remote work allowed
Volunteer days off
Competitive salaries and comprehensive benefits package, including medical, pharmacy, dental and vision benefits
Generous vacation/holiday pay
401(k) Retirement
Employee Stock Purchase Program
Childcare reimbursement
Pet care reimbursement
Learning and development programs
Discount programs, including vacations, theme parks, shopping, meal delivery services & much more
Free Black Card membership and fun exercise incentives
Company-sponsored social events
Apply Now: click Apply Now
Show Less
Report",3.4,201 to 500 Employees,1992,Company - Public,Beauty & Wellness,Personal Consumer Services,$5 to $25 million (USD)
Solutions Architect (Data Architect),$68K - $156K (Employer est.),BAXTER3.7 ★,"Cary, NC","This is where you save and sustain lives
At Baxter, we are deeply connected by our mission. No matter your role at Baxter, your work makes a positive impact on people around the world. You’ll feel a sense of purpose throughout the organization, as we know our work improves outcomes for millions of patients.
Baxter’s products and therapies are found in almost every hospital worldwide, in clinics and in the home. For over 85 years, we have pioneered significant medical innovations that transform healthcare.
Together, we create a place where we are happy, successful and inspire each other. This is where you can do your best work.
Join us at the intersection of saving and sustaining lives— where your purpose accelerates our mission.
The Care Communications Digital Health Solutions is a product portfolio comprised of communications applications and solutions including mobile clinical communication solutions, medical device integration, alarm and alert management, waveform visualization and solutions for natural language processing. Together these solutions are focused on a vision of unifying the software platform to drive workflow efficiency, improve patient outcomes and strengthen patient engagement. Our portfolio is regularly expanding to include innovative solutions to enhance patient outcomes.
Your Role at Baxter:
The Solutions Architect enables the organization to leverage its data assets and capabilities for maximum value with validated experience in defining, crafting, developing, and implementing data models and services across the business. This role is responsible for aligning the future state enterprise information architecture with the corporate strategy.
The Solutions Architect surfaces key metrics to help the business succeed by delivering IT solutions that align with business requirements to drive tactical and strategic decisions. Partnering across our business, the solutions architect will help our business understand and analyze a proposed business problem or project, define how it relates to similar systems and processes within the BI environment and craft a solution to meet those business needs.
Your Team:
Baxter offers a great benefits package including Healthcare Insurance, 401K, Paid Time Off, Parental Leave, and Employee Stock Purchase Plan.
What you'll be doing:
Work independently or in a team while applying knowledge of multiple technologies and structured design methodologies toward effective business solutions
Implement data strategies and models to address shareholders’ needs with domain experts translating business requirements into data solutions including the development of Power BI reports and dashboards originating from multiple data sources.
Analyze, plan, and define the data architecture framework, including security, reference data, metadata, usability, and stability to help ensure that it meets the needs of the business.
Lead multiple requests simultaneously in coordination with business priority.
Build Measures and Calculated columns using DAX.
User Power Query to clean, filter and transform the data according to the business needs.
Write M queries in Power Query to transform the data.
Write SQL queries, stored procedures, views, functions based on the requirements.
Oversee the design process for new applications, including creating data flows, diagrams, models, and prototypes, evaluating risks and defects, analyzing, and creating specifications as needed.
Facilitate and drive Data Analytics standard processes across the enterprise, creating a Data and Analytics community.
Identify challenges and opportunities with Data Analytics and recommend solutions that help mitigate challenges.
Create technical documents and provide technical support and training as needed.
Work closely with systems analysts, software developers, data managers and other team members to ensure successful production of analytical solutions.
Offer viable solutions for various systems and architectures to resolve variety of business requirements.
Education and experience:
5+ years of work experience with data and dashboard development.
Validated modeling and data pipeline buildout experience.
Experience with Microsoft Azure Platform - Emphasis on Power Platform, Azure Data Services (SQL Server, Data Lake, DataVerse, etc…)
Experienced with Azure SQL Databases / Tables, Advanced SQL with the ability to run SQL against Oracle tables.
Sophisticated knowledge of enterprise data/information architecture.
Understanding of DBA functions including creating and alternating tables.
Familiarity with Power Apps, Data Flows, Power Query.
Experience working in an Agile environment preferred.
Shown ability to translate end-state business, information, and technology models into reference patterns and standards.
Advanced interpersonal skills (both oral and written) demonstrating effectiveness in communicating business capability enablement through information management platforms.
Ability to coordinate across architects and developers to build the “end-to-end” view of the entire information landscape and roadmap.
Diligent team player who can consistently supply valuable suggestions and solutions in areas of analytical solutions.
We understand compensation is an important factor as you consider the next step in your career. At Baxter, we are committed to equitable pay for all our employees, and we strive to be more transparent with our pay practices. To that end, this position has a salary range of $68,000 - $156,000, plus an annual incentive bonus. The above range represents the expected base salary range for this position. The actual salary may vary based upon several factors including, but not limited to, relevant skills/experience, time in the role, business line, and geographic/office location.
The successful candidate for this job may be required to verify that he or she has been vaccinated against COVID-19, subject to reasonable accommodations for individuals with medical conditions or religious beliefs that prevent vaccination, and in accordance with applicable law.
Equal Employment Opportunity
Baxter is an equal opportunity employer. Baxter evaluates qualified applicants without regard to race, color, religion, gender, national origin, age, sexual orientation, gender identity or expression, protected veteran status, disability/handicap status or any other legally protected characteristic.

EEO is the Law
EEO is the law - Poster Supplement
Pay Transparency Policy
Reasonable Accommodations

Baxter is committed to working with and providing reasonable accommodations to individuals with disabilities globally. If, because of a medical condition or disability, you need a reasonable accommodation for any part of the application or interview process, please click on the link here and let us know the nature of your request along with your contact information.
Recruitment Fraud Notice

Baxter has discovered incidents of employment scams, where fraudulent parties pose as Baxter employees, recruiters, or other agents, and engage with online job seekers in an attempt to steal personal and/or financial information. To learn how you can protect yourself, review our Recruitment Fraud Notice.
097538
#LI-Remote
To apply to this job, click Apply Now
Show Less
Report",3.7,10000+ Employees,1931,Company - Public,Biotech & Pharmaceuticals,Pharmaceutical & Biotechnology,$10+ billion (USD)
